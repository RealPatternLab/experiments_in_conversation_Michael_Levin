[00:00:00 - 00:00:33] Speaker A says: "Yes, I was just hoping to show, really the main thing I was wanting to show you is. So I, I don't know if you saw, but Stephen Wolfram did a post on Biomedicine and I was helping him out with the code with that. And I was just hoping to get your thoughts really, on how accurate or like the connections between. As someone who knows the, like, real literature, you know biology better than me, like, where does the model fit and where doesn't it fit? Basically."

[00:00:33 - 00:00:35] Speaker B says: "Okay, yeah, that sounds great."

[00:00:35 - 00:00:35] Speaker A says: "Yeah."

[00:00:35 - 00:00:36] Speaker B says: "You want to take me through it?"

[00:00:36 - 00:06:11] Speaker A says: "Yeah. So I'm just going to share my screen. Okay. Yeah. So this is the automata that we're using. So It's k equals 4 and r equals 1. And I don't know, you're familiar with like the cellular automata kind of rules and stuff, right? Okay, yeah. So basically we ended up using k equals 4, r equals 1, because, you know, that's kind of just what worked for us. But basically what we're trying to do here is these are cellular automata and the basic idea is we, we, we change one cell in the body and then we see what happens to the pattern. And with the idea that like, the changing cell is like a disease and then, and then eventually we're going to look for a cell to change to try to put it back to the original pattern. And so basically what we find is, well, that it's just because of the complexity of the automata, it's really hard to both, to do, to do all the steps of medicine. So like you have, you have a disease classification. So for example, like, this is all the possible, all the possible perturbation, not all of them, but a few of the possible perturbations that you can do to this automata by changing a single cell. And if we try to like, put that in feature space using a machine learning algorithm and try to basically cluster the different potential diseases into different categories, we see that it's not completely discrete, meaning, like there's always going to be some in between, between diseases. And so it's potentially saying that like, you know, in the textbook, like in ICD10, where they classify diseases into different branches neatly. In the real world, it's kind of suggesting that that's not really possible, completely possible. And then like going another step, it's like, okay, so now classifying diseases, now what about, like, let's see, making predictions and diagnosing diseases. So one of Stephen Wolfram's ideas about medicine is that like the medical observer is, doesn't, is Basically they're observing something much more complex than they can possibly understand. And so because of that, you know, certain features emerge. So for example, in this case we look at like just the width of the automaton at all steps. So, so like the, here the, the green is the normal disease histogram. So those are all the lifetimes if you perturb that automaton. And then the yellow one is what happens if we, you know, it's kind of like when a doctor does a test and sees that something's wrong, which in this case we're using the width of the automaton. And then basically what that's saying is, you know, it's just observing that the lifetimes are all messed up based because the doctor observed a different width. And the goal is in like from the width of the automaton can you predict what's going to happen to that kind of organism? And so what this is showing is the orange, all the orange lines are the potential diseases in the blue or not the potential, the diseases. And then the blue line is the main guy, the original. And so it's kind of like you can already see just from the width that there's going to be a lot of chaos or like it's going to be a little bit unpredictable what's going to happen just based on like a high level metric like that. And like even if you just look at width at a single step, so this is with at step 25 and compared to like the lifetime which is the length of the pattern, we can see that it's just not a very like predictive measure. You know, you'd like it to be like, oh, you know, you'd like to see a trend there. But so yeah, and like we also try to use like this, this graph here is like a machine learning prediction of based on the width at step 25, what lifetime will you get? And basically it doesn't do any better than the median because there's just not good data here. And so like that's kind of one of the big like takeaways that Stephen Wolfram is making here is also that if you have like he's saying that if you have better interfaces with biology then you can end up making better predictions because, because it's complicated. If we continue to get more and more data faster then we'll be able to make a better diagnosis and prognosis. Yeah. And then I don't know, do you have any thoughts or should I just keep walking you through?"

[00:06:12 - 00:06:27] Speaker B says: "Well, I have a question and then and then I'll give some thoughts when you start these, these CAs. What, what, what starting string do you use? Like, what's the starting position for these things?"

[00:06:27 - 00:07:10] Speaker A says: "Yeah, so basically, and this is good because I really wanted to get into this as well. When we evolve them, we always start from this one red. It's called. We call it the seed condition. Or it's just like one red cell. And then what we're doing is we're. Let me just show you. We're changing the, the rules by one bit at a time. And if the, if the bit results in a longer or the same lifetime, then we keep it. So it's like kind of like a mutation and then a mutation to the rules. And then if it's neutral or advantageous, then we keep it."

[00:07:13 - 00:07:17] Speaker B says: "Okay, and when you're talking about lifetime, can you tell me what that is?"

[00:07:18 - 00:07:45] Speaker A says: "Yeah, so lifetime, we mean just the length of the automaton. So another point I should mention is that if it, if it lives forever, so a lot of times it'll. You'll do a mutation and then it'll like get into a loop and then like live forever, which we throw. We count that as a fitness of zero or a lifetime of zero. And then. So it's basically trying to get a longer and longer finite length."

[00:07:45 - 00:07:47] Speaker B says: "Longer finite length. Yeah. Okay, I get it."

[00:07:50 - 00:08:48] Speaker A says: "Anyways, so the, the. So that's kind of a normal evolution. But the. When we're evolving, these guys, because, because we were looking for like from the perspective of medicine, we wanted them to be robust. And this is like the kind of. One of the main things I wanted to ask you about, which is, so what we do is we do that same evolution, but we perturb it during the evolution. So this is like an example of a single step of evolution. And then we take the minimum fitness. So basically, if you perturb it 10 times, then you take the minimum fitness. So in this case it would be this 60 right here. And that's then the fitness. And all that's doing is just forcing the organism to be able to deal with perturbations. So, so it has to like, if, if it just. If any one of these goes to infinity or like we, we sometimes call it like cancer."

[00:08:48 - 00:08:49] Speaker B says: "Yeah."

[00:08:49 - 00:10:10] Speaker A says: "Then all of them, then the whole, the fitness of the whole organism is zero. So it has to get really good at not going to infinity and the whole. So has to get good at trying to keep its length despite a single point perturbation. And what we see is kind of like you may have Noticed, but it's kind of. We get these specific looking automaton which are, they're kind of like Steve Wolfram calls them, like attractors, which is they kind of have this randomness in the beginning and then they kind of eventually hit this state. In this case, it's like this purple cap and they have this like, I call it like a program death. So it's like no matter what the initial conditions are, they kind of always die. And so, I mean. Yeah, I'm just wondering how, how much that's actually like what you see in planaria, where like, like is. Do you think it's something as simple as this, that's, that tells them. Because I know that's one of the things you, you mentioned a lot, which is like, how do these, how do. When you're growing, when you're doing morphology, how do, how do the cells know when to stop? So I definitely wanted to, like, I know, you know, you, you haven't seen these before, but maybe you have some thoughts on that."

[00:10:10 - 00:10:51] Speaker B says: "Yeah, yeah. I mean, we, so, so we've done some work on this and I can send you some papers. I mean, we've, we used this a little bit more of a complex ca. In one case it's a neural ca. In another case it's something else. But I'll, I'll put some, I'll put some papers on the, on the chat. Yeah. And, and also, and also the planarian, the planarian story is I think we, we now have some, some, some pretty worked out thoughts about what's going on with the plenary. I can sort of, I can sort of go over it. Do you know the, the competency ratchet business? Does that, does that ring a bell at all?"

[00:10:51 - 00:10:52] Speaker A says: "Not really, no."

[00:10:52 - 00:12:18] Speaker B says: "All right, so, so, so, so the deal is basically this, that planaria, they at least the ones that we study, reproduce by, by ripping themselves in half and regenerating. Okay. And so unlike most of us who have this thing called Weissman's barrier, which is that mutations in your body don't get passed on to your offspring because. Right. You jettison the, the soma and it's only the, the, you know, the, the gametes that, that move on. Right? So the sperm and the egg. So we don't keep the mutations we acquire during our lifetime. Planaria are not like that because any mutation that doesn't kill the cell is propagated into the next generation as these stem cells reproduce. Right? So basically they accumulate. So, you know, for 400 million years or they've been Accumulating mutations. And they look, their genome is incredibly messy. It looks like a, like they can be mixed ployed, meaning that the cells can have different chromosomes. So it bothered me for a couple of decades when I first found out about this that the animal that is highly regenerative, immortal, resistant to cancer is also the one with the dirtiest genome. That's the exact opposite of what everybody tells you in biology classes where you say, well the genome is very important, you have to keep it clean because it determines this and that."

[00:12:18 - 00:12:18] Speaker A says: "So."

[00:12:20 - 00:15:20] Speaker B says: "We'Ve been studying this and by the way, there's a couple of other interesting features which finally snapped into place for me a couple of years ago, which is that for almost every other model system you can call the stock center and you can get mutants, so you can get flies with curly wings and mice with weird eyes and there's chickens with funny feet. There are mutant lines that you can get in planaria. There are no mutant lines. The only non, the only non standard planaria that are, that exist are our two head form and our, what we call the cryptic form. And neither of them is genetic, was created genetically. So, so, so, so long story short and I'll, and I'll put the papers on the, on the chat, here's what I think is going on there. The biggest, the most important thing about, about living tissue is that there is not a mechanical mapping between the genotype and the phenotype. That is not only is it complex, we all know it's not one to one and it's complex and all that, but it's not just complexity, pleiotropy, redundancy, degeneracy, all that stuff. It's not just that, it's that the middle layer that leads from the genome to the genotype to the phenotype has intelligence. What I mean by that is it's a problem solving system. And we put out something recently on the genome being a generative model for development. And there's also a cool paper on this by Nick Cheney and Kevin Mitchell. So anyway, the point is this. Imagine that you have like what we found in our tadpoles when you move the craniofacial organs to a novel location and will eventually find their way back. Like the thing it adjusts to perturbation. So now imagine what happens to a creature that has that level of morphogenetic competency between the genotype and the phenotype. Let's say you make a mutation. And that mutation, like all mutations, does multiple things. Maybe it does something good somewhere else in the animal. But one thing it does is move the mouth off to the side. Under standard circumstances, that animal will die because they can't eat. And whatever other consequences that mutation might have had never get explored. And so what you would have to do otherwise, whatever she would have to do, is wait until it finds a way to do that good thing without affecting the mouth, which could be a long time. Instead what happens is the face self corrects, as many things in embryogenesis do. And so now, now, now great, lots of mutations that otherwise would have been deleterious become neutral. And so now you get to explore that. So that's, that's fine. But, but, but here's the other thing about it. So, so that makes evolution go faster. But, but, but then here's the other thing. When that animal comes up for selection, selection doesn't know do you have a good face because your structural genome was great, or do you have a good face because your structural genome was actually kind of crap, but you had a lot of competency and you fixed it."

[00:15:20 - 00:15:21] Speaker A says: "Right?"

[00:15:21 - 00:19:00] Speaker B says: "So as soon as you start hiding information from selection, what happens then is that. And, and I'm sure I'll send you the paper. We, we modeled all this computationally. What happens is that evolution has a hard time seeing the structural genome. The pressure on the genome comes off, but what it does do is crank the competency. And so all the work ends up being spent on improving the competency and it becomes a positive feedback loop because the more you do that, the less you can see the structural genome. So then you have to put. So then more of the effort goes into the competency, so you get this positive feedback loop. And then what happens is at different positions on that spectrum, I think planaria are all the way to the end. Like it went all the way to the end. In other words, planaria, because their substrate was so unreliable, all the work of evolution went into making an algorithm that makes a proper worm no matter what the hardware looks like, pretty much. So they're kind of the biggest example of that's why there are no mutant lines is because, yeah, you try to edit the genome, but they ignore it because they mostly ignore their own genome too. And so, and so then you have intermediate cases like salamanders, which are pretty good at regenerating, but they're not immortal like planaria. And then you have mammals, and then all the way on the left you have something like nematodes, which are just completely cookie cutter organisms where every cell is numbered and all that. So I think what's really going on here is this, this, this, this deep competency around. And it's not just, you know, when you make defects it looks like repair, but when you make really drastic defects. For example, when we, when we make xenobots or anthrobots and we take the tissue completely out of its, out of its normal context, it doesn't repair, it doesn't try to repair to the normal, the standard default outcome. It makes something else and it makes something else that's completely viable, you know, that has all kinds of cool behaviors and morphology. So, so the key here is this middle layer, which is the competency layer. And this is what we've been modeling and what I've been writing about. So I think that's how in all of RCAs, that's what we've been doing. So we have the genome that comes in with the rules, we have the phenotype which gets selected, but in the middle it's something like a neural ca. Which really has some competencies and to get certain goals met even under, under, you know, all kinds of novel conditions. So, so I, you know, so, so that's, that, that's, that's how I see this process. And as far as diseases, I want to recommend because this is really interesting. There's, there's, there's this guy, Yuri Alon, you know him, he's like a synthetic biologist in Israel. He's, he's really good. He has a ton of great work. Anyway, here's the, here's the book and I'm going to put the, I'm going to put the title on the, on the chat. You should take a look at this. So if Stephen had not already hasn't already seen it, he should. It's called Systems Medicine by Yuri Alon, A L O N and the COVID of it is like basically like a periodic table. Like basically he's trying to ask the question of what from physiological circuits. What can we say about the kind of failure modes? And it's basically the clustering that you did for the different diseases and everything. That's, that's what he was trying to do based on, but based on, on, on data of, of physiological circuits, of real, real physiological circuits. So why, why do we have certain diseases and not so like the morphous space of possible diseases and so on."

[00:19:02 - 00:19:20] Speaker A says: "Wow. Yeah, that's definitely something that's definitely relevant. So thank you. But I wanted to ask you. So like I've seen, I've seen, I saw the. I don't know if it's A paper. But you guys were doing the, the neural ca. Like the one with the lizard. Is that the one you're talking about?"

[00:19:20 - 00:20:24] Speaker B says: "No, no, it's not. I'm going to put. I'm going to put a couple of things on the chat right now. So. So first is Peter. Peter Smiley's paper on competition between subunits being being used, becoming a type of coordination mechanism for. For morphology. And this business of growing something of finite size that does stop is really critical. And you can see, you can see in Peter's model how that happens. It basically happens because of competition for resources. And it's a really cool. That competition for resources is a very cool mechanism for enabling that. And then here's the neural ca stuff. Hold on. So this is right here. This is Ben Hartle and Sebastian Risi. That's one way to do it. Oops. And the other. The other thing. Yeah, and this is. And this is the. Yeah, and this is the evolutionary competency. The other. The other evolutionary competency model."

[00:20:24 - 00:21:17] Speaker A says: "Yeah. Okay. Yeah. Thank you so much. These are awesome. So, but. So one of the things I'm wondering is like, how much of that. Because, because like the neural cas, they're basically just like a bit smarter than the ones I'm looking at. And I'm wondering how. How much of that, like, intel, like you're basically saying that these guys, in order to do what the planaria do, have to be smarter than we kind of. Than biology kind of initially thought. And, and I'm. I'm wondering like, how simple do you think you can get this model to. To be in. In order to achieve what the planaria achieve? Have you guys, like, hit the bottom in terms of the neural cas, or do you think you could go even simpler than that?"

[00:21:19 - 00:21:43] Speaker B says: "No, I think you can go simpler than that. And it's some stuff. I. I have a student working some stuff. I'm not, I'm not. It's still, it's still very early days and we need to check. So I'm not really ready to talk about it until I check it and make sure that. That everything is. But, but no, it is much. It's even much earlier than that. And actually I'll. I'll show you something else. Hold on. I'm just taking, taking a note here."

[00:21:45 - 00:21:45] Speaker A says: "And."

[00:21:46 - 00:22:01] Speaker B says: "Yeah, okay. So. So there's this other thing that you can look at which. Because, because I'm. Because of all the world, the work on diverse intelligence and basal cognition. I'm really interested in this question of, like, what are the simplest systems that show this kind of competency, right?"

[00:22:01 - 00:22:01] Speaker A says: "Yes."

[00:22:01 - 00:22:40] Speaker B says: "And it turns out. So we started looking at it in very simple things, so we started looking at it in sorting algorithms. I don't know if you've seen this paper that we have on sorting and there's a couple of blog posts I have about it, but basically there's some of this already in Bubble sort already does some of this. So very simple systems, like extremely simple deterministic systems already do this. And I think, you know, I think there's a ton of such competencies to be, to be discovered. And I have a, I have a student working on some of this in, in various kinds of CAs."

[00:22:40 - 00:23:00] Speaker A says: "Okay, so what, sorry if this is like, you know, I don't want to waste your time and ask you questions that you've already answered in 100 times, but I'm wondering if what are the features you're looking for when you're trying to get the simplest possible model? What is it? What is the most essential things you're trying to capture that you see in the planarium?"

[00:23:02 - 00:28:05] Speaker B says: "I mean, the home run is, is for better for, for lack of a better vocabulary. Creative problem solving. Because we see, the kind of thing we see in biological tissues is not just homeostasis or anything like that. It's, it's also the ability to creatively come up with solutions that, that they've never seen before in evolution. So like, like in, in planaria, for example, there's we, we have this, this thing where we, we put them in barium chloride and barium is a non specific blocker of potassium channels. So the cells are very unhappy. In particular, all the neurons in the head are very unhappy because they can't pass potassium. So they're so, so over, over a day their, their heads explode like they, they literally explode. But then if you leave them in the barium after about a week or two, they grow back a new head and the new head is completely insensitive to the barium, like no problem. And so, and so we asked the question, what's different about these new heads compared to the old heads? And we found out that they, they express under a dozen new genes that enable them to live to, to basically get all their business done with blocked potassium channels. Now that's amazing. Planaria never. There's no pressure in the wild to be, to be resistant to barium. How do you, in the 20,000 dimensional action space, how do you find exactly those few genes that are going to help you? Because what you don't have time for is to randomly poke around in that space and see what happens. There's not time for the cells proliferate quite slowly. It's not like bacteria, so you don't have time for some sort of gradient descent. In fact, if you start messing around with different genes, you're going to kill yourself long before you find the solution. So this question of how the living material first of all is able to achieve the standard outcome despite all the noise and unreliability of the substrate, but also find new solutions, whether they be physiological solutions like vivarium or anatomical solutions and behavioral solutions like for anthrobots and xenobots, there's some degree of homeostasis and navigation of that anatomical space, but also towards novel solutions, which I think is just the exact same thing as creative problem solving. So that's the kind of thing we want to see. And so what that means is we put these things in weird scenarios and we see what they do and it's just like it's basically behavior science. And what you'll see in that sorting algorithms is paper is that we, yeah, we found different, different ways of looking at what they're doing and, and we started interfering with it and we found all kinds of crazy competencies like delayed gratification. Turns out, turns out these sorting algorithms can do delayed gratification. You know, who knew? Because it's not in the algorithm, right? And so, and so it's not just complexity, it's not just unpredictability, it's actually, you know, different degrees of problem solving competencies. So, so, so that's the kind of thing we want to see. You know, I want to see it and part of it is part of it. What makes it really hard but also really fun is that it isn't enough to be able to quantify like, like, like I like, I like what, what you guys have with the, with the persistence. Because it's not enough to say I want the same shape I had before because that, it doesn't just find new solutions to the same set point. It actually finds novel, it actually finds novel problems to solve. So an anthrobot is not an answer to the question of how to be a good, a good human embryo. That's not what it's doing. It's doing something completely different. And so being able to quantify that and recognize that is really hard because it's basically like in the field of what is it open, open ended evolution in a life, right? It's like you can do it. But, but what's, what, what, what do you reward for. If you don't know what, you know, if you don't want to constrain what it's going to find, what do you reward for? So, so I like this, I like this business of, of, of the growth control. But I also, I also think you guys should look for other aspects that are interesting. So for example, so I'll give you, I'll give you an example. Look, look for some kind of morphogenesis. So like not just growth control like in Peter. So, so in Peter Smiley's paper that I just put up, we, we look for two things. We, we rewarded for a couple of different things. We rewarded for growth control, so size and things like that, but also for, for specific shapes and specific topological relationships. So can you evolve you. Oh, you know, or can you find something that makes a specific shape, let's say multiple layers or you know, some, some, some kind of topology that's, that's like more, more biological, that kind of thing."

[00:28:05 - 00:28:13] Speaker A says: "Yeah, yeah, we've looked at, in other posts we looked or Stephen Wolfram really looked at aspect ratio."

[00:28:13 - 00:29:04] Speaker B says: "Yeah, but that's good, that's good. We did that in Peter's. Peter, Peter did exactly that. He looked, he looked at aspect ratio. So that's, so that's pretty good. Yeah. You know, and I love morphogenesis as a, as a, as a behavior, you know, in anatomical space. So I would, I would recommend thinking about that looking at, looking at different aspects of the shapes. You know, like aspect ratio is good. And then going, going beyond that too. That's, that's what we do in Ben Hardless paper that I just put up is look at, look at the ability to regenerate after, after anatomical damage. There's actually, by the way, there's a couple of other papers coming soon that, on this, on this kind of topic that might be interesting when, as soon as we've got it, you know, wrapped up, I'll send, I'll send it to you."

[00:29:05 - 00:29:43] Speaker A says: "Okay. Yeah. Thank you. So I was wondering like, so these are kind of simple models, but I know you guys have also done like more complicated, trying to get closer to act like actually how it works. And I was just wondering like how well do you guys feel like you understand the actual like so bubble sort has many of the features, but obviously it's not actually doing bubble sort of. But so the question is like the actual mechanism that it uses, how well do you understand that?"

[00:29:43 - 00:30:55] Speaker B says: "Yeah, well, that's an interesting philosophical question. So we need to define mechanism and we need to define Understand. So our situation is somewhat like neuroscience in that if you're looking at the proximal molecular mechanism, we understand it quite well. We know that a lot of this is mediated by bioelectrical circuits. We know the molecules involved. We know we can, we can see the electrical computations happening. Like the mechanisms aspect of it. We have it. But, but that by itself is, is utterly unsatisfying because it's kind of like saying you understand the computer because you understand copper and silicon and you can watch the electrons flow. Like, like. Yeah, right. But, but what's the computation that it's actually doing? That's, that's a much more, a much more challenging thing. So, so we have a little bit of it and what we're trying to do is exactly what the neuroscientists are trying to do, which is neural decoding. We, except, except not in neurons. So we see the electrical activity, we model it as a navigating agent like an animal basically navigating anatomical space. And we try to understand what are the algorithms that guide that, guide that. Navigation."

[00:30:56 - 00:30:59] Speaker A says: "Mm. Right."

[00:30:59 - 00:32:06] Speaker B says: "So, so, so some of this, so some of that we have. And, and, and we have it to the, to the extent that we can make tadpoles with eyes on their tails and the two headed flatworms and we can fix certain kinds of birth defects and we can induce certain kinds of regenerative events. So, so we're obviously, we, we've got the interface, we're obviously sort of learning some of the prompts that, that we can give it. But, but, and I really think that's what's going on here. This is, this isn't. I don't think medicine is going to be solved by mechanical kinds of approaches and not feed forward emergence. I think all of this is prompt and I think this is why we have so few good drugs in the sense of dependable efficacy and consistent, you know, lack of side effects among patients. Like, we have very few drugs that actually fix anything because, because we're trying to micromanage the holding down of specific molecular states. And instead what we should be doing is developing prompts for the decision making intelligence that's, that's implemented by these physiological circuits."

[00:32:08 - 00:32:39] Speaker A says: "Yeah. So like if, when you're, when you're making a, when you're doing basically writing to the organism, like is it, is it, is it set up so that like there's only a few cells that control. Is it like. So I know you say it's hierarchical, but like how hierarchical is it? Like, can you just Send one input to a single cell. And then how much of that organism can you change based on changing just one like node in the network?"

[00:32:39 - 00:34:05] Speaker B says: "Yeah, in some cases, in some cases that's exactly how it works. So for example, when you, when we can, we can induce basically metastatic melanoma in a normal tadpole. No, no drugs, no carcinogens, no oncogenes, no DNA damage. And you can do that by, by messing up the electrical communication with some cells. It only takes about three cells in the whole, in the whole tadpole before they trigger every other melanocyte to go, to go metastatic. So sometimes that works. We have other examples where what we do is manipulate. It doesn't even have to be geometrically proximal. We've shown both in cancer and in brain repair that you can actually trigger cells on the opposite side of the animal and still get, and get effects on the other side. So these things move. So there are waves of, propagating waves of this information that go through tissue and which we can now see to some extent. We have now a visualization modality for it. And, and, and my favorite, my favorite story it goes about this, it goes years back is when you, when you induce a, an ectopic eye on the, on the tail of a, or in the gut of a tadpole, you don't have to hit a lot of cells. If when you section those eyes, you often find out that we actually only hit a small number of cells. But what they did was recruit all their neighbors to help them build this structure."

[00:34:06 - 00:34:06] Speaker A says: "Right."

[00:34:06 - 00:35:34] Speaker B says: "And, right. So it's like, and a lot of collective intelligences do this. Ants obviously do this too. Right. When they come across something too heavy for them to lift, they recruit their, their nest mates to come in to come and help. So it's kind of like a feature of a self scaling property of collective intelligence of certain kinds. But there's a, there's a more interesting piece to the story which is that sometimes you do this, you get no eye at all. And when you look, what's actually happening is that there's kind of a battle of patterns going on there because, because the cells we injected are saying to their neighbors, you should help us to build an eye. And then, and all the neighbors, they have a tumor suppression mechanism that says, you guys have crazy voltage, you should stay skin. And that's what they normally, that's what cells normally do to, to suppress neighbors that acquire, start to acquire weird voltage patterns is they, they use these gap junctions to equalize it out. They try to buffer it out. So. And that's. And that's a. That's a, you know, a ubiquitous cancer suppression mechanism. So you have this. You have this battle, and sometimes the eyes. The eye story wins, and sometimes the skin story wins, because I really think it's. It's fundamentally a battle of patterns and which ones are the most convincing to these cells. And so sometimes you get an eye, and sometimes you get nothing. You know, you get. You get your normal organ. So that's the other thing is that I think there's a lot of both. Both competition and cooperation, and. And some of it takes place from the perspective of the cells, but some of it, I think, takes place from the perspective of the patterns, you know?"

[00:35:36 - 00:35:39] Speaker A says: "Yeah. God, it's so freaking cool, man."