{
  "file_metadata": {
    "text_file": "data/extracted_text/pdf_20250803_124126_518751_extracted_text.txt",
    "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
    "pdf_filename": "pdf_20250803_124126_518751.pdf",
    "file_size": 40379,
    "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
    "journal": "Interface Focus",
    "doi": "10.1098/rsfs.2014.0112",
    "year": "2015",
    "title": "Knowing one’s place: a free-energy approach to pattern regulation",
    "confidence_score": null,
    "document_type": "research_paper"
  },
  "chunks": [
    {
      "text": "Understanding how organisms establish their form during embryogenesis and regeneration represents a major knowledge gap in biological pattern formation. It has been recently suggested that morphogenesis could be understood in terms of cellular information processing and the ability of cell groups to model shape. Here, we offer a proof of principle that self-assembly is an emergent property of cells that share a common (genetic and epigenetic) model of organismal form. This behaviour is formulated in terms of variational free-energy minimization—of the sort that has been used to explain action and perception in neuroscience. In brief, casting the minimization of thermodynamic free energy in terms of variational free energy allows one to interpret (the dynamics of) a system as inferring the causes of its inputs—and acting to resolve uncertainty about those causes. This novel perspective on the coordination of migration and differentiation of cells suggests an interpretation of genetic codes as parametrizing a generative model—predicting the signals sensed by cells in the target morphology—and epigenetic processes as the subsequent inversion of that model. This theoretical formulation may complement bottom-up strategies that currently focus on molecular pathways—with (constructivist) top-down approaches that have proved themselves in neuroscience and cybernetics.",
      "section": "Abstract",
      "topic": "Morphogenesis as Cellular Information Processing",
      "chunk_summary": "Self-assembly in morphogenesis can be understood as cells minimizing variational free energy based on a shared model of organismal form, interpreting genetic codes as parameters of a generative model and epigenetic processes as its inversion.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "One of the central problems of biology is the origin and control of shape. How do cells cooperate to build highly complex three-dimensional structures during embryogenesis? How are self-limiting growth and remodelling harnessed for the regeneration of limbs, eyes and brains in animals such as salamanders? Understanding how to induce specific changes in large-scale shape (not only gene expression or cell differentiation) is crucial for basic developmental and evolutionary biology and is a fundamental requirement for radical advances in regenerative medicine and synthetic bioengineering.",
      "section": "Introduction",
      "topic": "Biological Pattern Formation",
      "chunk_summary": "The control of shape in biological systems, including embryogenesis and regeneration, is a central biological problem with implications for regenerative medicine and bioengineering.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "Although we now know an enormous amount about the molecular components required for patterning, it is currently unclear how the macromolecular and cellular constituents of a system orchestrate themselves to generate a specific structure and function. Importantly, numerous organisms are able to readjust their pattern to a specific target morphology despite drastic external perturbations and are able to stop growth and remodelling when the correct shape is reached. It is largely unknown how cell behaviours are coordinated to reach correct large-scale morphologies, and how the system is able to stop when the correct structure is complete. There are very few constructivist models that show what dynamics are sufficient for complex patterns to arise and be remodelled until a target anatomy results. The current focus on specific protein pathways has engendered a knowledge gap: high-resolution genetic data have not, in general, been able to specify what large-scale shape—or deformations of that shape—can or will occur. An important corollary is that it is difficult to know how or which of the myriad of low-level components (genes or proteins) must be tweaked to obtain a specific patterning change.",
      "section": "Introduction",
      "topic": "Limitations of Bottom-Up Approaches",
      "chunk_summary": "Current understanding of molecular components is insufficient to explain how cells coordinate to generate specific shapes, highlighting a knowledge gap between genetic data and large-scale morphology.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "This holds back progress in the biomedicine of birth defects and regeneration, which seek to induce the formation of coherent organs of correct size, shape and orientation—not merely gene activity profiles or stem-cell differentiation. In contrast to the near-exclusive pursuit of bottom-up strategies, a complementary approach has recently been suggested. It is possible that top-down models could parsimoniously explain high-level phenomena, such as coordination of cell behaviour towards a specific topological arrangement, and could provide strategies for exploiting developmental modularity and pluripotentiality to achieve desired changes in large-scale shape. Despite the successful use of goal-seeking models in cybernetics, physics, and cognitive neuroscience, these principled approaches have not been applied to morphogenesis. Here, we explore a specific application of these ideas, modelling morphogenesis via an optimality principle.",
      "section": "Introduction",
      "topic": "Top-Down Models for Morphogenesis",
      "chunk_summary": "Top-down models, successfully used in other fields, offer a potential complementary approach to understanding morphogenesis by focusing on high-level phenomena like cell coordination and shape control.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "In this paper, we pursue the notion that morphogenetic self-organization requires each cell to have an implicit model of its place in the final morphology and that self-assembly is the process of moving to sample local signals that are predicted by that model. In other words, we consider biologically plausible solutions to the inverse problem of how cells attain a target morphology, based upon a forward or generative model of the signals they should sense after they have attained that form. In brief, we formalize the solution in terms of an extremum or optimality principle; namely, the minimization of free energy. This minimization is an inherent aspect of self-organization at many levels. For example, protein folding minimizes thermodynamic free energy. However, we consider free-energy minimization with a twist: by re-writing the minimization of thermodynamic free energy in terms of a variational free energy from information theory, one can interpret self-organization in a Bayesian sense. Effectively, minimizing variational free energy is equivalent to maximizing the (Bayesian) evidence for a model that is contained in the signals (data) sampled by a system. This enables one to talk about self-organization in terms of inference and probabilistic beliefs that are implicit in its exchange with its local environment. This perspective is based upon a long history of theoretical work in the neurosciences that attempts to formulate action and perception in terms of conscious and unconscious inference. In recent years, the ensuing variational free-energy principle has been applied to cellular and pre-biotic self-organization: in which the environment supplies (sensory) signals to a system's internal states which, in turn, inform action on the environment. Both the changes in internal and active states minimize variational free energy, resulting in Bayes-optimal perception and action, respectively. This is known as active inference.",
      "section": "Introduction",
      "topic": "Free Energy Minimization in Morphogenesis",
      "chunk_summary": "Morphogenesis is modeled as cells minimizing variational free energy, acting to fulfill predictions of a generative model of the target morphology, enabling a Bayesian interpretation of self-organization.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "Here, we ask whether the same principles can explain self-assembly in the setting of morphogenesis. This is a particularly difficult problem because, unlike generic pattern formation, morphogenesis implies a pre-determined pattern or form to which an ensemble of cells should converge. However, from the point of view of any one cell, the remaining cells constitute external or environmental states that can only be inferred through intercellular signalling; molecular or electrochemical. This means that each cell can only infer its place in the target morphology when all the cells have reached their target destination—and are releasing the appropriate (chemotactic) signals. This presents a difficult chicken and egg (inverse) problem that requires each cell to differentiate itself from all other cells, so that it can release signals that enable other cells to differentiate themselves.",
      "section": "Introduction",
      "topic": "Challenges in Morphogenetic Self-Assembly",
      "chunk_summary": "Applying active inference to morphogenesis presents a challenge due to the interdependence of cell differentiation and signaling, requiring each cell to infer its place within the developing ensemble.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "One solution to this hard problem of self-assembly is to assume that every (undifferentiated) cell has the same model of the cellular ensemble, which it uses to predict the signals it should encounter at each location in the target form. At the beginning of morphogenesis, all the cells are thus identical: they possess the same model and implicit (stem-cell like) pluripotentiality, and know nothing about their past locations or their ultimate fate. If each cell then minimizes variational free energy then it should, in principle, come to infer its unique place in the ensemble and behave accordingly. This is guaranteed because the minimum of variational free energy is obtained when each cell is in a unique location and has correctly inferred its place. At this point, it will express the appropriate signals and fulfil the predictions of all other cells; thereby, maximizing the evidence for its model of the ensemble (and minimizing the free energy of the ensemble). This behaviour can be seen as autonomous, self-constructing or 'autopoietic' in the sense of Maturana & Varela. In fact, active inference (in many respects) can be regarded as a formalization of autopoiesis.",
      "section": "Introduction",
      "topic": "Solution via Shared Model and Free Energy Minimization",
      "chunk_summary": "The challenge of self-assembly is addressed by proposing that cells share a model of the target morphology and minimize variational free energy to infer their place and differentiate accordingly, a process akin to autopoiesis.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "In what follows, we present some simple simulations of cell migration and differentiation that provide a proof of principle that self-assembly can be understood in these terms. The resulting dynamics paint a relatively simple picture, where the parameters of each cell's model are genetically encoded—telling each cell how it should behave (what it should express) if it knew its place within the ensemble. One can then associate intracellular signalling—in response to signal receptor activation—with inferring its place or identity. This inference then leads to the transcription and release of appropriate molecular signals that induce intracellular signalling in other cells. This (signalling-dependent) transcription could be a metaphor for epigenetic processes. We first briefly review the fundaments of (thermodynamic) free-energy minimization in coupled (random dynamical) systems and how these can be cast as active (Bayesian) inference. We then use this formalism to simulate the morphogenesis of a simple organism (with a head, body and tail) to illustrate the emergent behaviour. Finally, we simulate some experimental perturbations to illustrate the predicted consequences in terms of regeneration and dysmorphogenesis.",
      "section": "Introduction",
      "topic": "Overview of the Study",
      "chunk_summary": "The paper presents simulations of cell migration and differentiation based on free energy minimization, linking the generative model to genetic and epigenetic processes, and exploring regeneration and dysmorphogenesis.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "We will consider self-assembly in (weakly mixing ergodic) random dynamical systems described by stochastic differential equations of the following form: ẋ = f(x) + ῶ. Here, the flow of generalized states f(x) is subject to random fluctuations ω. Generalized states x = (x, x′, x′′, ...) comprise the states per se, their motion, velocity, acceleration and so on. In essence, these equations specify probability distributions over paths in generalized coordinates of motion. We can now use the Helmholtz decomposition (a.k.a. the fundamental theorem of vector calculus) to express the flow in terms of a divergence-free component and a curl-free descent on a scalar Lagrangian L(x) or Lyapunov function: f(x) = (Q – Γ)∇L(x)",
      "section": "Generalized dynamics",
      "topic": "Random Dynamical Systems",
      "chunk_summary": "Self-assembly is considered within the framework of random dynamical systems, described by stochastic differential equations, where the flow of states can be expressed as a descent on a Lagrangian function.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "A Markov blanket is a set of states that separates two other sets in a statistical sense. The term was introduced in the context of Bayesian networks or graphs and refers to the children of a set (the set of states that are influenced), its parents (the set of states that influence it) and the other parents of its children. A Markov blanket induces a partition of states into internal states and external states that are hidden (insulated) from the internal (insular) states by the Markov blanket. For example, the surface of a cell may constitute a Markov blanket separating intracellular (internal) and extracellular (external) states. Statistically speaking, external states can only be seen vicariously by the internal states, through the Markov blanket. The Markov blanket itself can be partitioned into two sets that are, and are not, children of external states. We will refer to these as surface or sensory states and actuator or active states, respectively. Put simply, the existence of a Markov blanket S × A implies a partition of states into external, sensory, active and internal states: x ∈ X = Y × S × A × R. External states cause sensory states that influence—but are not influenced by—internal states, whereas internal states cause active states that influence—but are not influenced by—external states. Crucially, the dependencies induced by Markov blankets create a circular causality that is reminiscent of the action-perception cycle (figure 1).",
      "section": "Generalized dynamics and active inference",
      "topic": "Markov Blankets",
      "chunk_summary": "Markov blankets separate internal and external states, with sensory states influenced by external states and active states influenced by internal states, creating a circular causality resembling the action-perception cycle.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "We can now consider the dependencies among states implied by the Markov blanket, in terms of their equations of motion. In particular, we are interested in the flow of internal and active states that constitutes the system's response to sensory signals: f<sub>a</sub>(s, ā, r) = (Q<sub>a</sub> – Γ<sub>a</sub>)∇<sub>ā</sub>L(š, ã, î), f<sub>r</sub>(s, ā, r) = (Q<sub>r</sub> – Γ<sub>r</sub>)∇<sub>r</sub>L(š, ã, î) L(š, ã, r) = - ln p(š, a, ř|m). See [43] for details. This equation is the homologue of equation (2.2) for internal and active states. It says that their flow performs a generalized gradient ascent on the marginal ergodic density over internal states and their Markov blanket denoted by m. This means we can describe the (open) system in terms of a Lagrangian of the system's states that we will associate with its thermodynamic free energy in the setting of the stochastic thermodynamics of non-equilibrium steady states. On this point, one could stop and simply marvel at evolution for having selected equations of motion with attractors that have the intricate forms seen in biotic systems (e.g. protein folding, morphogenesis and pattern formation). These attracting forms are described probabilistically in terms of the thermodynamic free energy, describing the probability over the system's internal states and Markov blanket. Although we know this Lagrangian exists, it is practically (almost) impossible to evaluate its form. However, there is an alternative formulation of equation (3.1) that allows one to describe the flow in terms of a probabilistic model of how a system 'thinks' it should behave. This formulation is based on the following lemma:",
      "section": "Generalized dynamics and active inference",
      "topic": "Flow of Internal and Active States",
      "chunk_summary": "The flow of internal and active states, representing the system's response to sensory signals, can be described as a gradient ascent on the marginal ergodic density, related to thermodynamic free energy, but its form is difficult to evaluate.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "Lemma 3.1 (free energy): For any random dynamical system with a Markov blanket and Lagrangian L(x) = − lnp(ŭ, š, ã, r|m), there is a variational free energy F(š, ã, r) that describes the flow of internal and active states as a generalized descent f<sub>r</sub>(š, ã, r) = (Q<sub>r</sub> – Γ<sub>r</sub>)∇<sub>r</sub>F, f<sub>a</sub>(s, ā, r) = (Q<sub>a</sub> – Γ<sub>a</sub>)∇<sub>ā</sub>F and F(š, ã, r) = E<sub>q</sub>[L(x)] – H[q(Ŭ|ř)] = L(š, ã, î) + D<sub>KL</sub>[q(Ŭ|ř)||p(Ŭ|š, ā, ř)]. Proof. See [43]. This lemma says that if one interprets internal states as parametrizing some arbitrary (variational) density or Bayesian beliefs q(ψ|r) about external states, then the dynamics of internal and active states can be described as a gradient descent on variational free energy. Importantly, this free energy is a function of states that constitute the system; namely, the internal states and their Markov blanket. Variational free energy was introduced by Feynman to solve difficult integration problems in path integral formulations of quantum physics. This is also the free energy bound on log model evidence that is used extensively in approximate Bayesian inference; for example, variational Bayes and ensemble learning.",
      "section": "Generalized dynamics and active inference",
      "topic": "Variational Free Energy",
      "chunk_summary": "Variational free energy, a function of internal states and their Markov blanket, describes the flow of these states as a generalized descent, allowing a Bayesian interpretation of internal states as beliefs about external states.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "The expressions for variational free energy above highlight its Bayesian interpretation: the first equality expresses free energy as the expected Lagrangian (Gibbs energy) minus the entropy of the variational density. The second equality shows that variational free energy is the thermodynamic free energy plus a relative entropy or Kullback-Leibler divergence between the variational density and the posterior density over external states. The solution to equation (3.2) implies the internal states minimize free energy rendering the divergence zero (by Gibbs inequality). This means the variational free energy becomes the thermodynamic free energy and the variational density becomes the posterior density. In this setting, the thermodynamic free energy is also known as the log marginal likelihood or log model evidence. In short, the internal states will appear to engage in Bayesian inference, effectively inferring the (external) causes of sensory states. Furthermore, the active states are complicit in this inference, sampling sensory states that maximize model evidence: in other words, selecting sensations that the system expects. This is active inference, in which internal states and action minimize free energy—or maximize model evidence—in a way that is consistent with the good regulator theorem and related treatments of self-organization.",
      "section": "Generalized dynamics and active inference",
      "topic": "Bayesian Interpretation of Free Energy",
      "chunk_summary": "Minimizing variational free energy is equivalent to maximizing model evidence, leading to a Bayesian interpretation where internal states infer external causes and active states sample expected sensations, consistent with the good regulator theorem.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "The variational formulation above speaks directly to two fundamental observations made at the inception of cybernetics; namely, every good regulator is a model of its environment, and the law of requisite variety. The first observation is endorsed by the fact that variational free energy is a functional of a probabilistic model of how sensory states are generated by external states. The law of requisite variety follows from the fact that the variational density must be encoded by internal states whose cardinality equals or exceeds that of the sufficient statistics of the posterior density. This is necessary to eliminate the divergence between the variational and posterior densities. See [63] for a closely related discussion of information-based optimality criteria for control systems. The perspective afforded by the good regulator theorem highlights the fact that the (open) system can become the 'author' of its environment. In other words, it can control external or hidden states through action—such that they fulfil the predictions of the generative model. Indeed, as we will see later, the hidden states of the generative model do not even need to exist—provided their sensory consequences can be mediated through action. This is important because it allows one to specify the thermodynamic free energy in terms of a generative model, thereby specifying sets of attracting states (e.g. target morphologies) that can have quite complicated forms.",
      "section": "Generalized dynamics and active inference",
      "topic": "Good Regulator Theorem and Requisite Variety",
      "chunk_summary": "The variational formulation aligns with the good regulator theorem and the law of requisite variety, where the system's internal model and its capacity to encode beliefs are crucial for minimizing free energy and controlling its environment.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "Equipped with this (active inference) formulation, we can now simulate self-assembly by integrating equation (3.2) given a (probabilistic generative) model that entails beliefs about its environment. In other words, we only need to specify the generative model p(š, ã, r, ψ|m) and the dynamics of the environment f<sub>y</sub>(s, ā) and f<sub>s</sub>(s, ã) to completely specify the requisite equations of motion for the system and its environment. Generally, the model is specified in terms of nonlinear mappings with additive noise: s = g<sup>(1)</sup>(ψ<sup>(1)</sup>) + ω<sup>(1)</sup> ψ<sup>(1)</sup> = g<sup>(2)</sup>(ψ<sup>(2)</sup>) + ω<sup>(2)</sup> Gaussian assumptions (parametrized by their precision or inverse variance) about the random fluctuations ω prescribe the likelihood and priors over external states that define the Lagrangian or generative model L(x) = − lnp(š, ã, ř, ψ|m) = – ln p(s|ā, ř, ψ<sup>(1)</sup>) – ln p(ψ<sup>(1)</sup> |ψ<sup>(2)</sup>) ... p(s|ā, r, ψ<sup>(1)</sup>) = N(g<sup>(1)</sup>(ψ<sup>(1)</sup>), Π<sup>(1)</sup>) p(ψ<sup>(1)</sup>|ψ<sup>(2)</sup>) = N(g<sup>(2)</sup>(ψ<sup>(2)</sup>), Π<sup>(2)</sup>) : where Π correspond to the precision or inverse variance of the random fluctuations. In what follows, we integrated equation (3.2) using the Matlab routine spm_ADEM.m in the SPM academic freeware.¹ This scheme uses the Laplace assumption q(ψ|r) = N(ř, –∇<sub>r</sub>∇<sub>r</sub>L(š, ã, î, r)) and associates divergence-free flow within generalized motion Q<sub>r</sub>∇L(r) = D<sub>r</sub> = (r′, r′′, ...). The resulting scheme can be regarded as a generalized Bayesian filter, in which the internal states become the expected values of the external or hidden states, see [64] for details. This scheme has been used in several papers to simulate active inference in the neurosciences. In what follows, we use it to simulate self-assembly and how this illuminates the role of genetics and epigenetics in morphogenesis. These simulations are offered as a proof of principle that the above scheme provides a sufficient explanation for (simple) self-assembly.",
      "section": "Generalized dynamics and active inference",
      "topic": "Simulating Self-Assembly",
      "chunk_summary": "Self-assembly is simulated using a probabilistic generative model and the dynamics of the environment, integrating equations of motion using a generalized Bayesian filter where internal states represent expected values of external states.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "We simulated morphogenesis given a target morphology specified in terms of the location and differentiation of eight clones or cells shown in figure 2 (a simple form with a head, body and tail). Here, we focus on the migration and differentiation of each clone prior to subsequent proliferation (filled cells in the upper right panel of figure 2). We deliberately stripped down the problem to its bare essentials to illustrate the nature of the dynamics, which will be used in the final section to make predictions about the results of various interventions. In brief, starting from an ensemble of undifferentiated cells at the same location, we wanted to simulate their migration and differentiation using minimization of free energy. For simplicity, we did not consider cell division; however, the ensuing behaviour showed distinct phases of migration and differentiation that was mediated exclusively by extracellular signals: e.g. chemotactic signals or slow electrochemical coupling. Crucially, at the beginning of morphogenesis all the cells were identical: although they all possessed the same model and implicit (stem-cell like) pluripotentiality, they knew nothing about where they were or their ultimate fate.",
      "section": "Simulating self-assembly",
      "topic": "Simulation Setup",
      "chunk_summary": "Morphogenesis is simulated for a simple organism with a head, body, and tail, focusing on cell migration and differentiation driven by free energy minimization and mediated by extracellular signals.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "A key aspect of the resulting self-assembly is a circular causality that follows from modelling multiple cells, where each cell is constituted by internal (intracellular) states and their Markov blanket. The sensory states of the Markov blanket were limited to chemoreceptor samples of extrinsic (extracellular) and intrinsic (intracellular) concentrations, while the active states could either cause cell migration (on a two-dimensional surface) or the release of chemotactic signals. This is an interesting set-up because the external states of one cell are the active states of other cells. This means we are effectively simulating a multi-system or multi-agent problem that, as we will see, necessarily entails some form of communication or generalized synchrony among cells. By framing self-assembly as active inference, we can now functionally talk about a cell's beliefs and actions in the following way: each cell possesses a generative model that encodes (genetic) beliefs about the chemotactic signals it should sense and express if it occupied a particular place in the target form. However, it has to first infer its identity on the basis of chemotactic signals—enabling it to predict the signals it should sense and express. Action can then fulfil these predictions by moving over concentration gradients to match extracellular predictions and releasing signals to match intracellular predictions. Clearly, this would be a fairly robust (and trivial) scheme if all the other cells were in their target locations and were expressing the appropriate signals; however, at the beginning of morphogenesis they are not. This is where the circular causality comes in. In order to reach the target form, each cell has to move to an appropriate location based upon chemotactic concentration gradients. However, these gradients depend upon cell migration. In other words, self-assembly requires each cell to 'know its place' so that the population can establish a chemotactic frame of reference that enables each cell to ‘know its place'. This is the problem solved through minimizing free energy, where free energy is minimized when, and only when, every cell has associated itself with a unique target location.",
      "section": "Simulating self-assembly",
      "topic": "Circular Causality and Cell Beliefs",
      "chunk_summary": "The simulation incorporates circular causality, where cells' actions influence each other's external states, and active inference allows interpreting cell behavior as driven by beliefs encoded in a generative model and actions aimed at fulfilling predictions.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "Note that, after differentiation, every cell has to infer a unique identity without access to the beliefs of other cells. This hard problem is finessed by the embodied nature of active inference: because a cell can only be in one place at a time there is a unique free-energy minimum, where every cell knows its respective place. While this may sound abstract, it is relatively straightforward to simulate self-assembly and cast morphogenesis in terms of familiar processes such as genetic pathways, epigenetic influences and biophysical or chemical guidance cues. In detail, we simulated very simple environmental dynamics with external states that comprised the location of each cell x ∈ R<sup>2</sup> and its release of four chemotactic signals ψ ∈ R<sup>4</sup>, which were the corresponding active states of each cell. More realistic simulations would model cell migration and signalling as a function of action; however, we will assume action is sufficiently fast to use the adiabatic approximation ψ̇ ≈ a: i.e. the solution to τψ̇ = a − ψ. τ ≫ 0. Sensory states corresponded to chemotactic concentrations of intracellular, exogenous and extracellular signals. Here we assume the existence of exogenous (linear) concentration gradients, which we will relax later: s = [s<sub>c</sub> s<sub>x</sub> s<sub>x</sub> λ(ψ<sub>x</sub>, ψ<sub>ε</sub>)] + ω. ε = [ε<sub>c</sub> ε<sub>x</sub> s<sub>c</sub> ελ ψσ(ν) s<sub>x</sub> – ψσ(ν) s<sub>x</sub> – λ* σ(r)] The signal receptor noise was set at very low levels with a log precision of −16. The function λ(ψ<sub>x</sub>, ψ<sub>ε</sub>) returns extracellular signal levels generated by all cells assuming a monoexponential spatial decay of concentration for each of the signals: where, for the i<sup>th</sup> cell λ<sub>i</sub>(ψ<sub>xi</sub> , ψ<sub>ε</sub>) = τ · Σ<sub>j</sub> ψ<sub>cj</sub> · exp (−|ψ<sub>xi</sub> – ψ<sub>xj</sub>|) where, τ ∈ [0, 1] is developmental time and models a linear increase in sensitivity to extracellular signals (e.g. the progressive expression of cell surface receptors over time). Finally, each cell is assumed to have the same generative model specified in terms of the mapping from hidden states to sensations: g(ψ) = [ψ λ*ψ σ(ψ)], λ* = λ(ψ<sub>x</sub>, ψ<sub>ε</sub>) σ(ψ) = exp (ψ) / Σ<sub>j</sub> exp (ψ<sub>j</sub>) where, the matrices (Φ, Ψ) correspond to target locations and the combinations of the four signals expressed at these locations, respectively. The (softmax) function of hidden states σ(ψ) returns expectations about the identity of each cell. These expectations enable the cell to predict which chemotactic signals it should express and sense. We assumed (zero mean) Gaussian priors over the hidden states with a small precision Π<sup>(2)</sup> (with a log precision of minus two). This means that the cells have prior beliefs that they have a high expectation of being a particular clone but they do not know which clone they belong to. This form of prior is ubiquitous in generative models of sparse causes (e.g. [65]). The resulting model is extremely simple and has no hierarchical structure, enabling us to drop the superscripts of equation (3.2).",
      "section": "Simulating self-assembly",
      "topic": "Simulation Details and Generative Model",
      "chunk_summary": "The simulation uses a simple generative model with four chemotactic signals, incorporating environmental dynamics, cell location, signal release, and sensory states based on chemotactic concentrations, aiming to model cell differentiation and migration.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "This generative model or Lagrangian produces remarkably simple dynamics for internal and external states (suppressing higher order terms and using A·B ≡ A<sup>T</sup>B): f<sub>r</sub>(š, ã, î) = (Q<sub>r</sub> – Γ<sub>r</sub>)∇<sub>r</sub>F = Dř − ∇<sub>r</sub>ε· Π<sup>(1)</sup>ẽ – Π<sup>(2)</sup>ř f<sub>a</sub>(s, ā, r) = (Q<sub>a</sub> – Γ<sub>a</sub>)∇<sub>ā</sub>F = Dã – ∇<sub>a</sub>š · Π<sup>(1)</sup>ẽ ⇒ ȧ<sub>c</sub> = Da<sub>c</sub> – Π<sup>(1)</sup>ē<sub>c</sub> + Π<sup>(1)</sup>ē<sub>λ</sub> ȧ<sub>x</sub> = Da<sub>x</sub> − ∇<sub>x</sub>š<sub>x</sub> · Π<sup>(1)</sup>ē<sub>x</sub> + ∇<sub>x</sub>λ· Π<sup>(1)</sup>ē<sub>λ</sub> where, e = s - g(r) is the prediction error at the level of chemotactic signal receptors whose gradients are ∇<sub>x</sub>s = ∂s/∂x = ∂s/∂a<sub>x</sub>. The signal precision Π<sup>(1)</sup> had a log precision of two, where the precisions over (generalized) motion modelled random fluctuations with a Gaussian autocorrelation function of one. These equations have some straightforward interpretations: the internal states organize themselves to minimize (precision weighted) prediction error based upon predictions. These predictions are weighted mixtures of target locations and concentrations encoded by (Φ, Ψ). If we associate this encoding with a genetic code, then its transcription into predictions can be associated with epigenetic processes (i.e. intracellular signalling-dependent transcription). Figure 2 illustrates this graphically using the target morphology assumed for the simulations. Here, different segments of the target form are associated with four cell types, defined in terms of the combination of signals expressed.",
      "section": "Simulating self-assembly",
      "topic": "Dynamics of Internal and External States",
      "chunk_summary": "The generative model leads to simple dynamics where internal states minimize prediction error based on predictions encoded by genetic code and transcribed via epigenetic processes, with different cell types defined by signal combinations.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "The updates for action are even simpler. Active states control the expression of chemotactic signals and cell migration. Signal expression simply attempts to close the gap between the predicted and detected signals, while migration is driven by local concentration gradients sensed by the cell. It is interesting to note that these gradients require a distribution of receptors over a spatially extensive surface or sensory epithelia, which is characteristic of living organisms. Furthermore, it requires the spatial scale of cells to be non-trivial in relation to chemotactic gradients; although see [66] for a discussion of active sampling in this context. Heuristically speaking, the cell moves to fulfil its expectations about the signals it thinks it should encounter, while expressing the signals associated with its current beliefs about its place in the target ensemble.",
      "section": "Simulating self-assembly",
      "topic": "Action Updates and Cell Migration",
      "chunk_summary": "Active states control signal expression and cell migration, with signal expression minimizing the difference between predicted and detected signals, and migration driven by local concentration gradients, requiring spatially distributed receptors.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    },
    {
      "text": "Figure 3 shows the resulting self-assembly using the target morphology shown in figure 2. These simulations used 32 time steps (each corresponding to several minutes). The resulting trajectories show several interesting features. First, there is a rapid dispersion and migration of the cells to their target locations, followed by a differentiation into the respective cell types (at about the eighth time step). This migration and differentiation is accompanied by a profound reduction in free energy—as the solution converges towards the target configuration. Note the initial increase in free energy as cells disperse a bit too quickly on the first iteration (as often seen with nonlinear generative models). The free energy here is the free energy of the ensemble or the sum of the free energy of each cell (because the variational and posterior densities are conditionally independent given sensory signals). All the cells started at the same location and with undifferentiated expectations about their fate (using small random expectations with a log precision of minus four). In this example, the self-assembly is not perfect but reproduces the overall form and differentiation into head, body and tail cell types. We terminated the simulation prematurely to illustrate the partial resolution of uncertainty about cellular identity implicit in the expectations encoded by the internal states. These are shown in the lower middle panel of figure 3 for all cells (after application of the softmax function) and can be interpreted as a confusion matrix. The off-diagonal block structure of this confusion matrix shows that, as one might expect, there is a mild confusion between head and body cells, and between body and tail cells (but not between head and tail cells). This confusion resolves after continued differentiation (results not shown).",
      "section": "Results and discussion",
      "topic": "Simulation Results",
      "chunk_summary": "Simulations show rapid cell dispersion and migration followed by differentiation, accompanied by free energy reduction, with some initial confusion between cell types that resolves over time.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_518751.pdf",
      "original_filename": "pdf_20250803_124126_518751_extracted_text.txt",
      "authors": "[\"Karl Friston\", \"Michael Levin\", \"Biswa Sengupta\", \"Giovanni Pezzulo\"]",
      "year": "2015",
      "journal": "Interface Focus",
      "doi": "10.1098/rsfs.2014.0112"
    }
  ],
  "gemini_response": "",
  "processed_at": "2025-08-06T12:22:51.631647"
}