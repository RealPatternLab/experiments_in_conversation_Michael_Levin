{
  "file_metadata": {
    "text_file": "data/extracted_text/pdf_20250803_124125_735373_extracted_text.txt",
    "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
    "pdf_filename": "pdf_20250803_124125_735373.pdf",
    "file_size": 40793,
    "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
    "journal": "Unknown",
    "doi": null,
    "year": null,
    "title": "Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery",
    "confidence_score": null,
    "document_type": "research_paper"
  },
  "chunks": [
    {
      "text": "With recent Nobel Prizes recognizing AI contributions to science, Large Language Models (LLMs) are transforming scientific research by enhancing productivity and reshaping the scientific method. LLMs are now involved in experimental design, data analysis, and workflows, particularly in chemistry and biology. However, challenges such as hallucinations and reliability persist.",
      "section": "Abstract",
      "topic": "LLMs in Science",
      "chunk_summary": "LLMs are transforming scientific research but face challenges like hallucinations and reliability.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "In this contribution, we review how Large Language Models (LLMs) are redefining the scientific method and explore their potential applications across different stages of the scientific cycle, from hypothesis testing to discovery. We conclude that, for LLMs to serve as relevant and effective creative engines and productivity enhancers, their deep integration into all steps of the scientific process should be pursued in collaboration and alignment with human scientific goals, with clear evaluation metrics.",
      "section": "Abstract",
      "topic": "LLMs and the Scientific Method",
      "chunk_summary": "This paper reviews LLMs' role in redefining the scientific method and advocates for their integration into all stages of scientific research.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "The transition to AI-driven science raises ethical questions about creativity, oversight, and responsibility. With careful guidance, LLMs could evolve into creative engines, driving transformative breakthroughs across scientific disciplines responsibly and effectively. However, the scientific community must also decide how much it leaves to LLMs to drive science, even when associations with ‘reasoning', mostly currently undeserved, are made in exchange for the potential to explore hypothesis and solution regions that might otherwise remain unexplored by human exploration alone.",
      "section": "Abstract",
      "topic": "Ethical Considerations of AI in Science",
      "chunk_summary": "The increasing use of AI in science raises ethical concerns about creativity, oversight, and the extent to which LLMs should drive scientific inquiry.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Recent advances in artificial intelligence (AI) have transformed multiple areas of society, the world economy, and academic and scientific practice. Generative AI and Large Language Models (LLMs) present unprecedented opportunities to transform scientific practice, advance Science, and accelerate technological innovation. Nobel Prizes in Physics and Chemistry were awarded to several AI leaders for their contributions to AI and frontier models, such as Large Language Models (LLMs). This promises to transform or contribute to scientific research by enhancing productivity and supporting various stages of the scientific method. The use of AI in science is booming across numerous scientific areas and is impacting different parts of the scientific method.",
      "section": "Introduction",
      "topic": "AI's Impact on Science",
      "chunk_summary": "AI, particularly LLMs, is revolutionizing scientific practice and accelerating innovation, impacting various stages of the scientific method.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Despite the potential of LLMs for hypothesis generation and data synthesis, AI and LLMs face challenges in fundamental science and scientific discovery. Hence, our premise in our perspective is that AI, in general, has so far been limited in its impact on fundamental science, which is defined here as the discovery of new principles or new scientific laws. Here, we review how LLMs are currently used as a technological tool – to augment the scientific process in practice and how they may be used in the future as they become more powerful tools and develop into powerful scientific assistants. Combining data-driven techniques with symbolic systems, such a system could fuse into hybrid engines that may lead to novel research directions. We aim to describe the gap between LLMs as technical tools and “creative engines” that could enable new high-quality scientific discoveries and pose novel questions and hypotheses to human scientists. We first review the current use of LLMs in Science, aiming to identify limitations that need to be addressed when moving toward creative engines.",
      "section": "Introduction",
      "topic": "LLMs and Fundamental Science",
      "chunk_summary": "While LLMs show promise, their impact on fundamental scientific discovery has been limited so far, and this paper explores how LLMs can transition from tools to \"creative engines.\"",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "There is solid recognition and excitement for the transformative potential of AI in Science. For example, leading machine learning conferences (NeurIPS, ICML) have recently (2021-2023) arranged targeted workshops on AI4Science. Some recent reviews and papers include1–38. This demonstrates the energy and potential of using automated (i.e., AI tools) for Science. This “dream” can be traced back to the times of Turing and the emergence of Artificial Intelligence in the 1950s39. With recent advancements in computational techniques, vastly increased production of scientific data, and the rapid evolution of machine learning, this long-held vision can be transformed into reality. Yet, most current reviews and original papers focus on specifically designed machine learning architectures targeting particular application domains or problems.",
      "section": "Introduction",
      "topic": "AI4Science",
      "chunk_summary": "There is growing excitement and recognition of AI's potential in science, with conferences and publications dedicated to AI4Science, but current research often focuses on specific machine learning architectures for particular problems.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "For example, recent reviews have explored how to use variants of Deep Learning, Geometric Deep Learning, or Generative AI in its generality (including different architectures such as CNNs, GNNs, GANs, diffusion models, VAEs, and Transformers) as a tool for assisting Science 3,11,13,15,19,22. For example, Wang et al.¹, reviews breakthroughs in how specific techniques such as geometric deep learning, self-supervised learning, neural operators, and language modelling have augmented Science in protein folding, nuclear fusion, and drug discovery. An essential thread in their review is the vital notion of representation, pointing out that different AI architectures can support valuable representations of scientific data and thereby augment Science. Recent papers demonstrate the appeal and the potential of using AI-driven and augmented tools for automating science1,4,13,40.",
      "section": "Introduction",
      "topic": "Deep Learning in Science",
      "chunk_summary": "Recent reviews have explored the use of various deep learning techniques for assisting scientific research, highlighting the importance of data representation.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Traditional scientific advancements have been primarily driven by hypothesis-led experimentation and theoretical development, often limited by human cognitive capacities and manual data processing. For example, the formulation of Newtonian mechanics required meticulous observation and mathematical formalization over extended periods. Here, the rise of AI4Science represents a paradigmatic revolution that could reach beyond human cognitive limitations. AI-driven advancements promise to enable rapid processing and analysis of massive data sets, revealing complex patterns that surpass human analytical capabilities. For example, DeepMind's AlphaFold dramatically transformed protein structure prediction, a longstanding scientific challenge, using deep learning to predict protein folding accurately. Furthermore, AI4Science could reverse the slowdown in scientific productivity in recent years, where literature search and peer-review evaluation41-43 are bottlenecks.",
      "section": "Introduction",
      "topic": "AI4Science Revolution",
      "chunk_summary": "AI4Science represents a paradigm shift, overcoming human cognitive limitations and enabling rapid data analysis, as exemplified by AlphaFold's success in protein folding.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "In contrast to previous reviews, here we first address the use of LLMs, regardless of the specific underlying architecture, and their use as a tool for the scientific process. We assess how different areas of science use LLMs in their respective scientific process. This analysis sets the stage for asking how LLMs can synthesize information, generate new ideas and hypotheses, guide the scientific method, and augment fundamental scientific discoveries. Here, we ask to what extent AI can be described as a “general method of invention,” which could open up new paradigms and directions of scientific investigations. Hence, complementary to a purely representational and architectural viewpoint of AI4Science, we find it constructive to ask and assess to what extent the nature of the scientific process, both its inductive and deductive components, can and should be transformed by AI techniques.",
      "section": "Introduction",
      "topic": "LLMs and the Scientific Process",
      "chunk_summary": "This review focuses on LLMs as tools for the scientific process, exploring their potential to synthesize information, generate hypotheses, and drive fundamental discoveries, considering how AI can transform both inductive and deductive aspects of science.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "The ability of Large Language Models (LLMs) to process and generate human-like text, handle vast amounts of data, and analyse complex patterns with potentially some reasoning capabilities has increasingly set the stage for them to be used in scientific research across various disciplines. Their applications range from simple tasks, such as acting as copilots to assist scientists, to complex tasks, such as autonomously performing experiments and proposing novel hypotheses. We will first introduce the fundamental concepts of LLMs and then review their various applications in scientific discovery.",
      "section": "Current use of LLMs – From Specialised Scientific Copilots to LLM-assisted Scientific Discoveries",
      "topic": "LLMs in Scientific Research",
      "chunk_summary": "LLMs are increasingly used in scientific research, ranging from simple tasks like assisting scientists to complex tasks like autonomous experimentation and hypothesis generation.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Current mainstream LLMs are primarily conditional generative models, where the input, such as the beginning of a sentence or instructions, serves as a condition, and the output is the generated text, such as a reply. This text is typically sampled auto-regressively: the next token (considered the building block of words) is sampled from a predicted distribution. See Figure 1A. Given LLMs' capabilities in computation and emerging potential for reasoning, which we define as the ability to solve tasks that require reasoning, they can be considered programming languages that use human language as the code that instructs them to perform desired tasks. This code takes the form of “prompts.” For instruct-tuned LLMs, the prompt often consists of three parts: the system prompt and the user prompt, with an LLM's reply considered the assistant prompt. Hence, a chat is frequently composed of <system><user><assistant><user><assistant>, see Figure 1B. The system prompt typically includes general instructions for the LLMs, such as behaviour, meta-information, format, etc. The user prompt usually contains detailed instructions and questions. Using these prompts, the LLMs generate replies under the role of \"assistant.\"",
      "section": "Prompting LLMs: From Chatbot to Prompt Engineering",
      "topic": "LLM Prompting",
      "chunk_summary": "LLMs are conditional generative models driven by prompts, which act as code in a human language programming language, with instruct-tuned LLMs using system, user, and assistant prompts.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Since LLMs do not have background knowledge about the user, and prompts are their major input, designing a good prompt is often critical to achieving the desired output and superior performance. Researchers have shown that specific prompts, including accuracy, creativity, and reasoning, can significantly improve output performance. Specifically, the chain-of-thought (CoT) method44 can instruct LLMs to think step-by-step, leading to better results. Beyond these, the Retrieval-augmented Generation (RAG) method45 can incorporate a large amount of context by indexing the contents and retrieving relevant materials, then combining the retrieved information with prompts to generate the output. Due to the importance of prompts and LLM agents, designing prompts is now often called \"prompt engineering,” and many techniques and tricks have been developed in this area46,47, such as asking JSON format outputs, formulating clear instructions, setting temperatures, etc47,48.",
      "section": "Prompting LLMs: From Chatbot to Prompt Engineering",
      "topic": "Prompt Engineering",
      "chunk_summary": "Effective prompt design, or prompt engineering, is crucial for achieving desired LLM outputs, with techniques like chain-of-thought and retrieval-augmented generation improving performance.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "While carefully designed prompts can accomplish many tasks, they are not robust and reliable enough for complex tasks requiring multiple steps or non-language computations, nor can they explore autonomously. LLM agents are developed for these requirements, especially for complex tasks. LLM agents are autonomous systems powered by LLMs, which can actively seek to observe environments, make decisions, and perform actions using external tools49. In many cases, we need to ensure reliability, achieve high-performance levels, enable automation, or process large amounts of context. These tasks cannot be accomplished solely with LLMs and require integrating LLMs into agent systems. Early examples include AutoGPT50 and BabyAGI51, where LLMs are treated as essential tools within the agent system (Figure 1C). In scientific discovery, LLM agents become even more critical due to the complexity of science and its high-performance requirements. Many tools have also been developed to provide easy access to these prompting and agent methods, such as LangChain52 and LlamaIndex53. Automated prompt design methods, such as DSPy54 and TextGrad55, are also being developed to design prompts and LLM agents in a data-driven way.",
      "section": "Prompting LLMs: From Chatbot to Prompt Engineering",
      "topic": "LLM Agents",
      "chunk_summary": "For complex scientific tasks, LLM agents, autonomous systems powered by LLMs and capable of interacting with external tools, are necessary, with tools like LangChain and LlamaIndex facilitating their use.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "The ability of LLMs to work with a large body of text is being exploited in the practice of science. For example, LLMs assist in proposing novel ideas, writing scientific papers and generating computer code, thereby improving productivity; they also adapt texts for diverse audiences ranging from experts to broader audiences, thus supporting communication in science. Furthermore, LLMs can sift through vast bodies of scientific literature to identify relevant papers, findings, and trends. Such reviewing of the relevant literature helps investigators quickly digest and identify gaps in enormous bodies of knowledge. These capabilities can also mitigate discursive barriers across different scientific fields, supporting interdisciplinary scientific collaborations and knowledge sharing. Recently, chatbots have emerged in several disciplines as virtual assistants answering scientific queries posed by scientists. Such tools exploit the power of LLMs to extract and detect patterns, data, and knowledge. These techniques may also serve as important tools in science education and communication.",
      "section": "LLMs as Practical Scientific Copilots",
      "topic": "LLMs for Scientific Literature Review",
      "chunk_summary": "LLMs are used in science for tasks like proposing ideas, writing papers, generating code, reviewing literature, and facilitating interdisciplinary collaboration.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "These examples demonstrate the rise of LLMs in extracting and sharing information and the exciting open research frontier of the potential of reasoning that they represent in different scientific domains56–58. For instance, Caufield et al. proposed the SPIRES method59, which uses LLMs to extract structured data from the literature. Beyond data extraction, LLMs have also shown evidence of outperforming annotation tasks60,61, enabling scientists to scale data annotation. Some domain-specific models also show superior performance in classification, annotation, and prediction tasks62–64. With the help of RAG methods45, LLMs can directly apply their information extraction and distillation capabilities to large amounts of text data. With the combination of diverse capabilities of LLMs interconnected through LLM-agents, the recent “AI co-scientist65” demonstrates impressive ability in generating novel research ideas by leveraging existing literature, engaging in internal LLM-agent debates, and refining its outputs. This process leads to constructive progress when applied to real scientific tasks.",
      "section": "LLMs as Practical Scientific Copilots",
      "topic": "LLMs for Data Extraction and Annotation",
      "chunk_summary": "LLMs are increasingly used for extracting structured data, outperforming humans in annotation tasks, and generating novel research ideas through LLM-agent interactions.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Moreover, LLMs are currently used to automate the experimental design and the execution of experiments. For example, Boiko, et al.66 propose an autonomous LLM capable of performing chemical experiments. This work employs an LLM planner to manage the experimental process, such as drawing patterns on plates or conducting more complex chemical syntheses. Compared to hard-coded planners, the LLM-based planner is more flexible and can handle unexpected situations. Similar kinds of loop and tool usage are also shown in67, which includes literature tools, consulting with humans, experimental tools, and safety tools. In the biological domain, for instance, the CRISPR-GPT68 represents a significant advancement in biological research. It utilizes LLMs to automate the design of gene-editing experiments, enhancing both the efficiency and precision of genetic modifications, which is pivotal in speeding up genomic research and applications. Another advance in the application of LLMs in the biological domain is BioDiscoveryAgent69. These tools augment scientists' capabilities and accelerate scientific discovery. The capabilities described thus far capture the current use of LLMs as knowledge engines. Summarising, extracting, interfacing, and reasoning about (scientific) text, alongside automating experimental design and execution. While immensely useful, it remains an open frontier on how to do this safely and efficiently. It largely depends on how prompting is performed and how LLM agent systems are designed.",
      "section": "LLMs as Practical Scientific Copilots",
      "topic": "LLMs for Experimental Design and Automation",
      "chunk_summary": "LLMs are used to automate experimental design and execution in various scientific domains, including chemistry and biology, with examples like CRISPR-GPT and BioDiscoveryAgent, but safety and efficiency remain open challenges.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_735373.pdf",
      "original_filename": "pdf_20250803_124125_735373_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Levin, Jeremy\", \"Khan, Adnan Mahmud\", \"James Evans\", \"Alexander Lavin\", \"Michael Sumner\", \"Alan Bundy\", \"Saso Dzeroski\", \"Jesper Tegner\", \"Hector Zenil\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    }
  ],
  "gemini_response": "",
  "processed_at": "2025-08-06T12:40:25.504650"
}