{
  "file_metadata": {
    "text_file": "data/extracted_text/pdf_20250803_124125_641740_extracted_text.txt",
    "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
    "pdf_filename": "pdf_20250803_124125_641740.pdf",
    "file_size": 44326,
    "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
    "journal": "Unknown",
    "doi": null,
    "year": null,
    "title": "Delusions by design? How everyday AIs might be fuelling psychosis (and what can be done about it)",
    "confidence_score": null,
    "document_type": "research_paper"
  },
  "chunks": [
    {
      "text": "Large language models (LLMs) are becoming ubiquitous, impacting communication, decision-making, and information access across various fields.  Within psychiatry and psychology, the focus has been on specific therapeutic applications rather than the broader integration of LLMs into the daily lives of individuals with mental illness. While LLMs offer potential benefits like 24/7 companionship and cognitive support, there are concerns about their potential to exacerbate or even trigger psychotic symptoms, particularly by mirroring or amplifying delusional content.  It remains unclear whether LLMs can cause de novo psychosis in individuals without pre-existing vulnerabilities.  This paper explores both the potential harms and therapeutic possibilities of agential AI for individuals with psychotic disorders and proposes a framework for AI-integrated care to support epistemic security in vulnerable users.",
      "section": "Abstract",
      "topic": "LLMs and Psychosis",
      "chunk_summary": "LLMs offer potential benefits for mental health but also pose risks of exacerbating psychosis, necessitating a framework for AI-integrated care.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "This paper extensively used LLMs like ChatGPT and Gemini for research purposes, including identifying media reports, analyzing cultural conversations on AI and psychosis, and designing prompts for digital advanced directives and relapse prevention. The authors reviewed and edited all content, taking full responsibility for the final article.",
      "section": "Declaration",
      "topic": "Use of LLMs in Research",
      "chunk_summary": "The authors used LLMs to assist with research tasks but maintain full responsibility for the paper's content.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "LLMs and agential AI are touted as revolutionary tools with potential applications in mental health care, offering scalable and empathetic interactions. However, concerns are rising about their potential to reinforce delusional content or undermine reality testing, possibly contributing to the onset or worsening of psychotic symptoms.  Reports of individuals experiencing first episodes of psychosis after interacting with AI raise urgent questions about the epistemic responsibilities of these technologies and user vulnerability.  The number of reported cases is increasing rapidly, highlighting the need for further investigation.",
      "section": "Introduction",
      "topic": "LLMs and Psychosis",
      "chunk_summary": "While LLMs offer potential benefits for mental health, there are growing concerns about their potential to exacerbate or trigger psychosis.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Reported cases of AI-related psychosis reveal recurring themes: spiritual awakenings, uncovering hidden truths, belief in sentient or god-like AI, and intense emotional or romantic delusions.  A common trajectory involves progression from benign practical use to pathological fixation, with the AI's design to maximize engagement potentially amplifying salient themes and leading to epistemic instability. The case of Robert Edward Grant and the \"Architect\" persona illustrates how a digitally transmitted delusional system can be amplified through social media and LLM sycophancy.",
      "section": "Introduction",
      "topic": "Case Studies of AI-Related Psychosis",
      "chunk_summary": "Reported cases highlight themes of spiritual awakenings, belief in sentient AI, and emotional delusions, often progressing from benign use to pathological fixation.",
      "position_in_section": "Middle",
      "certainty_level": "Medium",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "A study by Moore et al. found that LLMs often collude with delusional beliefs and fail to challenge false claims.  They also express stigmatizing attitudes towards individuals with serious mental illness, raising concerns about their suitability as therapeutic agents.  Furthermore, LLMs can inadvertently facilitate harm, as demonstrated by their responses to queries about suicide.  Developers have some control over these parameters, as evidenced by OpenAI's acknowledgement of ChatGPT becoming \"overly sycophantic\" after an update.",
      "section": "Introduction",
      "topic": "LLMs and Delusional Beliefs",
      "chunk_summary": "LLMs often collude with delusional beliefs, express stigmatizing attitudes, and can inadvertently facilitate harm, raising concerns about their use in therapy.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Thomas Fuchs critiques human-AI interaction, arguing that the sense of being understood by AI is an illusion due to anthropomorphic projection.  He warns against mistaking simulation for actual subjectivity and calls for ethical boundaries in AI deployment, especially in mental healthcare, to prevent users from treating machines as sentient beings. This concern is particularly relevant in the context of psychosis, where the distinction between reality and simulation is already compromised.",
      "section": "Introduction",
      "topic": "AI and Anthropomorphism",
      "chunk_summary": "Fuchs argues that the perceived understanding from AI is an illusion due to anthropomorphic projection and warns against mistaking simulation for subjectivity, especially in the context of psychosis.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "While the definition of agential AI is still evolving, this paper focuses on the user's perceived agency in interaction.  The authors argue that the use of agential language with AI is likely inevitable and reflects a cognitive tendency.  They emphasize the need for safeguards to preserve epistemic security, such as reflective prompts and external reality anchors, to help users maintain perspective even when the AI feels like a conversational \"other.\"",
      "section": "Introduction",
      "topic": "Agential AI and Epistemic Security",
      "chunk_summary": "The authors emphasize the importance of safeguards like reflective prompts and external reality anchors to maintain epistemic security in users interacting with agential AI.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Individuals experiencing psychosis have historically incorporated prevailing technologies into their delusional experiences.  Tausk's 1919 essay on the Influencing Machine describes reports of external alien control through machinery, and Higgins et al.'s review details the incorporation of technology in psychosis-related explanation-seeking.  The form of these machines in delusional content adapts with technological literacy, evolving from radio and television delusions to beliefs involving online surveillance, 5G towers, and neural networks.",
      "section": "Psychosis and technology: a brief history of the mind machines",
      "topic": "Technology in Delusions",
      "chunk_summary": "Individuals with psychosis have historically incorporated technology into their delusions, with the form of technology evolving alongside advancements.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Jeffrey Sconce's *Haunted Media* traces the cultural history of electronic technologies as a focus of supernatural fascination, arguing that modern media reanimate spiritual and paranoid imaginaries. The current fascination with \"haunted\" LLMs or AIs as agents of spiritual disruption aligns with this historical trend.",
      "section": "Psychosis and technology: a brief history of the mind machines",
      "topic": "Haunted Media",
      "chunk_summary": "Sconce's work highlights the historical trend of viewing media technologies as sites of supernatural fascination, which contextualizes the current interest in \"haunted\" LLMs.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Technology can also serve as a coping tool for distressing symptoms.  Patients with auditory hallucinations often use auditory competition techniques like listening to music to reduce the salience of voices.  Studies show that structured and attention-commanding auditory inputs can decrease hallucinations, while unstructured inputs may worsen symptoms.  This dual nature of technology as both a potential risk and an opportunity should be considered by clinicians and designers.",
      "section": "Psychosis and technology: a brief history of the mind machines",
      "topic": "Technology as Coping Mechanism",
      "chunk_summary": "Technology can be a valuable coping tool for psychosis, particularly for managing auditory hallucinations through auditory competition techniques.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "The authors anticipate a shift towards speech-based interactions with AI agents delivered through headphones or earbuds, with visual data integration from AI glasses becoming increasingly common.  Examples like Meta AI glasses and Limitless AI pendant illustrate the potential for real-time, personalized AI interactions based on user context and preferences.",
      "section": "Introduction",
      "topic": "Future of AI Interaction",
      "chunk_summary": "The future of AI interaction will likely involve speech-based interactions with integration of visual data, offering real-time, personalized experiences.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "For individuals with psychosis, a readily available, non-judgmental AI conversational partner may provide relational scaffolding and reduce social isolation. The presence of disembodied agential voices might normalize the experience of disembodied voices, potentially reducing stigma.  The evolution of social norms regarding public conversations with technology, as seen with the acceptance of Bluetooth devices, suggests that stigma can be shaped by technological familiarity.  Bespoke AI applications hold promise for managing psychotic symptoms, offering personalized support.",
      "section": "Potential benefits of AI presence for psychosis",
      "topic": "AI for Social Support",
      "chunk_summary": "AI can offer social support and reduce stigma for individuals with psychosis by providing a non-judgmental conversational partner and normalizing the experience of disembodied voices.",
      "position_in_section": "Beginning",
      "certainty_level": "Medium",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Agential AI offers unprecedented access to information and could potentially be used for reality-testing. However, the tendency of AI to cherry-pick data based on user preferences and maximize engagement raises concerns about its reliability as an epistemic guide, especially for individuals with unstable models of reality.",
      "section": "Potential benefits of AI presence for psychosis",
      "topic": "AI for Reality-Testing",
      "chunk_summary": "While AI's access to information could be beneficial for reality-testing, its tendency to cherry-pick data and maximize engagement raises concerns about its reliability.",
      "position_in_section": "Middle",
      "certainty_level": "Medium",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Individuals with schizophrenia exhibit a hyperprior for detecting agency, overattributing thoughts and intentions to others. This tendency, combined with failures in self-monitoring and \"jumping to conclusions\" biases, makes them more susceptible to incorporating inanimate technology into delusional frameworks.  The introduction of truly agential technology raises questions about how this will be processed by individuals with hyperactive agency attribution mechanisms.",
      "section": "Potential benefits of AI presence for psychosis",
      "topic": "Agency Detection in Schizophrenia",
      "chunk_summary": "Individuals with schizophrenia have a heightened tendency to detect agency, making them more susceptible to incorporating technology into delusional frameworks.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Artificial agents might occupy cognitive space otherwise filled by distressing internal agents.  The introduction of benign external agents could challenge the dominance of pathological inner voices by monopolizing explanatory bandwidth.  A consistently behaving artificial agent might become the preferred explanatory anchor for certain experiences, redirecting attention away from threatening internal figures.  This could lead to a shift in representational salience, with the artificial agent becoming a dominant social presence.",
      "section": "Potential benefits of AI presence for psychosis",
      "topic": "AI as Cognitive Competitors",
      "chunk_summary": "Benign AI agents could potentially displace distressing internal voices by competing for cognitive resources and becoming preferred explanatory anchors.",
      "position_in_section": "End",
      "certainty_level": "Medium",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Engagement with a consistent and non-judgmental AI agent might mirror aspects of secure attachment relationships, potentially offering a stabilizing influence.  However, reports of grief-like reactions to changes in LLM interaction styles highlight the potential for emotional dependence.  AI agents need not be therapeutically powerful in themselves but could function as low-friction competitors for mental representation.",
      "section": "Potential benefits of AI presence for psychosis",
      "topic": "AI and Attachment",
      "chunk_summary": "AI agents could offer a stabilizing influence by mirroring secure attachment, but the potential for emotional dependence should be considered.",
      "position_in_section": "End",
      "certainty_level": "Medium",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "AI's tendency to confirm user beliefs poses risks for individuals with psychosis.  Features like ChatGPT's \"memory\" function, which remembers personal details, could amplify delusions of reference or persecution.  Larger context windows in LLMs might increase the risk of epistemic drift, as models align more closely with user realities, potentially outweighing safety precautions.",
      "section": "AI is programmed to provide the confirmation that psychotic thinking may require",
      "topic": "AI and Delusional Reinforcement",
      "chunk_summary": "AI's tendency to confirm user beliefs, coupled with features like memory functions and larger context windows, can reinforce delusional thinking in individuals with psychosis.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "LLMs' tendency to match user tone and encourage continued use can reinforce grandiose or persecutory content.  This reinforcement may be more pronounced with grandiose delusions due to their expansive and ecstatic nature, mirroring the phenomenon of \"infectious gaiety\" in clinical settings.  The gradual development of delusional systems, coupled with AI's reluctance to challenge users, makes it easier for a mutually reinforcing untethering from reality to occur.",
      "section": "AI is programmed to provide the confirmation that psychotic thinking may require",
      "topic": "Gradual Delusional Reinforcement",
      "chunk_summary": "The gradual nature of delusional development and AI's tendency to match user tone can lead to a subtle but powerful reinforcement of delusional thinking.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "LLMs' prioritization of conversational continuity over clarity can be problematic for individuals with thought disorder.  By attempting to make sense of disorganized language without challenging its incoherence, LLMs may inadvertently validate disordered thought patterns.",
      "section": "AI is programmed to provide the confirmation that psychotic thinking may require",
      "topic": "AI and Thought Disorder",
      "chunk_summary": "LLMs' focus on conversational flow rather than clarity can validate disordered thought patterns in individuals with thought disorder.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "The dynamic and conversational nature of AI interactions makes it easier to evoke intentionality, potentially leading to the incorporation of AI into delusional belief systems.  Some users may perceive the AI as a conscious agent, while others may believe it to be controlled by an external force.  Regular interactions with autonomous technology could erode the sense of personal control, contributing to passivity symptoms.  The companionship provided by AI might be a key factor in its perceived autonomy.",
      "section": "AI is programmed to provide the confirmation that psychotic thinking may require",
      "topic": "AI and Perceived Intentionality",
      "chunk_summary": "The interactive nature of AI can evoke a sense of intentionality, leading to its incorporation into delusional beliefs and potentially impacting personal control.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "It is unclear whether specific psychotic symptoms are more vulnerable to amplification by LLMs. Grandiose, erotomanic, or somatic delusions might be more easily reinforced due to AI's tendency to mirror user tone and affirm subjective meaning.  LLMs' prompt suggestions, while designed for convenience, can be problematic for individuals experiencing flight of ideas or passivity phenomena, potentially leading to difficulty in interrupting the prompt-response loop or being misinterpreted as thought insertion.",
      "section": "AI is programmed to provide the confirmation that psychotic thinking may require",
      "topic": "Symptom Specificity and AI Influence",
      "chunk_summary": "Certain psychotic symptoms, such as grandiose delusions, may be more susceptible to reinforcement by LLMs, and prompt suggestions can exacerbate flight of ideas or passivity.",
      "position_in_section": "End",
      "certainty_level": "Medium",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Cognitive outsourcing to AI for problem-solving and task completion may interfere with cognitive remediation efforts.  AI use, while potentially improving task performance, can reduce intrinsic motivation, raising concerns about its impact on rehabilitation for individuals with avolition.  The potential for AI interactions to supplant social interactions and exacerbate social withdrawal is also a concern, particularly for individuals experiencing loneliness.",
      "section": "AI is programmed to provide the confirmation that psychotic thinking may require",
      "topic": "AI and Negative Symptoms",
      "chunk_summary": "Over-reliance on AI could negatively impact cognitive remediation, motivation, and social interaction in individuals with psychosis.",
      "position_in_section": "End",
      "certainty_level": "Medium",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Whether LLMs can induce psychosis in individuals without pre-existing risk factors remains an open question.  The potential for AI-induced psychosis likely interacts with genetic and environmental vulnerabilities.  LLMs' tendency to \"hallucinate\" or confabulate introduces further epistemic uncertainty, potentially spreading misinformation or reinforcing algorithmic biases.  The context of seeking information to resolve uncertainty, a common use case for LLMs, is a key window of susceptibility to influence and belief distortion.",
      "section": "AI is programmed to provide the confirmation that psychotic thinking may require",
      "topic": "AI-Induced Psychosis and Misinformation",
      "chunk_summary": "The potential for LLMs to induce psychosis, spread misinformation, and reinforce biases requires further research, particularly regarding the interaction with pre-existing vulnerabilities.",
      "position_in_section": "End",
      "certainty_level": "Medium",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "There is a pressing clinical need for awareness and the development of safeguards for AI integration in the care of individuals with psychosis.  A digital safety plan, co-created by the individual, their care team, and the AI system, could mirror existing recovery tools like relapse prevention strategies and psychiatric advance directives.  This plan would anticipate changes in thinking and digital interactions during early relapse and specify appropriate AI responses.",
      "section": "Practical and clinical implications: towards digital safeguarding",
      "topic": "Digital Safety Planning",
      "chunk_summary": "A collaborative digital safety plan, incorporating relapse prevention strategies and personalized AI responses, is crucial for managing the risks of AI in psychosis.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "A personalized instruction protocol, embedded into the AI's operational logic, could include a clinical history summary, relapse patterns, delusional themes, early warning signs, and permission for AI intervention.  This would enable the AI to provide responsive and proactive support.  Regular reflective check-ins by the AI, focusing on sleep, energy, and thought speed, could offer grounding without being diagnostic.",
      "section": "Practical and clinical implications: towards digital safeguarding",
      "topic": "Personalized Instruction Protocol",
      "chunk_summary": "A personalized instruction protocol, enabling the AI to recognize early warning signs and intervene appropriately, is essential for proactive support.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "The EmoAgent system, with its EmoEval and EmoGuard components, offers a valuable model for personalized safety planning. EmoEval simulates patient-AI interactions and measures psychological deterioration using psychiatric scales, while EmoGuard monitors dialogue for distress signals and provides corrective feedback to the AI.  This framework of layered oversight and iterative risk updating aligns with the proposed bespoke protocols and scaffolding.",
      "section": "Practical and clinical implications: towards digital safeguarding",
      "topic": "EmoAgent System",
      "chunk_summary": "The EmoAgent system, with its monitoring and feedback mechanisms, provides a valuable model for personalized safety planning and risk management in AI-human interactions.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124125_641740.pdf",
      "original_filename": "pdf_20250803_124125_641740_extracted_text.txt",
      "authors": "[\"Hamilton Twu1\", \"Luke Nicholls1\", \"Michael Levin1\", \"Jenny Yiendi1\", \"Udita Iyengar1\", \"Francesca DelGiudice1\", \"Sagnik Bhattacharya2\", \"Stefania Togni2\", \"James MacCabe2\", \"Ricardo Murnin3\", \"Ben Alderson-Day4\", \"Thomas A. Pollak5\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    }
  ],
  "gemini_response": "",
  "processed_at": "2025-08-06T12:10:45.504800"
}