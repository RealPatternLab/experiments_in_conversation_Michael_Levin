{
  "file_metadata": {
    "text_file": "data/extracted_text/pdf_20250803_124126_558737_extracted_text.txt",
    "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
    "pdf_filename": "pdf_20250803_124126_558737.pdf",
    "file_size": 36984,
    "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
    "journal": "Unknown",
    "doi": null,
    "year": null,
    "title": "Diffusion Models are Evolutionary Algorithms",
    "confidence_score": null,
    "document_type": "research_paper"
  },
  "chunks": [
    {
      "text": "In a convergence of machine learning and biology, we reveal that diffusion models are evolutionary algorithms. By considering evolution as a denoising process and reversed evolution as diffusion, we mathematically demonstrate that diffusion models inherently perform evolutionary algorithms, naturally encompassing selection, mutation, and reproductive isolation. Building on this equivalence, we propose the Diffusion Evolution method: an evolutionary algorithm utilizing iterative denoising, as originally introduced in the context of diffusion models, to heuristically refine solutions in parameter spaces. Unlike traditional approaches, Diffusion Evolution efficiently identifies multiple optimal solutions and outperforms prominent mainstream evolutionary algorithms. Furthermore, leveraging advanced concepts from diffusion models, namely latent space diffusion and accelerated sampling, we introduce Latent Space Diffusion Evolution, which finds solutions for evolutionary tasks in high-dimensional complex parameter space while significantly reducing computational steps. This parallel between diffusion and evolution not only bridges two different fields but also opens new avenues for mutual enhancement, raising questions about open-ended evolution and potentially utilizing non-Gaussian or discrete diffusion models in the context of Diffusion Evolution.",
      "section": "Abstract",
      "topic": "Diffusion Models as Evolutionary Algorithms",
      "chunk_summary": "Diffusion models are mathematically equivalent to evolutionary algorithms, incorporating selection, mutation, and reproductive isolation, leading to a novel Diffusion Evolution method that outperforms traditional evolutionary algorithms.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "At least two processes in the biosphere have been recognized as capable of generalizing and driving novelty: evolution, a slow variational process adapting organisms across generations to their environment through natural selection (Darwin, 1959; Dawkins, 2016); and learning, a faster transformational process allowing individuals to acquire knowledge and generalize from subjective experience during their lifetime (Kandel, 2013; Courville et al., 2006; Holland, 2000; Dayan & Abbott, 2001). These processes are intensively studied in distinct domains within artificial intelligence. Relatively recent work has started drawing parallels between the seemingly unrelated processes of evolution and learning (Watson & Levin, 2023; Vanchurin et al., 2022; Levin, 2022; Watson et al., 2022; Kouvaris et al., 2017; Watson & Szathmáry, 2016; Watson et al., 2016; Power et al., 2015; Hinton et al., 1987; Baldwin, 2018). We here argue that, in particular, diffusion models (Sohl-Dickstein et al., 2015; Song et al., 2020b; Ho et al., 2020; Song et al., 2020a), where generative models are trained to sample data points through incremental stochastic denoising, can be understood through evolutionary processes, inherently performing natural selection, mutation, and reproductive isolation.",
      "section": "Introduction",
      "topic": "Evolution and Learning",
      "chunk_summary": "Evolution and learning, two distinct processes driving novelty in the biosphere, are being increasingly linked, with diffusion models offering a potential framework for understanding their interplay.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "The evolutionary process is fundamental to biology, enabling species to adapt to changing environments through mechanisms like natural selection, genetic mutations, and hybridizations (Rosen, 1991; Wagner, 2015; Dawkins, 1996); this adaptive process introduces variations in organisms' genetic codes over time, leading to well-adapted and diverse individuals (Mitchell & Cheney, 2024; Levin, 2023; Gould, 2002; Dennett, 1995; Smith & Szathmary, 1997; Szathmáry, 2015). Evolutionary algorithms utilize such biologically inspired variational principles to iteratively refine sets of numerical parameters that encode potential solutions to often rugged objective functions (Vikhar, 2016; Golberg, 1989; Grefenstette, 1993; Holland, 1992). On the other hand, recent breakthroughs in deep learning have led to the development of diffusion models—generative algorithms that iteratively refine data points to sample novel yet realistic data following complex target distributions: models like Stable Diffusion (Rombach et al., 2022) and Sora (Brooks et al., 2024) demonstrate remarkable realism and diversity in generating image and video. Notably, both evolutionary processes and diffusion models rely on iterative refinements that combine directed updates with undirected perturbations: in evolution, random genetic mutations introduce diversity while natural selection guides populations toward greater fitness, and in diffusion models, random noise is progressively transformed into meaningful data through learned denoising steps that steer samples toward the target distribution. This parallel raises fundamental questions: Are the mechanisms underlying evolution and diffusion models fundamentally connected? Is this similarity merely an analogy, or does it reflect a deeper mathematical duality between biological evolution and generative modeling?",
      "section": "Introduction",
      "topic": "Evolutionary Algorithms and Diffusion Models",
      "chunk_summary": "Both evolutionary processes and diffusion models utilize iterative refinements with directed updates and undirected perturbations, raising questions about a potential fundamental connection between them.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "To answer these questions, we first examine evolution from the perspective of generative models. By considering populations of species in the biosphere, the variational evolution process can also be viewed as a transformation of distributions: the distributions of genotypes and phenotypes. Over evolutionary time scales, mutation and selection collectively alter the shape of these distributions. Similarly, many biologically inspired evolutionary algorithms can be understood in the same way: they optimize an objective function by maintaining and iteratively changing a large population's distribution. In fact, this concept is central to most generative models: the transformation of distributions. Variational Autoencoders (VAEs) (Kingma, 2013), Generative Adversarial Networks (GANs) (Goodfellow et al., 2014), and diffusion models are all trained to transform simple distributions, typically standard Gaussian distributions, into complex distributions, where the samples represent meaningful images, videos, or audio, etc.",
      "section": "Introduction",
      "topic": "Evolution as a Generative Process",
      "chunk_summary": "Evolution can be viewed as a transformation of genotype and phenotype distributions, similar to how generative models transform simple distributions into complex ones.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "On the other hand, diffusion models can also be viewed from an evolutionary perspective. As a generative model, diffusion models transform Gaussian distributions in an iterative manner into complex, structured data points that resemble the training data distribution. During the training phase, the data points are corrupted by adding noise, and the model is trained to predict this added noise to reverse the process. In the sampling phase, starting with Gaussian-distributed data points, the model iteratively denoises to incrementally refine the data point samples. By considering noise-free samples as the desired outcome, such a directed denoising can be interpreted as directed selection, with each step introducing slight noise, akin to mutations. Together, this resembles an evolutionary process (Fields & Levin, 2020), where evolution is formulated as a combination of deterministic dynamics and stochastic mutations within the framework of non-equilibrium thermodynamics (Ao, 2005). This aligns with recent ideas that interpret the genome as a latent space parameterization of a multi-scale generative morphogenetic process, rather than a direct blueprint of an organism (Mitchell & Cheney, 2024; Hartl et al., 2024; Levin, 2023; Gould, 2002). If one were to revert the time direction of an evolutionary process, the evolved population of potentially highly correlated high-fitness solutions will dissolve gradually, i.e., step by step and thus akin to the forward process in diffusion models, into the respectively chosen initial distribution, typically Gaussian noise (see Figure 1).",
      "section": "Introduction",
      "topic": "Diffusion Models as Evolutionary Processes",
      "chunk_summary": "Diffusion models' iterative denoising can be interpreted as directed selection with mutations, aligning with the view of evolution as a combination of deterministic and stochastic dynamics.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Driven by this intuition, we conduct a thorough investigation into the connections between diffusion models and evolutionary algorithms, discovering that these seemingly disparate concepts share the same mathematical foundations. This insight leads to a novel approach, the Diffusion Evolution algorithm, which directly utilizes the framework of diffusion models to perform evolutionary optimization. This can be obtained by inverting the diffusion process with the Bayesian method. Our analytical study of Diffusion Evolution reveals promising parallels to biological evolution, naturally incorporating concepts such as mutation, hybridization, and even reproductive isolation.",
      "section": "Introduction",
      "topic": "Diffusion Evolution Algorithm",
      "chunk_summary": "The mathematical connection between diffusion models and evolutionary algorithms leads to the Diffusion Evolution algorithm, which uses the diffusion model framework for evolutionary optimization, incorporating mutation, hybridization, and reproductive isolation.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "This equivalence provides a new way of improving evolutionary algorithms and has the potential to unify developments in both fields. By mimicking biological evolution, evolutionary algorithms have shown promising results in numerical optimization, particularly for tasks that cannot be effectively trained using gradient-based methods (Wang et al., 2024; Goodfellow et al., 2014). These algorithms thus excel in exploring complex, rugged search spaces and finding globally optimal or near-optimal solutions (Ho & Salimans, 2022; Hansen, 2016; Hansen & Ostermeier, 2001; Sehnke et al., 2010). While the biosphere exhibits extreme diversity in lifeforms, many evolutionary strategies, such as CMA-ES (Hansen & Ostermeier, 2001) and PEPG (Sehnke et al., 2010), struggle to find diverse solutions (Lehman & Stanley, 2011). However, our Diffusion Evolution Algorithm offers a new approach. By naturally incorporating mutation, hybridization, and reproductive isolation, our algorithm can discover diverse solutions, mirroring the diversity of the biosphere, rather than converging on a single solution as is often the case with traditional methods. Since this parallel between diffusion and evolution exists naturally and not imposed by our design, the two fields—diffusion models and evolutionary computing—can mutually benefit from each other. For example, we demonstrate that the concept of latent diffusion (Rombach et al., 2022) and accelerated sampling (Nichol & Dhariwal, 2021) can significantly improve the performance of our Diffusion Evolution algorithm.",
      "section": "Introduction",
      "topic": "Benefits of Diffusion Evolution",
      "chunk_summary": "The equivalence between diffusion and evolution allows for mutual improvements, with Diffusion Evolution offering increased diversity and the potential for integration with latent diffusion and accelerated sampling.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "In the following sections, we will first review evolutionary strategies and diffusion models, introduce the mathematical connection between diffusion and evolution, and propose the Diffusion Evolution algorithm. Then, we will quantitatively compare our algorithm to conventional evolutionary strategies, demonstrating its capability to find multiple solutions, solve complex evolutionary tasks, and incorporate developments from diffusion model literature. Finally, the emerging connections between the derived algorithm and evolution will be discussed, along with the potentials of this finding and the limitations of our algorithm. Codes are available on Github² and the package can be installed via `pip install diffevo`.",
      "section": "Introduction",
      "topic": "Paper Overview",
      "chunk_summary": "The paper will review evolutionary strategies and diffusion models, introduce the Diffusion Evolution algorithm, compare it to conventional methods, and discuss its potential and limitations.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "None",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "The principles of evolution extend far beyond biology, offering exceptional utility in addressing complex systems across various domains. The key components of this process—imperfect replication with heredity and fitness-based selection—are sufficiently general to find applications in diverse fields. In computer and data science, for instance, evolutionary algorithms play a crucial role in optimization (Vikhar, 2016; Grefenstette, 1993; Golberg, 1989; Holland, 1992). These heuristic numerical techniques, such as CMA-ES (Hansen & Ostermeier, 2001) and PEPG (Sehnke et al., 2010), maintain and optimize a population of genotypic parameters over successive generations through operations inspired by biological evolution, such as selection of the fittest, reproduction, genetic crossover, and mutations. The goal is to gradually adapt the parameters of the entire population so individual genotypic samples, or short individuals, perform well when evaluated against an objective or fitness function. These algorithms harness the dynamics of evolutionary biology to discover optimal or near-optimal solutions within vast, complex, and otherwise intractable parameter spaces. The evaluated numerical fitness score of an individual correlates with its probability of survival and reproduction, ensuring that individuals with superior traits have a greater chance of passing their genetic information to the next generation, thus driving the evolutionary process toward more optimal solutions. Such approaches are particularly valuable when heuristic solutions are needed to explore extensive combinatorial and permutation landscapes.",
      "section": "Background",
      "topic": "Evolutionary Algorithms",
      "chunk_summary": "Evolutionary algorithms, inspired by biological evolution, are heuristic numerical techniques used for optimization in complex parameter spaces, utilizing selection, reproduction, crossover, and mutations to improve fitness over generations.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Some evolutionary algorithms operate with discrete, others with continuous sets of parameters. Here, we focus on the latter since discrete tasks can be seen as a subcategory of continuous tasks. Typically, the structure of the parameter space is a priori unknown. Thus, the initial population is often sampled from a standard normal distribution. As explained above, this initially random population is successively adapted and refined, generation by generation, to perform well on an arbitrary objective function. Thus, initially randomized parameters are successively varied by evolutionary algorithms into sets of potentially highly structured parameters that perform well on the specified task, eventually (and hopefully) solving the designated problem by optimizing the objective function. Thus, evolutionary algorithms can be understood as generative models that use heuristic information about already explored regions of the parameter space (at least from the previous generation) to sample potentially better-adapted offspring individuals for the next generation (cf., CMA-ES (Hansen et al., 2003), etc.).",
      "section": "Background",
      "topic": "Evolutionary Algorithms as Generative Models",
      "chunk_summary": "Evolutionary algorithms can be viewed as generative models that iteratively refine parameters based on heuristic information from explored regions of the parameter space to produce better-adapted offspring.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Diffusion models, such as denoising diffusion probabilistic models (DDPM) (Ho et al., 2020) and denoising diffusion implicit models (DDIM) (Song et al., 2020a), have shown promising generative capabilities in image, video, and even neural network parameters (Wang et al., 2024). Similar to other generative approaches such as GANs, VAEs, and flow-based models (Dinh et al., 2016; Chen et al., 2019), diffusion models transform a simple distribution, often a Gaussian, into a more complex distribution that captures the characteristics of the training data. Diffusion models achieve this, in contrast to other techniques, via iterative denoising steps, progressively transforming noisy data into less noisy (Raya & Ambrogioni, 2024), more coherent representations (Sohl-Dickstein et al., 2015). Diffusion models have two phases: diffusion and denoising. In the diffusion phase, we are blending original data points with some extent of Gaussian noise. Specifically, let x₀ be the original data point and xₜ be the fully distorted data, then the process of diffusion can be represented as: xₜ = √αₜx₀ + √(1 – αₜ)ε, (1) where the amount of total noise ε ~ N(0, I) added to the data x₀ at time step t ∈ [0,T] is controlled by αₜ that is monotonously decreasing from α₀ = 1 to αₜ ~ 0. Thus, while x₀ represents the original data, xₜ will consist entirely of Gaussian noise. To restore such diffused data, a predictive model, typically a neural network εᶿ with parameter θ, is trained to predict the added total noise given xₜ and time step t. Thus, diffusion models can be trained by minimizing the loss function: L = Eₓ₀~Pdata,ε~N(0,1) ||εᶿ(√αₜx₀ + √(1 – αₜ)ε, t) – ε||², (2) where Pdata is the distribution of training data. So, conventionally, diffusion models are understood as predicting the added noise during the diffusion process.",
      "section": "Background",
      "topic": "Diffusion Models",
      "chunk_summary": "Diffusion models transform simple distributions into complex ones through iterative denoising, involving a diffusion phase where noise is added and a denoising phase where a model predicts and removes the added noise.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "In the denoising phase, starting with a noisy pattern, the trained models are used to iteratively remove the predicted noise from current data: from xₜ ~ N(0, I), iteratively refine to xₜ₋₁, xₜ₋₂, ..., until x₀. In the DDIM framework, this sampling process is given by: xₜ₋₁ = √αₜ₋₁(xₜ - √(1 – αₜ)ε(xₜ,t))/√αₜ + √(1-αₜ₋₁)στε(xₜ, t) + σₜw, (3) where σₜ controls the amount of noise w ~ N(0, I) added during the denoising phase. Notably, the schedule of αₜ and σₜ will both affect the denoising process and can be chosen based on our needs under the DDIM framework.",
      "section": "Background",
      "topic": "Denoising Phase in Diffusion Models",
      "chunk_summary": "The denoising phase in diffusion models involves iteratively removing predicted noise from noisy data, controlled by parameters αₜ and σₜ, until the original data is recovered.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Describing prior work",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Similar to the relationship between energy and probability in statistical physics, evolutionary tasks can be connected to generative tasks by mapping fitness to probability density: higher fitness corresponds to higher probability density. Thus, given a fitness function f : ℝⁿ → ℝ, we can choose a mapping g to transform f into a probability density function p(x) = g[f(x)]. When aligning the denoising process in a diffusion model with evolution, we want x₀ to follow this density function, i.e., p(x = x₀) = g[f(x₀)]. This requires an alternative view of diffusion models (Song et al., 2020a): diffusion models are directly predicting the original data samples from noisy versions of those samples at each time step. Given the diffusion process xₜ = √αₜx₀ + √(1 – αₜ)ε, we can easily express x₀ in terms of the noise ε, and vice versa: x₀ = (xₜ - √(1 - αₜ)ε)/√αₜ and ε = (xₜ - √αₜx₀)/√(1-αₜ) (4) In diffusion models, the error ε between x₀ and xₜ is estimated by a neural network, i.e., ε = εᶿ(xₜ,t). Thus, Equation 4 provides an estimation x̂₀ for x₀ when replacing ε with ε̂. Hence, the sampling process of DDIM (Song et al., 2020a) in Equation 3 can be written as: xₜ₋₁ = √αₜ₋₁x̂₀ + √(1 - αₜ₋₁) · σₜε̂ + σₜw. (5) Since the denoising step in diffusion models requires an estimation of x₀, we need to derive it from sample xₜ and the corresponding fitness f(xₜ). The estimation of x₀ can be expressed as a conditional probability p(x₀ = x|xₜ). Using Bayes' theorem and p(x = x₀) = g[f(x₀)] yields: p(x₀ = x|xₜ) = p(xₜ|x₀ = x)p(x₀ = x)/p(xₜ) = p(xₜ|x)g[f(x)]/p(xₜ) (6)",
      "section": "Diffusion Models are Evolutionary Algorithms",
      "topic": "Mapping Fitness to Probability Density",
      "chunk_summary": "Evolutionary tasks can be connected to generative tasks by mapping fitness to probability density, allowing diffusion models to predict original data samples from noisy versions based on fitness.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Here, p(xₜ|x₀ = x) can be computed easily by N(xₜ; √αₜx, 1 – αₜ) given the design of the diffusion process, i.e., xₜ = √αₜx₀ + √(1 – αₜ)ε. Since deep-learning-based diffusion models are trained using mean squared error loss, the x₀ estimated by xₜ should be the weighted average of the sample x. Hence, the estimation function of x₀ becomes: x̂₀(xₜ, α, t) = Σₓ~Peval(x) p(x₀ = x|xₜ)x = Σₓ~Peval(x) (g[f(x)]N(xₜ; √αₜx, 1 – αₜ)x)/p(xₜ), (7) where Peval is the evaluation sample on which we compute the fitness score, here given by the current population Xₜ = (x⁽¹⁾, x⁽²⁾, ..., x⁽ᴺ⁾) of N individuals. Equation 7 has three weight terms: The first term g[f(x)] assigns larger weights to high fitness samples. For each individual sample xₜ, the second Gaussian term N(xₜ; √αₜx, 1-αₜ) makes each individual only sensitive to local neighbors of evaluation samples. The third term p(xₜ) is a normalization term. Hence, x̂₀ can be simplified to: x̂₀(xₜ, α, t) = Σₓ∈Xₜ g[f(x)]N(xₜ; √αx, 1 – αₜ)x/Z, (8) where Z is the normalization term: Z = p(xₜ) = Σₓ∈Xₜ g[f(x)]N(xₜ; √αₜx, 1 – αₜ). (9) When substituting Equation 8 into Equation 4 we can express ε̂ as: ε̂(xₜ, α, t) = (xₜ - √αₜ x̂₀(xₜ, α, t))/√(1 - αₜ), (10) and by substituting Equations 8 and 10 into Equation 5, we derive the Diffusion Evolution algorithm: an evolutionary optimization procedure based on iterative error correction akin to diffusion models but without relying on neural networks at all (see pseudocode in Algorithm 1). When inversely denoising, i.e., evolving from time T to 0, while increasing αₜ, the Gaussian term will initially have a high variance, allowing global exploration at first. As the evolution progresses, the variance decreases, giving lower weight to distant populations, leading to local optimization (exploitation). This locality avoids global competition and thus allows the algorithm to maintain multiple solutions and balance exploration and exploitation. Hence, the denoising process of diffusion models can be understood in an evolutionary manner: x̂₀ represents an estimated high fitness parameter target. In contrast, xₜ can be considered as diffused from high-fitness points. The first two parts in Equation 5, i.e., √αₜ₋₁x̂₀ + √(1 – αₜ₋₁) σₜε̂, guide the individuals towards high fitness targets in small steps. The last part of Equation 5, σₜw, is an integral part of diffusion models, perturbing the parameters in our approach similarly to random mutations.",
      "section": "Diffusion Models are Evolutionary Algorithms",
      "topic": "Diffusion Evolution Algorithm Derivation",
      "chunk_summary": "The Diffusion Evolution algorithm is derived by estimating x₀ using Bayes' theorem and incorporating fitness-based weighting, resulting in an iterative error correction process that balances exploration and exploitation.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Figure 2(a) demonstrates the detailed evolution process of a multi-target fitness landscape with two optimal points (see exact fitness function in Appendix A.1). Each individual estimates high fitness parameter targets and moves toward the target along with random mutations. The high fitness parameter targets x̂₀ are estimated based on their neighbors' fitness scores (neighbors are shown in blue disks, with radius proportional to √(1 – αₜ)/√αₜ). The estimated targets x̂₀ typically move faster than the individuals while the individuals are successively refined in small denoising steps in the direction of the estimated target (see Figure 2(b)). Although x̂₀ often have higher fitness, they exhibit lower diversity, hence they are used as a goal of individuals instead of the final solutions. This difference also provides flexibility in balancing between more greedy and more diverse strategies.",
      "section": "Diffusion Models are Evolutionary Algorithms",
      "topic": "Diffusion Evolution Process",
      "chunk_summary": "The Diffusion Evolution process involves individuals estimating high-fitness targets based on neighbors' fitness and moving towards them with mutations, balancing fitness and diversity.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "We conduct two sets of experiments to study Diffusion Evolution in terms of diversity and solving complex reinforcement learning tasks. Moreover, we utilize techniques from the diffusion models literature to improve Diffusion Evolution. In the first experiment, we adopt an accelerated sampling method (Nichol & Dhariwal, 2021) to significantly reduce the number of iterations. In the second experiment, we propose Latent Space Diffusion Evolution, inspired by latent space diffusion models (Rombach et al., 2022), allowing us to deploy our approach to complex problems with high-dimensional parameter spaces through exploring a lower-dimensional latent space.",
      "section": "Experiments",
      "topic": "Experimental Overview",
      "chunk_summary": "Two sets of experiments are conducted to study Diffusion Evolution's diversity and performance in reinforcement learning, incorporating accelerated sampling and latent space diffusion.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "To compare our method to selected mainstream evolutionary algorithms, we choose five different two-dimensional fitness landscapes as benchmarks: The Rosenbrock and Beale fitness functions have a single optimal point, while the Himmelblau, Ackley, and Rastrigin functions have multiple optimal solutions (see Appendix A.4 for more details); we compare our method to other evolutionary strategies, including CMA-ES (Hansen et al., 2003), OpenES (Salimans et al., 2017), and PEPG (Sehnke et al., 2010). The experiments show that our Diffusion Evolution algorithm can find diverse solutions on the Himmelblau, Ackley, and Rastrigin functions, while other methods struggle (see Figure 3 and Table 1). CMA-ES, OpenES, and PEPG either focus on finding a single solution or get distracted by multiple high-fitness peaks, leading to sub-optimal results. Our experiments demonstrate that the Diffusion Evolution algorithm can identify diverse solutions and adapt to various fitness landscapes. The most time-consuming part of evolutionary algorithms is often the fitness evaluation. In this experiment, we adopt an accelerated sampling method from the diffusion models literature to reduce the number of iterations. As proposed by Nichol & Dhariwal (2021), instead of the default αₜ scheduling in DDPM, a cosine scheduling αₜ = cos(πt/T)/2 + 1/2 leads to better performance when T is small. With this, we can significantly reduce the number of fitness evaluations while maintaining sampling diversity and quality.",
      "section": "Experiments",
      "topic": "Multi-target Evolution",
      "chunk_summary": "Diffusion Evolution outperforms CMA-ES, OpenES, and PEPG in finding diverse solutions on multi-optimal fitness landscapes, and accelerated sampling reduces the number of iterations required.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "To systematically compare different methods, we repeated the evolution 100 times for each method. In all experiments, the fitness functions were rescaled from 0 to 1, with 1 representing the highest fitness (see Appendix A.4). Each experiment was conducted with a population of 512 and 25 iterations, except for the OpenES method, which requires 1000 steps to converge. To quantify diversity, we then calculated Shannon entropy of the final population by gridding the space and counting the individuals in different grid cells (we select the top-64 fitness individuals, focusing solely on elite individuals). The results in Table 1 show that our method consistently finds more diverse solutions without sacrificing fitness performance. While CMA-ES shows higher entropy on the Ackley and Rastrigin functions, it finds significantly lower fitness solutions compared to Diffusion Evolution, suggesting it is distracted by multiple solutions rather than finding diverse ones (see examples in Figure 3).",
      "section": "Experiments",
      "topic": "Multi-target Evolution Results",
      "chunk_summary": "Experimental results show Diffusion Evolution consistently finds more diverse solutions without sacrificing fitness compared to other methods, as measured by Shannon entropy.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Here, we apply the Diffusion Evolution method to reinforcement learning tasks (Sutton & Barto, 1998) to train neural networks for controlling the cart-pole system (Barto et al., 1983). This system has a cart with a hinged pole, and the objective is to keep the pole vertical as long as possible by moving the cart sideways while not exceeding a certain range (see Figure 4(d)). The game is terminated if the pole-angle exceeds ±12° or the cart position exceeds ±2.4. Thus, longer duration yields higher fitness. We use a two-layer neural network of 58 parameters to control the cart, with inputs being the current position, velocity, pole angle, and pole angular velocity. The output of the neural network determines whether to move left or right (see more details about the neural network in Appendix A.5.1). The task is considered solved when a fitness score (cumulative reward) of 500 is reached consistently over several episodes.",
      "section": "Experiments",
      "topic": "Latent Space Diffusion Evolution in Reinforcement Learning",
      "chunk_summary": "Diffusion Evolution is applied to reinforcement learning for controlling the cart-pole system, using a two-layer neural network with fitness based on the duration the pole remains vertical.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "Deploying our original Diffusion Evolution method to this problem results in poor performance and lack of diversity (see Figure 4(b-c)). To address this issue, we propose Latent Space Diffusion Evolution: inspired by the latent space diffusion model (Rombach et al., 2022), we map individual parameters into a lower-dimensional latent space in which we perform the Diffusion Evolution Algorithm. This approach significantly improves performance and restores diversity. The key insight comes from the Gaussian term in Equation 8 for estimating the original points x̂₀: the distance between parameters increases with higher dimensions, making the evolution more local and slower. Moreover, the parameter or genotype space may have dimensions that don't effectively impact fitness, known as sloppiness (Gutenkunst et al., 2007). Assigning random values to these dimensions often doesn't affect fitness, similar to genetic drift or neutral genes, suggesting the true high-fitness genotype distribution is lower-dimensional. The straightforward approach is directly denoising in a lower-dimensional latent space z and estimating high-quality targets z₀ via: x̂₀(zₜ, α, t) = Σₓ~Peval(x) g[f(x)]N(zₜ; √αz, 1 – αₜ)x/Z (11) However, this approach requires a decoder and a new fitness function f' for z, which can be challenging to obtain. To circumvent this, we approximate the latent diffusion by using the latent space only to calculate the distance between individuals. While we don't know the exact distribution of x a priori, a random projection can often preserve the distance relationships between populations, as suggested by the Johnson-Lindenstrauss lemma (Johnson, 1984). To do this, we change Equation 11 to: x̂₀(xₜ, α, t) = Σₓ~Peval(x) g[f(x)]N(zₜ; √αz, 1 – αₜ)x/Z, (12) where z = Ex, Eᵢⱼ ~ N(d,D)(0,1/D), D is the dimension of x, and d is the dimension of latent space (Johnson, 1984) (see Algorithm 2 in Appendix). Here we choose d = 2 in our experiments for better visualization. The results show a significant improvement in both fitness and diversity (see Figure 4(b-c)). We also found that this latent evolution can still operate in a much larger dimensional parameter space, utilizing a three-layer neural network with 17,410 parameters, while still achieving strong performance. Combined with the accelerated sampling method, we can solve the cart pole task in only 10 generations, with 512 population size, one fitness evaluation per individual. These highlights the potential of using tools and theories from the diffusion model domain in evolutionary optimization tasks and vice versa, opening up broad opportunities to improve and understand evolution from a new perspective.",
      "section": "Experiments",
      "topic": "Latent Space Diffusion Evolution Results",
      "chunk_summary": "Latent Space Diffusion Evolution, inspired by latent space diffusion models, improves performance and diversity in high-dimensional parameter spaces by mapping parameters to a lower-dimensional latent space for distance calculations, enabling efficient solution of the cart-pole task.",
      "position_in_section": "End",
      "certainty_level": "High",
      "citation_context": "Presenting new results",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "By aligning diffusion models with evolutionary processes, we demonstrate that diffusion models are evolutionary algorithms, and evolution can be viewed as a generative process. The Diffusion Evolution process inherently includes mutation, selection, hybridization, and reproductive isolation, indicating that diffusion and evolution are two sides of the same coin. Our Diffusion Evolution algorithm leverages this theoretical connection to improve solution diversity without compromising quality too much compared to standard approaches. By integrating latent space diffusion and accelerated sampling, our method scales to high-dimensional spaces, enabling the training of neural network agents in reinforcement learning environments with exceptionally short training time.",
      "section": "Discussion",
      "topic": "Diffusion and Evolution Equivalence",
      "chunk_summary": "Diffusion models and evolution are shown to be equivalent, with Diffusion Evolution improving solution diversity and scaling to high-dimensional spaces through latent space diffusion and accelerated sampling.",
      "position_in_section": "Beginning",
      "certainty_level": "High",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    },
    {
      "text": "This equivalence between the two fields offers valuable insights from both deep learning and evolutionary computation. Through the lens of machine learning, the evolutionary process can be viewed as nature's way of learning and optimizing strategies for survival of species over generations. Similarly, our Diffusion Evolution algorithm iteratively refines estimation of high-fitness parameters, continuously learning and adapting to the fitness landscape. This positions evolutionary algorithms and diffusion models not merely as optimization tools, but also as learning frameworks that enhance understanding and functionality through iterative refinement. Conversely, framing evolution as a diffusion process offers a concrete mathematical formulation. In contrast to previous approaches (Ao, 2005), we provide an explicit and implementable evolutionary framework.",
      "section": "Discussion",
      "topic": "Insights from Equivalence",
      "chunk_summary": "The equivalence provides insights into evolution as a learning process and diffusion models as evolutionary algorithms, offering a concrete mathematical framework for evolution.",
      "position_in_section": "Middle",
      "certainty_level": "High",
      "citation_context": "Drawing conclusions",
      "page_number": null,
      "pdf_filename": "pdf_20250803_124126_558737.pdf",
      "original_filename": "pdf_20250803_124126_558737_extracted_text.txt",
      "authors": "[\"Yanbo Zhang\", \"Benedikt Hartl\", \"Hannef Hazan\", \"Michael Levin\"]",
      "year": null,
      "journal": "Unknown",
      "doi": null
    }
  ],
  "gemini_response": "",
  "processed_at": "2025-08-05T11:35:49.383170"
}