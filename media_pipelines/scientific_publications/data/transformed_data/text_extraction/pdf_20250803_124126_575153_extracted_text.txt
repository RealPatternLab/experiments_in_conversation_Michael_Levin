Brains and Where Else?
Mapping Theories of Consciousness to Unconventional Embodiments

Authors:
Nicolas Rouleau<sup>1,2,*</sup> and Michael Levin<sup>2,3,*</sup>

Affiliations:
1 Department of Health Sciences, Wilfrid Laurier University, Waterloo, ON, Canada
2 Allen Discovery Center at Tufts University, Medford, MA 02155, USA.
3 Wyss Institute for Biologically Inspired Engineering, Harvard University, Boston, MA 02115, USA.

*Corresponding authors:
nrouleau@wlu.ca, michael.levin@tufts.edu

Running title: Minds Beyond Brains

Keywords: consciousness, aneural cognition, functionalism, organizational invariance, unconventional minds


[PAGE 2] Abstract
It is commonly assumed that a useful theory of consciousness (ToC) will, among other things, explain why consciousness is associated with brains. However, the findings of evolutionary biology, developmental bioelectricity, and synthetic bioengineering are revealing the ancient pre-neural roots of many mechanisms and algorithms occurring in brains – the implication of which is that minds may have preceded brains. Most of the work in the emerging field of diverse intelligence emphasizes externally observable problem-solving competencies in unconventional media, such as cells, tissues, and life-technology chimeras. Here, we inquire about the implications of these developments for theories that make a claim about what is necessary and/or sufficient for consciousness. Specifically, we analyze popular current ToCs to ask: what features of the theory specifically pick out brains as a privileged substrate of inner perspective, or, do the features emphasized by the theory occur elsewhere. We find that the operations and functional principles described or predicted by most ToCs are remarkably similar, that these similarities are obscured by reference to particular neural substrates, and that the focus on brains is more driven by convention and limitations of imagination than by any specific content of existing ToCs. Encouragingly, several contemporary theorists have made explicit efforts to apply their theories to synthetic systems in light of the recent wave of technological developments in artificial intelligence (AI) and organoid bioengineering. We suggest that the science of consciousness should be significantly open to minds in unconventional embodiments.


[PAGE 3] Introduction
What processes or algorithms underlie the ability of certain physical objects, such as living bodies, to form memories, implement decision-making, have an inner perspective with preferences, and navigate their environment in a goal-directed manner? This question is crucial to our understanding of ourselves, the development of ethics and social systems, and the status of hybrid and fully synthetic artificial intelligence (AI). A number of formalisms, including that of Turing [1] and later, the connectionist paradigm [2-7], have attempted to delineate what it is that confers mind within a given embodiment. In all cases however, it was assumed that the formalisms' dynamics describe events in brains. What would have happened if the biologists came to McCulloch [3], Pitts, Pappert, Rosenblatt, etc. and said: “we were wrong, the human mind is in the liver”? Would they have had to modify their models, or shrug it off as irrelevant to their efforts? What is actually neural about artificial neural networks, used to attempt to understand minds and build AI? Specifically, what aspects of neuroscience-inspired formalisms are actually tied to neurons per se, as opposed to other cell types?

This seems like an odd question – surely neurons are unique, and there must be a reason why minds associate with brains? This assumption, which permeates discussions of AI and philosophy of mind, is crumbling due to a number of reasons. First, evolutionary developmental biology shows how brains evolved gradually from other cell types. Indeed, the molecular mechanisms that set up the bioelectric networks of the brain are ancient – existing in all cells of the body and having their origin in bacterial biofilms [8-11]. Phylogenetically ancient traits of all kinds are carried forward and even implemented by new substrates (i.e., degeneracy) – so, why not the mechanisms underlying mindedness? Second, memory, creative problem-solving, decision-making, and numerous other aspects of active agency have now been seen in cells, tissues, slime molds, and even small molecular networks [12-16]. Advances in biophysics, cell biology, and behavioral science are revealing deep evolutionary commonalities between the mechanisms and algorithms of neuroscience and other fields such as developmental biology, for example in the study of cell groups as a collective intelligence that navigates anatomical space [17, 18].

Thus, the emerging field of diverse intelligence reveals that the focus on brains, and on the readily observable movement of medium-sized objects at medium speeds through the 3D world, is a result of our evolutionary firmware. Efforts to expand from this myopia are under way, via research on the problem-solving competencies of a wide range of living and synthetic agents that is helping to erode our limited evolutionary firmware for visualizing minds in unconventional embodiments [19]. To date however, all of the work in this field has focused on externally-observable behavior – problem-solving, or the "easy” problem of consciousness [20]. What of the hard problem – how to explain the inner perspective and elucidate its relationship to the brain?

Here, we explore the state of consciousness research with a focus on Theories of Consciousness (ToC) [21, 22] and inquire about the implications of the new biology for theories that make a claim about what is necessary and/or sufficient for consciousness. Specifically, we analyze popular current ToCs to ask: what features of the theory specifically pick out brains as a privileged substrate of inner perspective, or, do the features emphasized by each theory occur elsewhere, in natural bodies and perhaps even in the world of engineering? We find that most ToCs rely on functional principles that are not specific to neuronal networks, which means that their claims about consciousness should apply to a wide range of unconventional substrates. We find few specifics about why neuronal assemblies in particular would be an exclusive substrate for consciousness, and suggest that the focus on brains is more driven by convention and limitations of imagination than by any specific content of existing ToCs. Thus, it is interesting to explore the relationships of various ToCs with the nervous system per se, and the consequences of taking seriously the features they emphasize when they occur outside of brains.


[PAGE 4] Theories of Consciousness: a tool to counter-act pervasive mind-blindness
Specific ToCs offer long-awaited explanatory and predictive power amid a history of confusion about the nature of experience. By what standard can a ToC be assessed as useful? Insofar as it can reliably point to subjects in the world, a ToC accomplishes its most basic function. But what if the theory can only reliably point to a particular type of subject? The validity of any theory that purports to explain how and where experience manifests is impacted not only by its positive identifications of mind, but by the number of true minds that it leaves unidentified. Though practical distinctions have always been made to classify the contents of experience, there is yet no consensus definition of consciousness or ToC that accounts for its mechanisms. We usually have no problem being epistemically confident about our own inner perspective. However, the existence of other minds with private thoughts and feelings may be fundamentally unknowable [23-26]. Still, humans share a robust intuition that we live among other minds in a shared environment [27]. That others speak, gesture, respond, and emote in ways that mirror our own behavioural correlates of consciousness reinforces a theory of mind that underlies the social and moral systems humans have created and refined over hundreds of thousands of years [27], and the ancient biological firmware that tuned our agency detectors for specific kinds of behaviors in visible space. Whether it reflects reality or not, humans infer the existence of other embodied minds within their environments, and this leap of faith (and its attendant limitations) is a normal feature of human psychology.

Mind-blindness – or a failure to form a theory of mind in the presence of other humans – is a defining characteristic of some common neuropathologies [28] when it affects the kinds of minds that neurotypical humans routinely recognize. However, we suggest that humans are insensitive to a wide range of unconventional minds, without sensing any kind of deficit, in the same way that we are insensitive to huge swaths of the electromagnetic spectrum without feeling impaired. If our default cognitive apparatus was significantly mind-blind to major categories of unconventional beings, we wouldn't know about it without developing tools in the same way that physics, and a useful theory of electromagnetic waves, opened our awareness to the existence of X-rays, radio waves, and other signals that our default configuration cannot perceive. This analogy also works because light and X-rays simply do not seem like what happens when you wave a magnet up and down – on a superficial level, they appear quite different indeed. And yet, a rigorous formalism allowed us to overcome our limited intuitions and see electromagnetics in all of its glorious guises. Is there a reason to hypothesize that the same situation awaits us with respect to the space of possible minds?


[PAGE 5] Why neural correlates fall short as consciousness criteria
Consciousness cannot be directly measured; therefore, correlates have been used as indirect signs of an underlying mind in the same way that the presence of a black hole is inferred on the basis of how light is bent or “lensed” by distortions of space-time. Many contemporary ToCs refer to “neural correlates” of consciousness (NCCs), which are a set of conserved relationships between human brain structure-function and self-reported experiences [31]. Why “neural correlates” as opposed to, simply, “correlates”? Following localized brain lesions, neural stimulation, or the use of psychoactive compounds, humans report highly conserved experiential phenomena that map on to common brain regions as revealed by neuroimaging [31]. While its flow may be interrupted by sleep or altered by drugs, anesthetics, rituals, and environmental forces, the evidence indicates that consciousness is a shared feature of human brains with stereotyped structure-function correlates. Because brain morphology is highly conserved (i.e., most brains display the same gyri, sulci, nuclei, tracts, circuits, networks, etc.), NCCs can be generalized across members of the human species, allowing us to overcome weaker forms of mind-blindness in clinical settings. Until the development of brain imaging, immobile and seemingly unresponsive coma patients were lumped into the category of non-conscious systems with most organisms, robots, and the deceased; however, with NCCs, new degrees of distinction could be made including the confirmation of a minimally conscious state [32-35]. NCCs predict the existence of recondite minds on the bases of neural activations alone if the same activations were associated with the reported experiences of others. This mind-detecting strategy, termed “reverse inference” [36], is a practical solution to mind-blindness when the potential subject in question is a human with a brain.

Developmental biology and evolutionary theory emphasize the continuity of conserved mechanisms and algorithms spanning slowly and gradually from single cells (such as microbes and fertilized eggs) to adult metacognitive humans, and the gradual modification of generic cells and cell networks into neurons (Figure 1). The gradual self-construction of the body suggests the natural possibility of the gradual appearance of consciousness (and thus its presence, in degrees, in substrates different from an adult brainy animal), as perhaps reflected in Turing's interest in synthetic intelligence and the spontaneous patterning of embryonic morphogens [1, 29]. At the same time, recent advances in bioengineering, synthetic biological intelligence, artificial intelligence, brain-computer interfaces, and robotics have fundamentally challenged our mind-inferencing strategies. The interoperability of life with engineered components is revealing a wide option space of hybrid beings that do not fit into classic life/machine categories [30] (Figure 2). Thus, whether or not the behavior patterns of “artificial” and hybrid systems reveal the presence of an experiencing subject has become a topic of great interest to many. ToCs, as principled theories for where one can expect inner perspective, promise to enable technologies to reveal heretofore unrecognized vistas – like tele-spectroscopy, which revealed familiar earthly elements in then-unexpected locations: celestial objects. To overcome the limitations of a human-centered theory of mind and increase true positive identifications of unconventional manifestations of consciousness in the environment, ToCs must be sufficiently universalizable to account for other minds. Are current ToCs formulated with other minds, well, in mind?


[PAGE 6] Unfortunately, any movement across the phylogenetic tree decreases the predictive power of reverse inference because NCCs are fundamentally correlates and can only be used to infer consciousness in precisely the same way that behaviors motivate the same inferences. If the associations in question are non-generalizable, such as involving very specific nervous systems with defined organizations, the logic of reverse inference breaks down. While many ToCs have highlighted the relevance of NCCs, their poor generalization to non-human subjects limits their utility. How would an NCC-dependent ToC map on to the distributed nervous system of a jellyfish or the ganglia of a mollusk? What can current ToCs offer in terms of predicting a capacity for experience when comparing 3-layered and 6-layered cortices or their intermediates? Unless a ToC can account for differences in neural organization, it will return the same predictive errors that human intuitions commit when assessing the mental status of anything other than a human. Some authors have suggested the use of perturbational complexity as a measure of consciousness, which despite its focus on the responses of neural tissues, has the potential to transcend a historical reliance on specific NCCs because, in principle, other systems can display brain-independent perturbational markers that predict conscious experience [37, 38].

Despite the longstanding absence of any direct measure of consciousness, and strong philosophical reasons to doubt its existence in others, humans often extend a theory of mind to infer non-human animal sentience [39]. Interestingly, the degree to which a non-human animal shares superficial, human-like characteristics is predictive of our willingness to infer subjectivity on the bases of their behaviours [40, 41]. Once again, reverse inference is used to bridge the epistemic gap (i.e., analogous behaviors and observable traits as predictors of mind). Prior to a scientific study of animal consciousness, moral considerations were granted to many non-human animal species, and most people are quite happy to assume that their pets lead rich, experiential lives with felt states of pleasure and pain. In many countries, non-human animal species such as dolphins and chimpanzees enjoy personhood status [42, 43] that set them apart from other living systems, including plants, insects, and microorganisms which together constitute over 99% of Earth's biomass [44]. In other words, less than 1% of living systems on the planet are granted special status and consideration over the vast majority due to their presumed subjectivity, even though the rest have long been known to exhibit different degrees of learning, decision-making, predictive capacity, etc. [13, 45-48]. Notably, much less than 1% of living systems on Earth possess a nervous system. If even a minority subset of aneural life is conscious – perhaps a single plant or animal species – the NCC standard will fail to account for their experiences, generating false negative errors wherever it is applied.


[PAGE 7] While recent developments in synthetic biological intelligence and AI research have accelerated discussion around the topic of unconventional minds, the emergence of neural-robotic hybrids in the late 20th century represented a major branching point in the conversation. That cultured neural networks could be coupled with robotic or virtual “bodies” to solve real-world problems challenged longstanding dichotomies between the living and non-living or the agential and automatic [49-51]. It was quickly realized that disembodied brains were dysfunctional but could be normalized with stochastic inputs or response-contingent feedback [52-54]. Now, there is evidence to suggest that cultured neural networks in closed-loop feedback systems can optimize their outputs toward many types of defined goal states without external programming [55]. Importantly, these displays of self-organized problem-solving are achieved without specialized, genetically-encoded brain circuits. That is, embodied cultured networks demonstrated that, fundamentally, there is no intrinsic, universal value to any particular tract system, nucleus, or circuit outside of its default context. Rather, a sufficiently plastic neural network can be shaped to accomplish any number of tasks. Once considered exclusive to human brains, cognitive functions such as learning, attention, and decision-making have, over time, been incrementally extended to living and non-living systems alike. While it is possible that any one or perhaps all of these features of cognition could be displayed without an experiential correlate, the stakes are high – not knowing whether a physical object with which you are engaged is conscious is an ethical risk. This is especially relevant now that a much wider variety of beings – biobots [56-59], cyborgs [60-66], and minimal active matter systems [67-71] – are coming on line and beginning to be bioengineered. ToCs will need to be applied to an ever-increasing number of organizationally unique systems with potential minds [17, 30, 72].

ToCs are important. Whether or not they hold construct validity (i.e., how well the ToC not just predicts the presence of a subject but actually describes true features or mechanisms of consciousness), they enable us to make meaningful distinctions that inform decisions related to lifestyle, ethics, public policy, and law. Frameworks must now be developed to identify unfamiliar minds in unconventional spaces that betray longstanding neurocentric assumptions [17, 48, 73]. Here, we survey contemporary ToCs and explore their suitability to identify other kinds of minds in diverse environments. How many of them are actually neuron-specific? While many ToCs have already adopted a panpsychist, functionalist, or universalized approach, some still focus exclusively on the brain even though nothing about their secret sauce is actually unique to neurons.


[PAGE 7] Neural tissues as non-exclusive specialists of cognitive function

[PAGE 8] Because ToCs that reference NCCs or any specific neurobiological details will likely fail to generate a true positive prediction of unconventional minds, the role of the brain within the cognitive landscape must be revisited. Neurons – and specifically, pyramidal cells – were once described by Ramón y Cajal as “the butterflies of the soul”. The implication, of course, was that neural cells conferred the properties of minds, which remains a central assumption of modern neuroscience. However, there is no single feature of the neuron that isn't also displayed by some other cell, living system, inorganic material, or natural process (Figure 3). Whether it's a capacity for long-range signaling, cell shape plasticity, chemical communication, electrotonic coupling, electromagnetic sensing, membrane polarization, chemotaxis, galvanotaxis, ephaptic coupling, or networking, the neuron holds no exclusive capacity or function [74-76].

Many living systems display electrochemical patterns that are homologous to those of neurons, including the electromagnetic fields that have been hypothesized to be important for consciousness [77-83]. Most bodily cells regulate membrane-bound ion channels to maintain a polarized electrical state; however, neurons display notably hyperpolarized resting potentials (-70 mV). Cardiomyocytes, which are similarly hyperpolarized at rest (-90 mV), generate spontaneous depolarizations or “action potentials” [84] with refractory periods and other dynamics that are similar but not identical to those of neurons (and participate in a phenomenon known as cardiac memory [85, 86]). Immune cells can be sensitized, display learned responses, and encode long-term memories reflective of a history of exposure to specific pathogens [87], just like cells of the nervous system form long-term memories reflective of a history of sensory inputs. Neurotransmitters such as glutamate and serotonin are expressed throughout the body, outside the brain [88] and by many plant species as chemical signals for cellular communication [89]. Incidentally, plants display anticipatory responses and even game-theoretic decision-making capabilities that weigh the availability of resources with kin status of neighboring organisms, determining the expression of competitive or cooperative actions [90]. Unsurprisingly, some authors have called for a more inclusive definition of “nervous system” that captures a spectrum of signal generation, transmission, and processing in multicellular systems [91]. Paramecia [92-94] and slime molds [95-97] can be conditioned and even solve problems without nervous tissues. We previously demonstrated that non-associative learning such as habituation is a commonplace function that is not dependent on any specific biological substrate or cell type [98, 99]. Several authors have since suggested that learning is a universal property shared by cells, generally [14, 15, 100-104].

[PAGE 8] Dynamical properties of neurons are also displayed by simple molecular interactions at sub-cellular scales [105]. Indeed, phospholipid membranes alone display memcapacitive properties that recapitulate long-term potentiation (LTP) without a cell or synapse to speak of [106]. Water at an interface generates negative potential differences (voltage) within range of resting membrane potentials (-100 mV) that can be modified by the addition of physiological ions and detected hundreds of microns away from the surface [107]. Microtubules and their special properties have been suggested to be critical


[PAGE 9] for consciousness [108-111], but cytoskeletal structures such microtubules are present in all cells and play an important role in cellular and multicellular decision-making and collective behavior [112-115]. Moreover, microtubules in a dish spontaneously align with and migrate along electric fields [116, 117] and polymerize as branched networks with dendrite-like arbors. Incidentally, branching patterns of neurites, plants, and blood vessels conform to the same scaling laws [118-120]. Similarly, the structures of neural networks are quantitatively convergent with those of galactic filaments [121] within the cosmic web. Even inorganic substrates such iron bars are subject to conditioned hysteresis responses [122] and silver nanowires display self-assembling properties in the presence of electric current that optimize patterning with properties of learning and memory [123]. Interestingly, the current densities, firing frequencies, backpropagation responses, and saltatory-conductive properties of neurons are also displayed by lightning strikes between the Earth's surface and its atmosphere [124].

Neither the composition nor the dynamics of neurons are sufficiently unique to justify their special status as mind generators. Either individual cell properties are insufficient, or many types of simple systems are similarly capable of generating conscious states. The third possibility is that brains deserve exclusive status because of their connective properties, local circuitry, and network architectures. It is often suggested that structural complexity is what sets brains apart from other systems. However, contrary to popular assumption, a network architecture with sparse rather than dense connectivity is likely to specialize brains as implementers of cognition [125]. Notably, feedforward networks are unlikely to generate consciousness [35]. Feedback mechanisms, including reverberation by re-entrant circuits, are thought to be requirements for consciousness [126, 127]. From a functionalist perspective, the organizational principles are more relevant than the substrates, and neural tissues represent one of many possible ways to implement cognitive functions. With many natural and synthetic examples of reentry, feedback, network sparsity, and plasticity outside the nervous system, there is good reason to doubt that brains occupy a privileged position over other systems with analogous organizational features. Here, we examine several contemporary frameworks from a functionalist perspective, with the aim of universalizing ToCs to interact with unconventional substrates and scales.

[PAGE 9] Theories of consciousness to map diverse embodied minds

A universalizable ToC should be substrate-independent, scale-invariant, and organization-invariant [20], with the implication that mind is multiply realizable [72, 128]. Unfortunately, when the properties of cognitive systems are divorced from their biological substrates, it can be difficult to know where to apply inferencing strategies and deeply unintuitive questions arise: What does it mean to be conscious in spaces other than 3D space at human spatiotemporal scales (i.e., beyond centimeter- or millimeter-wide objects with dynamics in the order of seconds or milliseconds)? Beyond the neural variety, what kinds of correlative phenomena can reliably serve as indirect measures of consciousness? What kinds of perturbations or physical interactions can reliably induce changes within a system that indicate the likely presence of a mind? Without the grounding of a testable ToC, little progress can be made. As an initial step toward mapping minds in unconventional spaces, we reviewed prominent theories of consciousness as recently selected by Seth & Bayne [21] and substituted neurocentric language with aneurocentric or generic terms. Expanded, aneurocentric versions of the primary claims of each theory were then constructed with language reflecting inclusion of different substrates, scales, and organizations (see Table 1). Common terms such as “sensation" or “sensory” were replaced with generic afferents such as “input”. Likewise, terms such as “motor” were replaced with generic efferents such as “output”. Similarly, terms such as “brain” or “neuron” were replaced with generic terms for potential loci of consciousness including "system” or “processor”, which we consider potentially interchangeable with "cell”, “core”, “hub”, and/or “node”, depending on the context of the specific ToC.


[PAGE 10] Table 1. Aneurocentric formulations of prominent theories of consciousness.

| Theory | Original Formulation | Expanded Aneurocentric Formulation |
|---|---|---|
| Predictive Processing | Consciousness arises from the brain’s continuous attempt to predict sensory input and minimize prediction error | Consciousness arises from a *system’s* continuous attempt to predict *input* and minimize prediction error |
| Free Energy Principle | Consciousness arises when the brain minimizes free energy, a measure of surprise or uncertainty about its sensory input | Consciousness arises when a *system* minimizes free energy, a measure of surprise or uncertainty about its *input* |
| Attention Schema Theory | Consciousness arises from the brain’s internal model of attention, which allows it to selectively process information | Consciousness arises from a *system’s* internal model of attention, which allows it to selectively process information |
| Global Workspace Theory | Consciousness arises when information is broadcast globally within the brain, making it available for various cognitive processes | Consciousness arises when information is broadcast globally within a *system*, making it available for various cognitive processes |
| Higher-Order Theories | Consciousness arises when the brain has higher-order thoughts about its own mental states | Consciousness arises when a *system* has higher-order thoughts about its own mental states |
| Information Closure Theory | Consciousness arises in systems that are informationally closed, meaning that they can only access information from within themselves | Consciousness arises in systems that are informationally closed, meaning that they can only access information from within themselves |
| Integrated Information Theory | Consciousness arises from the amount of integrated information in a system, which is a measure of how much information is lost when the system is divided into parts | Consciousness arises from the amount of integrated information in a system, which is a measure of how much information is lost when the system is divided into parts |
| Recurrent Processing Theory | Consciousness arises from recurrent processing in the brain, which allows information to be maintained and amplified over time | Consciousness arises from recurrent processing in a *system*, which allows information to be maintained and amplified over time |
| Multiple Drafts Model | Consciousness arises from the brain’s ongoing construction of multiple drafts of experience, which are constantly being revised and updated | Consciousness arises from a *system’s* ongoing construction of multiple drafts of experience, which are constantly being revised and updated |
| Neural Darwinism | Consciousness arises from the selection and amplification of neuronal groups in the brain | Consciousness arises from the selection and amplification of *processing units* in a *system* |
| Embodied Cognition | Consciousness arises from the brain’s interaction with the body and the environment | Consciousness arises from a *system’s* interaction with its *embodiment* and the environment |
| Orchestrated Objective Reduction | Consciousness arises from quantum computations in microtubules within neurons | Consciousness arises from quantum computations in *organized structures* within *processing units* |
| Predictive coding and active inference | Consciousness arises when the brain engages in predictive coding and active inference, which involve predicting sensory input and acting to minimize prediction error | Consciousness arises when a *system* engages in predictive coding and active inference, which involve predicting *input* and acting to minimize prediction error |
| Self-organizing consciousness | Consciousness arises when the brain self-organizes into a complex, integrated system | Consciousness arises when a *system* self-organizes into a complex, integrated system |
| Radical plasticity thesis | Consciousness arises when neural networks in the brain exhibit radical plasticity, which allows them to adapt to changing circumstances | Consciousness arises when *networks* in a *system* exhibit radical plasticity, which allows them to adapt to changing circumstances |
| Unlimited associative learning | Consciousness arises when a system's states are processed by high-level integrating units, learning about itself in an open-ended way with compounds of paired patterns of stimuli and actions | Consciousness arises when a *system’s* states are processed by high-level integrating units, learning about itself in an open-ended way with compounds of paired patterns of *inputs* and *outputs* |


[PAGE 13] Legend: This table contains the main ToCs; italics indicate the words that were generalized to show how the theory applies beyond brains. In many cases, no changes needed to be made. This illustrates how many ToCs are actually not about brains specifically, but call out aspects that are relevant to diverse cells, systems, and collectives.

When the substrate- and scale-dependent contents of each theory are separated from their functional principles, it becomes clear that, amongst the most prominent ToCs, there are only a handful of distinct concepts or themes including: 1) predictive modeling, 2) enactivism/ecological interactions, 3) reentrancy or looped feedback, 4) meta-representations, 5) attentional gating/monitoring, 6) emergence from computation, 7) integration of information, and 8) coarse-graining. Some ToCs are mutually incompatible; however, viewed through a functionalist lens, many more display broad conceptual overlap. While there's no doubt that particular brain regions (e.g., cortices, brainstem nuclei), networks (e.g., default mode network, attentional, sensorimotor), and circuits (e.g., corticothalamic), as well as neurophysiological processes (e.g., gamma oscillations) are at least necessary for human brains to generate consciousness, efforts to extend ToCs to other minds must involve a generalization and analysis of the biological details of such theories to test mappings of the theory onto functions of all cells (and thus organs). Aneurocentric formulations of ToCs are thus testable while enabling a comparative analysis of consciousness across very different systems.


[PAGE 13] Implications of consciousness in agents living in unconventional spaces

The kinds of functionality and competencies normally indicating a being with at least some degree of consciousness – learning, decision-making, causal emergence, navigation driven by valence and goal-directed activity – typically take place in the 3-dimensional space of conventional behavior. However, it is now known that many cells, tissues, and aneural organs can do all of these things in metabolic, physiological, transcriptional (gene expression), and anatomical spaces [19] (Figure 4). They formulate and pursue goals, solve new problems they have not seen before, exhibit taxis and aversive behavior with respect to regions of their state space, and align components towards large-scale goals (reviewed in [14, 47, 48, 100, 115, 167-169]). Indeed, it appears that the interesting properties of brains arose as a gradual evolutionary pivot of fundamental capacities (including active inference and homeodynamic goal-directedness) across problem spaces [74]. While difficult for us to visualize directly, because of sense organs and our own evolved theory-of-mind firmware focused on a fixed range of embodiments and behaviors involving obvious motility, it is essential to let advances in science expand our native perspective. To the extent that research in basal cognition and diverse intelligence reveals behavioral competencies in unconventional


[PAGE 14] spaces, we must be open to the applicability of ToCs to these scenarios. As seen in Table 1, and consistent with the very high conservation of mechanisms and algorithms between neurons and non-neural cells, no existing ToC rules out aneural substrate. For precisely the same reasons we routinely entertain the possibility of consciousness in brainy animals based on their behavior and its biophysical underpinning, we must consider the possibility that cells, tissues, organs, organoids, biobots, and a wide range of chimeric cyborg/hybrots architectures could have inner experience as they intelligently navigate, strive, achieve, and suffer in their own worlds of possibility. And indeed, as known from advances in the field of morphological computation [170-172], the structure of an agent's problem space has massive impact on their embodiment and cognition, which suggests that minds navigating unconventional spaces may not be easy for us to detect unaided.


[PAGE 14] Developing research programmes

This perspective, grounded in developmental and evolutionary biology of the biophysics underlying neural networks, has a number of implications for a research roadmap. The use of tools and concepts of neuroscience and behavioral science is already paying off in terms of empirical discoveries and new experimental vistas in these fields, for example in the use of the collective intelligence of cells navigating anatomical morphospace to impact birth defects, regeneration, and cancer (reviewed in [173-175]) and the investigation of learning and memory in gene-regulatory networks with possible impacts on a wide range of pharmacological use cases [176-179]. But to date, these have all been strictly 3rd-person perspective, standard science. It is time to extend consciousness studies and philosophy of mind to cell biology, regenerative medicine, and bioengineering.

An obvious next step is to use metrics from causal information theory and IIT to study the information flows during behavior in non-neural agents [180]. This has already begun, in work to measure information architecture [181] and causal emergence metrics in Xenobots [182] and gene-regulatory networks [183]. Many other substrates, such as calcium and bioelectric signaling during embryonic and regenerative morphogenesis [184], carcinogenic transformation [185, 186], and self-assembly of biobots [56, 57, 187, 188] remain to be tested. We also envision development of classic tools such as the mirror test, and variants of the Turing test, in spaces that make them applicable to cells and similar unconventional agents.

One of the key lynchpins in discussions of both AI and organoid consciousness has been the criterion of embodiment [72, 189-193]. Many have argued that engagement with a rich action space via a perception-action loop (including perceptual control [194] or active inference [195-197]) is critical for the formation of true agents with consciousness. We agree, but point out that movement in 3D space is not the only arena for this critical dynamic. It is possible that “disembodied” organoids for example, which offer no obvious behavior in 3D space, in fact display a kind of “locked in syndrome” [198] which makes


[PAGE 15] observers think there is no one inside, whereas they have an active life solving problems in gene expression, physiological, and other spaces. For the same reasons we seek to develop tools to identify inner perspective in human cases of locked in syndrome or coma [37, 38], we must broaden our perspective and create substrate-agnostic conceptual and experimental tools to detect, quantify, and characterize these processes across the diverse agential material of life, from subcellular molecular networks to organ systems. We hypothesize that the existing tools of the neuroscience of consciousness, combined with virtual reality tools to assist visualization of behavior in high-dimensional, unconventional spaces by human scientists, will be a powerful combination to begin to overcome our innate inability to see all but a tiny fraction of the endless forms most beautiful [199], of minds.

By loosening arbitrary constraints on the nature of conscious embodiments and the spaces within which they must navigate, the science of consciousness gains access to a wide range of beings that are alien in just the right amount. Many questions abound with respect to the kinds of minds that exo-biological life forms would have; while we don't have access to true aliens, we now have the opportunity to try to understand minds which are on the same evolutionary tree as us, and thus perhaps tractable, but will force us to expand and refine our conceptual apparatus because they are not tractable to the increasingly stale and constraining anthropocentric, brain-focused formalisms. The recognition of possible consciousness in living material more broadly will re-calibrate current debates about octopuses, crustaceans, etc. and raise fascinating questions about ethical relationships to this much broader class of beings.


[PAGE 15] Conclusion

Taking seriously the slow, gradual scale-up from single cells revealed by developmental and evolutionary biology makes the continuity thesis the null hypothesis. The high conservation of mechanisms and behaviors in brains all the way back to pre-cellular material implies that a kind of panpsychism, committed to understanding the scaling and transformation of embodied minds from physical dynamics, is not only viable but should be the baseline assumption. Competing ideas, relying on sharp phase transitions and brain-specific theories, need to specify principled reasons for discontinuities and explain “emergence” of novel natural kinds.

The state of the art in physiology and diverse intelligence research, combined with the compatibility of current ToCs with aneural substrates, suggests that consciousness may be common throughout the body. Our mind supervenes on a collection of cells, working together by means of a bioelectric network which aligns them toward larger cognitive light cones in abstract problem spaces. That architecture is ubiquitous throughout our bodies and throughout evolution. Thus, consciousness in a collective intelligence made of cells is not a wild claim – indeed, it is the only kind of consciousness we've ever seen, because each of us is a collective intelligence (of neurons). For all the


[PAGE 16] reasons discussed above, we can drop the part in parentheses from the list of requirements, and get on with the task of understanding collective intelligence in all of its general guises, and the ways in which it enables intelligence to come into the world.

But, it is often objected: “we don't feel our liver being conscious!”. While that is true, we don't feel each other being conscious either. Indeed, if the liver or its parts were capable of subjective experience, that point-of-view