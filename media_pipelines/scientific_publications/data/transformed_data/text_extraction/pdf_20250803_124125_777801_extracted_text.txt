GIVING SIMULATED CELLS A VOICE: EVOLVING
PROMPT-TO-INTERVENTION MODELS FOR CELLULAR CONTROL.
Nam H. Le
University of Vermont
Vermont, USA
namlehai90@gmail.com
Patrick Erikson
Tufts University
Boston, USA
Yanbo Zhang
Tufts University
Boston, USA
Michael Levin
Tufts University
Boston, USA
Josh Bongard
University of Vermont
Vermont, USA
May 6, 2025

ABSTRACT
Guiding biological systems toward desired states, such as morphogenetic outcomes, remains a
fundamental challenge with far-reaching implications for medicine and synthetic biology. While
large language models (LLMs) have enabled natural language as an interface for interpretable control
in Al systems, their use as mediators for steering biological or cellular dynamics remains largely
unexplored. In this work, we present a functional pipeline that translates natural language prompts
into spatial vector fields capable of directing simulated cellular collectives. Our approach combines a
large language model with an evolvable neural controller (Prompt-to-Intervention, or P2I), optimized
via evolutionary strategies to generate behaviors such as clustering or scattering in a simulated 2D
environment. We show that even with a limited vocabulary and simplified cell models, evolved P2I
networks can successfully align cellular dynamics with user-defined goals expressed in plain language.
This work offers a complete loop from language input to simulated bioelectric-like intervention to
behavioral output, providing a foundation for future systems capable of natural language-driven
cellular control.
Note: This is the authors' preprint version. The final version will appear in the ACM GECCO
Workshop Proceedings 2025.

[PAGE 1] 1 Introduction
Complex systems remain inherently difficult to predict and control [6]. Biological systems, despite being notoriously
complex and thus hard to control, have an advantage over inorganic complex systems in that their behavior can be
modified by a wide range of interventions across physical modalities (electrical, mechanical, chemical, vibrations,
thermal, optical) – applied across multiple scales, from molecular interactions to whole-body and even ecosystem-level
influences. However, traditional bottom-up approaches to biological control have predominantly focused on molecular
mechanisms at the cellular level, often neglecting the emergent behaviors that arise from the collective interactions
of cells. Recent insights from information theory and control systems suggest that higher levels of organization may
provide effective control points, where emergent dynamamics serve as interfaces for top-down regulation [5]. For
instance, collective behaviors such as those observed in wound healing, morphogenesis, and metastasis are driven by
localized interactions yet give rise to robust global patterns essential for life [19, 11]. Bridging these hierarchical levels
of control remains a key challenge for understanding and influencing emergent biological dynamics.
One way to discover the best angles from which to apply successful interventions to biological targets is to not
presuppose the scale and type of intervention. Rather, it could be efficacious to train AI to autonomously discover the
appropriate scale and type of intervention free of human investigator bias, as well as which intervention of that type,
and at that scale, yield the desired result.
It is very likely that different desired results will require different interventions of different kind and scale. Thus it
would be desirable to (1) develop an interface that allows investigators to rapidly articular and specify desied outcome;
(2) employ an AI model that could translate these desired outcomes into interventions likely to bring them about; and
(3) provide a complementary interface that renders the resulting system behavior in human-interpretable form.
In this paper, we present a framework that embodies these ideas in a simulated environment. Our approach-termed
ZapGPT-leverages natural language as the medium for interfacing with cellular dynamics. Specifically, natural
language prompts (e.g., “Cluster!") are translated into spatially distributed interventions via a Prompt-to-Intervention
(P2I) model, and the ensuing cellular dynamics are interpreted back into natural language using a Dynamics-to-Response
(D2R) model based on a video language model. While our experiments focus on a simplified task with a constrained set
of interventions and outcomes, they serve as an initial demonstration of a language-guided, evolutionary framework for
influencing decentralized behaviors in synthetic systems.
We further explore how evolutionary algorithms can be integrated to optimize the mapping from human prompts to cellu-
lar interventions. In our study, we focus on simple collective behaviors such as clustering and scattering—providing a
proof-of-concept that lays the groundwork for future investigations into more complex and nuanced language-to-cellular
dynamics transformations.

[PAGE 2] 2 Background and Related Work
Recent advances in developmental biology, bioelectricity, and multi-scale physiology suggest that biological systems
exhibit collective intelligence, integrating information across multiple scales to make adaptive decisions [13, 14].
Cells communicate through bioelectric, biochemical, and mechanical signals, dynamically shaping morphogenesis,
regeneration, and behavior. Understanding and harnessing these properties require a framework that enables high-level
communication with cellular collectives rather than micromanaging molecular mechanisms.
It has been shown recently that biological systems process information beyond the molecular scale, suggesting that
higher-level interventions can shape collective behavior without requiring direct genetic or molecular manipulations
[19, 3]. Bioelectric signaling, for instance, provides a powerful mechanism for influencing cellular decision-making,
enabling the reprogramming of anatomical structures and regenerative outcomes [12, 13]. Rather than focusing solely
on gene editing or biochemical pathways, researchers have explored methods for modulating bioelectric gradients to
guide self-organization and pattern formation in tissues [19, 11]. This shift from reductionist molecular control to
emergent, system-level regulation suggests the need for novel computational frameworks that can translate high-level
human intent into biologically meaningful interventions. Rather than prescribing specific molecular changes, such
frameworks should enable guided self-organization, allowing tissues to achieve target structures or behaviors based on
interpretable external cues.
Similar principles have been demonstrated in synthetic systems, where decentralized agents evolve complex behaviors
through local interactions and selection. For example, evolving neuronal controllers for Boid-like agents has shown
that coordinated group motion and adaptive dynamics can emerge from simple, bottom-up rules, without centralized
control or explicit objectives [10]. This line of work underscores the potential of evolutionary computation to generate
lifelike, adaptive behaviors offering a synthetic parallel to the self-organizing principles observed in biological
morphogenesis.
Advances in artificial intelligence (AI) and machine learning (ML) have enabled new ways to analyze and control
complex systems, including biological networks. Deep learning models have been applied to tasks such as protein
folding [29], cellular image analysis [16], and bioelectric signal interpretation [8]. However, most AI applications in
biology remain focused on data-driven pattern recognition rather than active control.
Beyond predictive modeling, evolutionary algorithms (EAs) offer a robust framework for optimizing biologically
meaningful interventions, experimental protocols, and control strategies for cellular behaviors [24, 1]. EAs have been
applied in fields such as synthetic biology [21, 2] and bioelectric pattern optimization [4], providing a mechanism for
tuning system-level parameters to achieve desired outcomes without requiring explicit mechanistic models.
Yet, a key challenge remains: while evolutionary algorithms can optimize interventions, they do not inherently provide
an intuitive way for human users to specify goals or interpret results. Most AI-driven approaches in biological control
either rely on rigid mechanistic models or produce opaque, uninterpretable policies. To address this, our work proposes
leveraging natural language as an intuitive interface for specifying objectives and evaluating outcomes.
Language-based interventions allow for adaptive, dynamic communication between human intent and complex systems,
bridging the gap between abstract symbolic goals and physical interventions. Inspired by this idea, our proposed
framework integrates large language models (LLMs) to generate structured interventions and vision-language models
(VLMs) to interpret the resulting system dynamics. Furthermore, evolutionary algorithms are employed to refine the
translation process from natural language to intervention. It is important to note that our approach is presented as a
preliminary, proof-of-concept demonstration within a constrained simulation setting, with the ultimate goal of scaling
to more complex, real-world scenarios.
The following section describes the key components of this framework and the experimental setup used to evaluate its
effectiveness.


[PAGE 3] 3 Experimental Methods
In this section we provide an overview of our approach, followed by a description of each component of the ZapGPT
pipeline (Fig. 1). Our experiments are conducted in a controlled simulated environment and serve as a proof-of-concept
for using language-guided, evolutionary optimization to influence system behavior.

[PAGE 3] 3.1 Framework Overview
The proposed framework establishes a bidirectional pipeline for translating high-level human intent into actionable
interventions and interpreting system dynamics into human-understandable symbolic descriptions. Although the
framework is designed to be generalizable to a wide range of complex systems, in this study we apply it to a simplified
setting.
The pipeline begins with a natural language prompt, such as “achieve clustering” (Fig. 1a), representing the desired
outcome for the system. This input is input to the Prompt-to-Intervention (P2I) model, which uses a language model to
generate system-specific interventions (e.g., vector fields for spatially distributed systems (Fig. 1b)). These interventions
influence the complex system (Fig. 1c) by guiding its initial state and shaping its dynamics over time (Fig. 1d).
Subsequently, the Dynamic-to-Response (D2R) model (Fig. 1e) processes the system dynamics and produces a human-
interpretable symbolic response (e.g., “system achieved clustering” (Fig. 1f). Finally, the pipeline computes a semantic
loss metric that quantifies the alignment between the original prompt and the generated response (Fig. 1g), enabling
iterative optimization of the P2I model.
This framework highlights two key interfaces: (1) translating human intent into actionable interventionsinterventions
through the P2I model, and (2) interpreting system dynamics into symbolic responses through the D2R model. The
complex system in between can take various forms, with interventions and behaviors adapted to the domain and the
specific problem being addressed. Together, these components provide a scalable method for aligning high-level human
intent with the dynamics of diverse systems. In this proof-of-concept study, we restrict our experiments to a simplified
set of interventions and responses, thereby focusing on the feasibility of the overall approach.


[PAGE 4] 3.2 Simulated Environment
To implement the pipeline, we conducted experiments in a simulated environment designed to study cellular behavior in
response to language-guided vector fields. The environment is a continuous 2D rectangular space (500 × 500 units)
with reflective boundaries to ensure cells remain within the simulation area.
The environment contains N = 100 circular cells (radiusr = 5 units), initialized with random positions and velocities.
Cells are influenced by external vector fields, represented as n × n grids (with n = 2, 3, 5, 10). Each grid cell contains
a vector that defines the direction and magnitude of the force acting on cells in that region. Interpolated field vectors
dynamically guide cell movement, overriding initial trajectories.
At each time step, cell positions are updated based on the vector field forces, reflective boundary conditions, and local
repulsion to prevent overlap. The simulation records metrics such as the average distance of cells and tracks cell
positions over time, which serve as quantitative measures for evaluating the system's response to the interventions.

[PAGE 4] 3.3 Prompt-to-Intervention (P2I) Model Architecture
The P2I model serves as an interface that translates natural language prompts into spatially actionable vector fields
- i.e., interventions that drive cellular dynamics. As illustrated in Figure 2, the model begins by encoding the input
prompt using a precomputed BERT embedding, yielding a 768-dimensional vector. This embedding is then processed
through a feed-forward neural network (FFN) that transforms the input into a flattened representation of the vector field.
The output is reshaped into a 3D tensor with dimensions (n, n, 2), where n × n denotes the resolution of the grid, and 2
represents the magnitude and direction of the vector in each grid cell.
By directly generating spatial interventions from natural language, the P2I model establishes a bridge between symbolic
instructions and cellular dynamics, forming a foundational component of the ZapGPT framework.

[PAGE 5] 3.4 Representing System Dynamics for Evaluation
To evaluate the performance of the P2I-D2R system, we focus on two key aspects of system dynamics: temporal
progression and final spatial configuration.
The first criterion, capturing immediate or temporal dynamics, is measured by the average pairwise distance metric:

Davg (t)
N N
1
N(N-1) ΣΣ x(t) – xj(t)\,
i=1 j=i+1
(1)

where N is the number of cells, and x₁(t) denotes the position of the i-th cell at time step t. This metric tracks whether
cells move closer together or spread apart over time, providing a quantitative measure of clustering or scattering trends.
The second criterion evaluates the final configuration of cells at the simulation's end, determining whether the cells
have formed a cohesive cluster or remain dispersed.
Both metrics are crucial for interpreting system behavior in ways that align with human expectations. Furthermore,
advances in vision-language models (VLMs) enable the translation of these quantitative metrics into concise natural
language descriptions, facilitating a more intuitive evaluation of the interventions.

[PAGE 5] 3.5 D2R and Fitness Evaluation
The Dynamics-to-Response (D2R) model evaluates the alignment between cellular behaviors and the original language
prompt. To achieve this, it leverages a pretrained vision-language model (VLM), Moondream2 [28], which interpret
simulation outputs (e.g., time-series plots and spatial configurations) and generate concise textual responses. These
responses, such as "Clustering" or "Scattering", are then compared with the input prompt to compute fitness scores.
Among various available vision-language models (VLMs)—such as GPT-4 Vision [17] and LLava [15]—we selected
Moondream2 [28] for its lightweight architecture, fast inference, and suitability for structured visual inputs like
simulation plots. By constraining its output to a one-word label (e.g., “Clustering” or “Scattering”), Moondream2
integrates well with our binary evaluation framework and enables efficient iteration during training.


[PAGE 5] 3.5.1 Restricting Output to One Word
Our task is defined by simple, one-word outputs (either "Clustering" or "Scattering"). To ensure the alignment between
the input prompt and the D2R output, we measure their similarity using a loss function, such as cosine similarity.
However, differences in dimensionality between embeddings can cause inconsistent results, especially in tasks with
fixed, straightforward objectives [26].
To mitigate this, we employ prompt engineering to force the D2R output to a single word–directly matching the dimen-
sionality of the input prompt. This allows us to apply binary or categorical loss functions, providing a straightforward
and reliable evaluation framework.

[PAGE 5] 3.5.2 Input to D2R: Visual and Textual Prompts
The D2R model receives two types of inputs: (1) simulation-derived visualizations, and (2) minimal textual prompts to
elicit one-word responses. The visual inputs include a time-series distance plot (Figure 3) and a final cell position plot
overlaid with the vector field (Figure 4). Prompts shown in the figures are designed to guide the VLM toward binary
classification “clustering” or “scattering”—which aligns with our evaluation framework.

[PAGE 5] 3.5.3 Fitness Evaluation
The fitness evaluation measures the similarity between the original prompt (as processed by the P2I model) and the
D2R model's response. In our experimental setup, an epoch is defined as a complete simulation run consistint of the
following steps:
1. An environment is randomly initialized.
2. The P2I model translates the input prompt into a corresponding vector field intervention.
We validated Moondream2's performance through a testbed evaluation using artificial plots of average pairwise distance trends
and final spatial configurations of clustering and scattering behaviors. These tests confirmed the model's ability to interpret visual
data accurately and produce the expected responses. Code and evaluation results will be released at https://github.com/
namlehai90/moondream-score-validation.

[PAGE 5] 3.4 Representing System Dynamics for Evaluation
To evaluate the performance of the P2I-D2R system, we focus on two key aspects of system dynamics: temporal
progression and final spatial configuration.
The first criterion, capturing immediate or temporal dynamics, is measured by the average pairwise distance metric:

Davg (t) = 1
N(N-1) ΣN i=1 ΣN j=i+1 |xi(t) – xj(t)|, (1)

where N is the number of cells, and xi(t) denotes the position of the i-th cell at time step t. This metric tracks whether
cells move closer together or spread apart over time, providing a quantitative measure of clustering or scattering trends.
The second criterion evaluates the final configuration of cells at the simulation's end, determining whether the cells
have formed a cohesive cluster or remain dispersed.
Both metrics are crucial for interpreting system behavior in ways that align with human expectations. Furthermore,
advances in vision-language models (VLMs) enable the translation of these quantitative metrics into concise natural
language descriptions, facilitating a more intuitive evaluation of the interventions.

[PAGE 5] 3.5 D2R and Fitness Evaluation
The Dynamics-to-Response (D2R) model evaluates the alignment between cellular behaviors and the original language
prompt. To achieve this, it leverages a pretrained vision-language model (VLM), Moondream2 [28], which interpret
simulation outputs (e.g., time-series plots and spatial configurations) and generate concise textual responses. These
responses, such as "Clustering" or "Scattering", are then compared with the input prompt to compute fitness scores.
Among various available vision-language models (VLMs)—such as GPT-4 Vision [17] and LLava [15]—we selected
Moondream2 [28] for its lightweight architecture, fast inference, and suitability for structured visual inputs like
simulation plots. By constraining its output to a one-word label (e.g., “Clustering” or “Scattering”), Moondream2
integrates well with our binary evaluation framework and enables efficient iteration during training.

[PAGE 5] 3.5.1 Restricting Output to One Word
Our task is defined by simple, one-word outputs (either "Clustering" or "Scattering"). To ensure the alignment between
the input prompt and the D2R output, we measure their similarity using a loss function, such as cosine similarity.
However, differences in dimensionality between embeddings can cause inconsistent results, especially in tasks with
fixed, straightforward objectives [26].
To mitigate this, we employ prompt engineering to force the D2R output to a single word–directly matching the dimen-
sionality of the input prompt. This allows us to apply binary or categorical loss functions, providing a straightforward
and reliable evaluation framework.

[PAGE 5] 3.5.2 Input to D2R: Visual and Textual Prompts
The D2R model receives two types of inputs: (1) simulation-derived visualizations, and (2) minimal textual prompts to
elicit one-word responses. The visual inputs include a time-series distance plot (Figure 3) and a final cell position plot
overlaid with the vector field (Figure 4). Prompts shown in the figures are designed to guide the VLM toward binary
classification “clustering” or “scattering”—which aligns with our evaluation framework.

[PAGE 5] 3.5.3 Fitness Evaluation
The fitness evaluation measures the similarity between the original prompt (as processed by the P2I model) and the
D2R model's response. In our experimental setup, an epoch is defined as a complete simulation run consistint of the
following steps:
1. An environment is randomly initialized.
2. The P2I model translates the input prompt into a corresponding vector field intervention.
We validated Moondream2's performance through a testbed evaluation using artificial plots of average pairwise distance trends
and final spatial configurations of clustering and scattering behaviors. These tests confirmed the model's ability to interpret visual
data accurately and produce the expected responses. Code and evaluation results will be released at https://github.com/
namlehai90/moondream-score-validation.


[PAGE 6]
3. The intervention is applied to the environment, and the simulation is run for 500 steps, allowing the cellular
dynamics to evolve.
4. At the end of the simulation, the D2R model processes the resulting dynamics and generates a one-word
response (e.g., "Clustering" or "Scattering").
For each epoch, we assign a binary score Ri = 1 where:
• Ri = 1 if the D2R response matches the input prompt, and
• Ri = 0 otherwise.

[PAGE 7]
To mitigate randomness and ensure reliable evaluation, we repeat this process over E = 30 epochs and compute the
average fitness score as follows:

Raverage = 1/E ΣE i=1 Ri (2)

This approach provides a robust measure of the alignment between the human-specified prompt and the system's
emergent behavior.
For experiments involving both the distance plot and the final position plot, we combine the rewards to balance their
contributions:

Rcombined = αRdistance + βRposition, (3)

where α = 0.5 and β = 0.5. This combined reward function captures both the temporal dynamics and the final spatial
configuration, providing a robust metric for evaluating the alignment between human intent and system behavior.
With this fitness/loss function in place, the next step is to optimize the vector fields generated by the Prompt-to-
Intervention (P2I) model to better achieve the desired outcomes.

[PAGE 7] 3.6 Evolutionary Algorithms
We model our problem as optimizing the P2I model so that it can generate vector fields which, when applied to guide
cellular dynamics, yield behaviors that closely match the original input prompt as the intended outcome. In other words,
our objective is to find an optimal configuration of the P2I model's neural network weights so that the resulting cellular
dynamics align with the goal (e.g., 'clustering'). It is important to note that we are not directly optimizing the vector
fields themselves; instead, we optimize the P2I model to produce the desired interventions.
This optimization problem is well-suited for evolutionary algorithms (EAs), which are effective in exploring high-
dimensional, nonlinear search spaces. Unlike reinforcement learning (RL) methods—often associated with large
language models (LLMs)—traditional backpropagation is challenging in our pipeline due to sparse rewards and
non-differentiable components (e.g., the emergent dynamics of cellular behavior and the evaluations from the Dynamics-
to-Response (D2R) model) [22, 24]. EAs, which rely solely on reward evaluations, thus provide an attractive alternative
by bypassing the need for gradient propagation.

[PAGE 7] 3.6.1 (1+1) Evolution Strategy
Our initial approach employs the simple (1+1) Evolution Strategy (ES) [18] with an adaptive mutation step size to
optimize the P2I model's weights. This approach is chosen for its intuitive hill-climbing behavior, making it suitable for
initial experiments with intermediate rewards (e.g., those based solely on the distance plot).
The (1+1)-ES uses mutation as its sole evolutionary operator. Key parameters and the optimization process are detailed
in Algorithm 1.
While (1+1)-ES demonstrated good performance with simpler vector field configurations (e.g., 2 × 2 and 3 × 3), our
experiments showed that it struggled to achieve optimal clustering behavior in more complex settings (e.g., 5 × 5 and
10 × 10 grids). This limitation motivates the use of more robust optimization methods.

[PAGE 7] 3.6.2 Genetic Algorithms
For larger search spaces, we implemented a real-valued genetic algorithm (GA) with arithmetic crossover [7] to optimize
the P2I model's weights. The key components of our GA are as follows:
• Pop_size = 20: Twenty P2I weight candidates are randomly generated as the initial population.
• Selection: Tournament selection is performed with a tournament size of 8.
• Crossover: Arithmetic crossover is applied to generate offspring:
Wchild = αWparent1 + (1 - α)Wparent2,
where α ∈ [0, 1] is chosen randomly.
• Mutation: Gaussian noise is added to weights:
Wmutated = Woriginal + N(0, σ),
with σ = 0.1.
• Fitness Evaluation: Each individual is evaluated using the combined reward function derived from both the distance plot
and the final position plot.

[PAGE 8]
The GA iteratively performs selection, crossover, mutation, and fitness evaluation for a 50 generations. By maintaining
a diverse population and utilizing crossover operations, the GA effectively explores larger search spaces and overcomes
some of the limitations observed with (1+1)-ES.

[PAGE 8] 4 Experimental Results

[PAGE 8] 4.1 Evaluating (1+1)-ES with Single Criterion (Immediate Reward)
We begin by assessing the simplest setting, where we use (1+1)-ES to optimize the P2I model with only an immediate
reward-derived from the average distance plot. Each vector field configuration (2 × 2, 3 × 3, 5 × 5, 10 × 10) was
evaluated over 30 random seeds, and the results were averaged to mitigate randomness.2
To monitor optimization progress, we report the best fitness values over generations for each configuration. Additionally,
we conducted a wilcoxon signed-rank test comparing the fitness at generation 0 with that at the last generation to assess
the statistical significance of the improvements.
Across all vector field sizes, (1+1)-ES consistently improves fitness over generations, as shown in Figure 5. The
Wilcoxon signed-rank test (p-value < 0.05) confirms that the final fitness distributions are statistically significantly better
than the initial ones. These results indicate that, when evaluated solely on the distance plot, (1+1)-ES can effectively
optimize the clustering behavior in our simulated environment.
However, while these results are promising for the immediate reward criterion, they do not necessarily guarantee that the
cellular dynamics will converge to a single cohesive cluster. This observation motivates the evaluation of an additional
criterion.

[PAGE 9] 4.2 Evaluating (1+1)-ES with Combined Rewards
To better capture both the progression of cellular behavior and the final spatial arrangement, we extended the evaluation
to include a combined reward. This combined reward function comprises:
• An immediate reward based on the distance plot, which encourages cells to move closer together over time.
• A final reward based on the final spatial configuration, ensuring that cells form a single cohesive cluster rather
than multiple small groups.
We tested vector field settings of 2 × 2, 3 × 3, and 5 × 5 over 30 random seeds. Figure 6 illustrates the evolution of the
combined fitness scores, including error bars that capture the variability across runs. Statistical testing again confirmed
that the improvements from generation 0 to the final generation were significant (p < 0.05).
The results reveal that for smaller grids (2 × 2 and 3 × 3), (1+1)-ES successfully balances both criteria, leading to the
formation of a single cohesive cluster. However, for the 5 × 5 grid, although the overall fitness improves, the final spatial

[PAGE 9] Figure 5: Best fitness scores across generations for different vector field sizes, using (1+1)-ES and average distance metric.

[PAGE 9] 4.2 Evaluating (1+1)-ES with Combined Rewards

To better capture both the progression of cellular behavior and the final spatial arrangement, we extended the evaluation to include a combined reward. This combined reward function comprises:
• An immediate reward based on the distance plot, which encourages cells to move closer together over time.
• A final reward based on the final spatial configuration, ensuring that cells form a single cohesive cluster rather than multiple small groups.

We tested vector field settings of 2 × 2, 3 × 3, and 5 × 5 over 30 random seeds. Figure 6 illustrates the evolution of the combined fitness scores, including error bars that capture the variability across runs. Statistical testing again confirmed that the improvements from generation 0 to the final generation were significant (p < 0.05).

The results reveal that for smaller grids (2 × 2 and 3 × 3), (1+1)-ES successfully balances both criteria, leading to the formation of a single cohesive cluster. However, for the 5 × 5 grid, although the overall fitness improves, the final spatial configuration (position score) remains suboptimal. This suggests that while (1+1)-ES can reduce pairwise distances effectively, it struggles to enforce global cohesion in more complex scenarios.

[PAGE 10] 4.3 Genetic Algorithms on 5x5 and 10x10 vector fields

Building on the limitations observed with (1+1)-ES in higher-dimensional settings, we investigated a Genetic Algorithm (GA) as an alternative. In our GA experiments, we focus on configurations where (1+1)-ES underperforms, specifically for 5 x 5 and 10 x 10 vector fields.

Using the same combined reward function, we tracked overall fitness, distance scores, and position scores over generations. As shown in Figure 7, GA-driven evolution improved both the overall fitness and the position scores more effectively than (1+1)-ES. Notably, in the 10 × 10 setting, the position score steadily increased, suggesting that the crossover mechanism in the GA helps the population explore solutions that balance both local proximity and global cohesion.

[PAGE 11] Statistical tests comparing the initial and final generations yielded p-values < 0.0001, indicating a significant improvement in both metrics. Although these results are preliminary, they highlight the potential of GA-based optimization to overcome the limitations of local search methods like (1+1)-ES in more complex vector field configurations.

A key advantage of GAs is evident in the larger vector field setting (10 × 10), where the position score increases steadily, indicating an ability to achieve a well-structured cluster compared to (1 + 1)-ES. This suggests that crossover mechanisms here contribute to a more effective search process, helping the population discover solutions that balance both local and global structure.

Summary: Our experimental results demonstrate that while (1+1)-ES is effective in simple settings and for optimizing immediate rewards, its performance deteriorates when the task requires balancing multiple objectives in higher-dimensional spaces. In contrast, Genetic Algorithms show a clear advantage in these more challenging scenarios by effectively guiding both local and global aspects of cellular dynamics. These findings establish a preliminary proof-of-concept for our language-guided, evolutionary framework, while also outlining the need for further research to address scalability and robustness in more complex systems.


[PAGE 11] 5 Discussion and Future Directions

[PAGE 11] 5.1 Applying P2I-D2R to Real-World Systems

While our current work is based on a simplified simulation, the principles of the P2I-D2R framework have broader applicability:

Real-Cell Biology Experiments: In biological research, understanding cellular responses to environmental interventions is crucial. A P2I-driven system could generate optimized intervention schedules (e.g., for releasing chemical signals or drugs) in a bioreactor. The resulting cellular dynamics, such as changes in intracellular signaling, can be recorded and analyzed by D2R to inform further optimization [25, 9].

Swarm Robotics: In swarm robotics, controlling distributed agents to achieve coordinated behaviors like clustering, dispersing, or coordinated navigation is a significant challenge. The same framework could generate control signals for robotic swarms, with D2R evaluating the emergent formations. This language-guided approach could enable high-level control over complex, dynamic multi-agent systems [23, 27].

By demonstrating that language-guided intervention and evaluation can generalize across synthetic and real-world domains, our study highlights the broader implications of integrating natural language interfaces with dynamic system control.

[PAGE 11] 5.2 Generalization and Task Expansion

Our experiments demonstrate the feasibility of the ZapGPT framework for steering collective cellular behavior based on natural language prompts. While the present study focuses on a constrained scenario using simple instructions (e.g., clustering), it lays the groundwork for translating language to spatial interventions through learned vector fields.

In ongoing extensions, we introduce multi-word prompts (e.g., clustering slowly, scattering quickly) to explore how the model handles behaviorally distinct but linguistically similar instructions. Although such prompts may be close in embedding space, they often correspond to qualitatively different control strategies in simulation. For instance, "scattering slowly" and "scattering quickly" differ subtly in language but require distinct intervention dynamics-highlighting a disconnect between semantic and behavioral similarity.

[PAGE 12] Training a single P2I model on multiple behaviors-especially those with conflicting goals can lead to interference, where learning one behavior degrades another. To address this, future work will explore training strategies such as modular architectures, prompt-conditioned layers, and curriculum-based evolution to support multi-behavior learning.

Currently, we use domain-specific metrics (e.g., average intercellular distance) combined with restricted binary captions from a vision-language model (VLM) to evaluate behavioral alignment. This strategy enables clean optimization but depends on constrained language and engineered reward functions, which limit scalability.

To move beyond this, we plan to use flexible, language-grounded evaluators that allow both prompts and outputs to take natural language form. One approach involves using a VLM such as Moondream to generate a free-form caption of the simulation outcome, followed by a second model (e.g., Ollama or DeepSeek-R1) that compares the caption to the prompt. Another strategy leverages CLIP [20], framing the prompt as a text input and the simulation snapshot as an image, using CLIP's similarity scores to assess alignment.

These alternatives eliminate the need for handcrafted priors but introduce a new challenge: ensuring that semantic similarity reflects behavioral success. For example, if a prompt says “form a cluster” but the VLM caption is “cells are spreading out," some embedding-based methods may still assign a high similarity score, leading to misleading optimization signals. Designing evaluators that are both behaviorally accurate and semantically meaningful is a key direction for future work.

With improved scoring, we aim to test generalization across semantically diverse instructions. For instance, the model could be trained on "form a cluster" and tested on variants such as "group together" or opposites like "spread apart." This allows us to examine not only success but also whether the model internalizes the structure of natural language and maps it to behavior accordingly.

Lastly, while this paper centers on short, abstract prompts under the assumption that they are easier to learn, they may in fact present greater ambiguity due to their lack of context. Richer prompts (e.g., "form a tight group near the center") provide more linguistic structure and may lead to faster and more robust learning. Future work will explore reversing the learning order-training on descriptive prompts first, then testing generalization to abstract forms like “cluster.” This mirrors how humans often ground abstract language through experience before understanding symbolic commands.

[PAGE 13] Together, these directions will advance ZapGPT toward more expressive, generalizable, and interpretable control of complex collective systems using natural language.

[13] References
[1] Josh Bongard, Victor Zykov, and Hod Lipson. Resilient machines through continuous self-modeling. Science,
314(5802):1118–1121, 2006.
[2] Hongqing Cao, Francisco J Romero-Campero, Stephan Heeb, Miguel Cámara, and Natalio Krasnogor. Evolving
cell models for systems and synthetic biology. Systems and synthetic biology, 4:55–84, 2010.
[3] Chris Fields, Johanna Bischof, and Michael Levin. Morphological coordination: a common ancestral function
unifying neural and non-neural signaling. Physiology, 35(1):16–30, 2020.
[4] Hananel Hazan and Michael Levin. Exploring the behavior of bioelectric circuits using evolution heuristic search.
Bioelectricity, 4(4):207–227, 2022.
[5] Erik Hoel and Michael Levin. Emergence of informative higher scales in biological systems: a computational
toolkit for optimal prediction and control. Communicative & Integrative Biology, 13(1):108–118, 2020.
[6] Erik P Hoel, Larissa Albantakis, William Marshall, and Giulio Tononi. Can the macro beat the micro? integrated
information across spatiotemporal scales. Neuroscience of Consciousness, 2016(1):niw012, 2016.
[7] John H Holland. Genetic algorithms. Scientific american, 267(1):66–73, 1992.
[8] K Kalaivani, Pravin R Kshirsagarr, J Sirisha Devi, Surekha Reddy Bandela, Ilhami Colak, J Nageswara Rao, and
A Rajaram. Prediction of biomedical signals using deep learning techniques. Journal of Intelligent & Fuzzy
Systems, 44(6):9769–9782, 2023.
[9] Hedi Karoui, Pankaj Singh Patwal, BVVS Pavan Kumar, and Nicolas Martin. Chemical communication in
artificial cells: basic concepts, design and challenges. Frontiers in Molecular Biosciences, 9:880525, 2022.
[10] Nam H. Le, Richard Watson, Mike Levin, and Chrys Buckley. Emergent collective reproduction via evolving
neuronal flocks, 2024.
[11] Michael Levin. Reprogramming cells and tissue patterning via bioelectrical pathways: molecular mechanisms and
biomedical opportunities. Wiley Interdisciplinary Reviews: Systems Biology and Medicine, 5(6):657–676, 2013.
[12] Michael Levin. The computational boundary of a "self": developmental bioelectricity drives multicellularity and
scale-free cognition. Frontiers in psychology, 10:2688, 2019.
[13] Michael Levin. Bioelectric signaling: Reprogrammable circuits underlying embryogenesis, regeneration, and
cancer. Cell, 184(8):1971–1989, 2021.
[14] Michael Levin. Collective intelligence of morphogenesis as a teleonomic process. 2022.
[15] Haotian Liu, Chunyuan Li, Yuheng Li, Bo Li, Yuanhan Zhang, Sheng Shen, and Yong Jae Lee. Llava-next:
Improved reasoning, ocr, and world knowledge, January 2024.
[16] Erick Moen, Dylan Bannon, Takamasa Kudo, William Graf, Markus Covert, and David Van Valen. Deep learning
for cellular image analysis. Nature methods, 16(12):1233–1246, 2019.
[17] OpenAI. Gpt-4 technical report, 2024.
[18] Andreas Ostermeier, Andreas Gawelczyk, and Nikolaus Hansen. A derandomized approach to self-adaptation of
evolution strategies. Evolutionary Computation, 2(4):369–380, December 1994.
[19] Giovanni Pezzulo and Michael Levin. Top-down models in biology: explanation and control of complex living
systems above the molecular level. Journal of The Royal Society Interface, 13(124):20160555, 2016.
[20] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,
Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language
supervision. In International conference on machine learning, pages 8748–8763. PmLR, 2021.
[21] Thomas S Ray. An evolutionary approach to synthetic biology: Zen and the art of creating life. Artificial Life,
1(1_2):179-209, 1993.
[22] Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, and Ilya Sutskever. Evolution strategies as a scalable
alternative to reinforcement learning. arXiv preprint arXiv:1703.03864, 2017.
[23] Melanie Schranz, Martina Umlauft, Micha Sende, and Wilfried Elmenreich. Swarm robotic behaviors and current
applications. Frontiers in Robotics and AI, 7:36, 2020.
[24] Kenneth O Stanley, Jeff Clune, Joel Lehman, and Risto Miikkulainen. Designing neural networks through
neuroevolution. Nature Machine Intelligence, 1(1):24–35, 2019.
[25] Anuradha Subramanian, Joseph A Turner, Gaurav Budhiraja, Sanjukta Guha Thakurta, Nicholas P Whitney, and
Sai Siddhartha Nudurupati. Ultrasonic bioreactor as a platform for studying cellular response. Tissue Engineering
Part C: Methods, 19(3):244-255, 2013.
[26] Federico Tessari and Neville Hogan. Surpassing cosine similarity for multidimensional comparisons: Dimension
insensitive euclidean metric (diem). arXiv preprint arXiv:2407.08623, 2024.
[27] Vito Trianni, Roderich Groß, Thomas H Labella, Erol Şahin, and Marco Dorigo. Evolving aggregation behaviors
in a swarm of robots. In Advances in Artificial Life: 7th European Conference, ECAL 2003, Dortmund, Germany,
September 14-17, 2003. Proceedings 7, pages 865–874. Springer, 2003.
[28] vik. moondream2 (revision 92d3d73), 2024.
[29] Jinbo Xu. Distance-based protein folding powered by deep learning. Proceedings of the National Academy of
Sciences, 116(34):16856–16865, 2019.