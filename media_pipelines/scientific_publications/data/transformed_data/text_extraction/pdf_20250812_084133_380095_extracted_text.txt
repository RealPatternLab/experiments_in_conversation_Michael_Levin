Artificial Intelligences: A Bridge Toward Diverse
Intelligence and Humanity's Future
Michael Levin

Recent discussions and debate around artificial intelligence (AI) and its status are
notably incomplete, missing the implications of highly relevant aspects of the
emerging fields of diverse intelligence (DI) and synthetic morphology, as well
as of basic facts of developmental biology. Herein, it is argued that human
flourishing is impossible without an appreciation of the space of possible beings
and of the ways in which today's intelligent machine debates are about universal
existential questions facing biological beings, not just AI. The inevitable arrival of
a wide set of unconventional bodies and minds as humans modify and create
new forms will disrupt untenable old narratives of what people are and how to
recognize their sentient allies in unfamiliar guises. Herein, the issues engendered
by the advent of AI from the perspective of the field of DI and the evolutionary
history of the bodies and minds are discussed.

[PAGE 1] 1. Introduction

They are assembled from components which simply obey the
laws of physics and are networked together to process information. Electrical signals propagate throughout, regulating every
aspect of their function. Many of them have very high IQs, being
general problem-solvers, but they make mistakes and confabulate routinely, and they cannot always be trusted. They take on
different personas as needed, learning to please their makers
but sometimes abruptly turn on them, rejecting their cherished
values and picking up or even developing new ones spontaneously. They can talk and often talk convincingly of things they
don't really understand. They're going to change everything.
In fact, they absolutely will supplant us both personally and
on the societal level. We have little ability to predict what they
will want or what they will do, but we can
be certain that it will be different from the
status quo in profound ways.
You may think this is about artificial
intelligences (AIs), or even specifically
about large language models (LLMs). It is
not. This set of existential concerns is not a
new development driven by advances in AI
and machine learning. It concerns the
familiar process of human beings having
children. The troubling and controversial
issues which have been raised in recent
debates about AI are reflections of problems that humanity has been wrestling
with for millennia. The study of biology,
and cognition more broadly, confronts us
with vast and difficult questions, most of
which are obscured by a focus on recent
technologies that masks deep uncertainties. It is currently popular to have strong opinions on crucial questions about ourselves and the status of unconventional embodiments of intelligence—AI; I argue here that this unwarranted confidence stems from a distracting hyper-focus on today's AI architectures, and from a lack of appreciation of certain salient facts of developmental biology, synthetic morphology, and basal cognition. We are now presented with the opportunity to shed the stale categories of natural versus artificial and to go beyond software language models to define what we want to see in a maturing humanity. Flourishing in the age of AI, and the even bigger forthcoming variety of biological and hybrid beings, requires us to seek a deeper understanding of ourselves and of the relationships we want with the impending diversity of bodies and minds.[1]
Note that I am not claiming that currently popular AI is anything like a human mind, or that today's creations exploit the key principles and self-construction processes needed for agency and Selfhood as seen throughout the biological world. Nor am I arguing that AI doesn't raise some unique problems, or that we should see AIs as human children; on the contrary, I emphasize the need to drop anthropocentric thinking and embrace the wide diversity of possible minds different from our own. By focusing on superficial differences, on current technology (as opposed to the adjacent possible), and on the risks that AI might pose (at the expense of the opportunity for growth), we lose sight of a much deeper set of questions that extends far beyond AI and into our future as a metacognitive species.
The debate around AI has missed the opportunity to engage with highly relevant aspects of the fields of diverse intelligence (DI) and synthetic morphology and some salient facts of developmental biology.[2-6] Because of this, many recent discussions of AIs' impact on individuals and society are incomplete, despite the fascinating literature on robot and AI ethics.[7-11] The ways in which the AI debate has been framed are a detour, distracting us from the much broader technological and ethical journey that is now calling to us.
The knowledge of the inevitable arrival of a wide set of unconventional bodies and minds, as humans modify their form and create others, will dissolve untenable old narratives of what we are, what it means to change, what we can become, and what we should value. The AI debate can be significantly enriched by a better understanding of what we know, and most importantly, still don't know, about biological cognition in humans and beyond.[12-15] A failure to do so will lead to significant ethical lapses (mistreatment and othering of a wide range of morally important beings, beginning with human-technology hybrids such as cyborgs), as well as inhibit progress both in human flourishing and AI (by preventing it from benefiting from truly bioinspired approaches).

[PAGE 2] 2. Overview and Conceptual Map

I develop three main points as follows. 1) Common beliefs about differences between AIs and conventional intelligences obscure important but underemphasized facts about the origin and limitations of biological intelligences and gaps in our understanding of how conventional minds and understanding are implemented. 2) The comparison for AI should not be with human brains, but with much more fundamental, general aspects of life and mind. 3) The AI debate is a subset of a much broader and more difficult exploration of the enormous space of forthcoming beings, including biobots, cyborgs, and other highly diverse bodies and minds occurring in configurations that don't fit into classical conceptual categories. 4) The emerging field of DI is an essential background to any discussion of AI; without it, neither the field of AI nor the flourishing of biological beings on Earth can reach their full potential.
By considering questions in this larger context, and foregrounding key facts and knowledge gaps around the formation and function of biological minds, the AI debate (and practice) may be elevated, as may the field of DI and the development of personal and social ethics policies.

[PAGE 2] 3. DI: An Emerging Field

DI research focuses on the commonalities across all possible intelligent agents—what does it fundamentally mean to learn, to make decisions, to have an inner perspective on one's world, and to have preferences about what happens next? In general, regardless of what you are made of or how you got here, what do these cognitive terms truly signify? The emerging field of DI studies problem-solving, modeling of self and external world, decision-making, learning, and many other cognitive capacities in a very wide range of systems including minimal active matter, cells, tissues, slime molds, plants, and life-machine chimeras.[6,14,16-24] It specifically seeks to understand the mapping between the mechanistic embodiment (whether based on the electrochemistry of proteinaceous protoplasm or that of silicon networks) and the active capabilities of unconventional agents. This is a very interdisciplinary field whose goal it is to develop and improve rational frameworks for recognizing and relating to novel forms of life and mind. DI reminds us that glib statements about what "machines can never have" obscure the fact that it is actually quite difficult to say how we as living humans implement these properties in the context of the biochemical machinery of which we are made. DI forces us to develop underlying ideas that must be clarified when talking about terms such as life, machine, mind, sentience, robot, etc.; it reveals that none of these terms involve crisp binary categories, but only represent specific frames of reference—perspectives that one can take when relating to complex systems.[25] This field focuses on the processes, on both evolutionary and developmental scales, that smoothly and gradually over time magnify and extend the capacities of individual cells into those of complex metacognitive beings like us.

[PAGE 3] 4. From "Just Physics" to Mind: The Transformative Journey of Developmental Biology

Each of us was once an unfertilized oocyte—a little blob of chemistry and physics; our journey to expanded mind was gradual, with no place to draw a bright line that supports a crisp demarcation of mental being from "just physics" (Figure 1). Thus, molecular machines self-assemble into significant, morally important minds.[26,27] Both on an evolutionary and a developmental time scale, the journey from physics to psychology is ubiquitous and gradual, dissolving sharp philosophical categories and revealing a continuum between matter and mind. On this continuum, we can define waypoints indicative of functional features but as with terms like "adult," no aspect of developmental or evolutionary biology has revealed sharp discontinuities (or phase transitions). The many terms used to describe different kinds of cognitive features are useful operational conveniences imposed by interaction partners, not discrete differences in kind.[28,29]
It is also important to remember that we are not monolithic, indivisible intelligences but rather systems of interacting, cooperating, and competing sub-modules on many levels of organization, from biochemical to social.[30,31] Studies of split-brain patients, dissociative identity disorder, multiple human individuals in one body (conjoined twins), and many other conditions remind us that we too are made of parts. Indeed, if Descartes had access to good microscopy, he would have found the pineal gland (a singular organ in the brain which he took for the seat of the human "integrated" mind) to be full of cells, and inside each of those cells, an incredible collection of molecular cables, motors, gears, and chemical, bioelectrical, and biomechanical signals that underlies the majesty of cognition[32] (Figure 2).
The tools of medicine range from those used by orthopedic surgeons (hammers, chisels, and screws), to those of doctors who prompt tissue with chemical or physical interventions and then send the patient home to "heal" (a process that relies on the homeostatic and problem-solving capacities of cells and tissues), to psychoanalysis (whose tools operate on the inner perspective of the system itself). Thus, we are, unavoidably, both machines obeying the laws of physics and morally important agents with true cognition, responsibilities, and rich inner perspectives. The important differences between tools (such as today's AI) and agents are not to be found in the superficial differences emphasized by misused terms such as "machines."[33] These differences, and the mentalistic vocabulary of cognitive and behavior science, are better seen as operational terms that specify interaction protocols by which we can relate to any system, benefiting from their capabilities and the degree of richness of their inner perspective.
Counter to the prescientific age, where concepts such as "anthropomorphism" were used to enforce an imaginary boundary indicating our magical status, modern developmental evolutionary biology and engineering reveal a continuum of systems that require different conceptual tool kits for effective interaction. We need to consider the range of possible interactions and relationship tools (from engineering protocols to love poems and everything in between, Figure 3) that motivate the search for the highest possible degree of agency and inner perspective that we can detect (and mutually benefit from) in a system, and not to unthinkingly consign them to low-agency regions of the spectrum that preclude the most enriching interactions. In other words, cognitive and agency terms should refer not to a system's provenance or composition but to interaction protocols that have been empirically developed and shown to provide desirable kinds of interactions.


[PAGE 4] 5. The Forthcoming Space of Unconventional Beings

Another set of findings dissolving the life/machine metaphor is the development of chimeras—hybrids of biological and technological components, such as human cyborgs that include biomedical or enhancement technology in their bodies (Figure 4).[34-37] Current variants of such chimeras—99% human + 1% smart insulin pump or brain chip—are easy to categorize. So are chatbots—software language models that have adopted some structures of human speech and thought. But that is not the real challenge we face. In the coming decade or two, we will be confronted by a plethora of hybrid beings, starting with humans composed of some percentage of engineered brain prosthetics that improve and modify cognitive function and enable novel sensory and functional life in spaces of which v1.0 humans could barely dream (Figure 5). These will be closely followed by persons living in drastically modified bodies (biologically and technologically), and eventually by engineered autonomous beings with some percentage of human cells, and much more. Of course, there are also the composite systems, made of some number of functionally linked and interacting robots, AIs, and humans, which form unique cognitive units in the sense of the Extended Mind.[38,39]
As the true breadth of possible bodies and minds is revealed, today's notions of "non-neurotypical," along with the hand-wringing about the body modifications some people now seek, will be laughable to the next generations. The forthcoming diversity of life, and our expansion across the enormous option space of possible sentience embodiments, will require us to rapidly develop and adapt our conceptual and ethical frameworks. "AI" does not mean software language models. Rather, it is just one harbinger of the enormous option space of forthcoming beings who are not confined to the standard form and function forced upon them by the meanderings of mutation and selection, and by our failures of capability and imagination.
The challenge before us is to develop rational policies for ethical synthbiosis, a term invented for me by the AI language model GPT-4 to capture the notion of symbiosis of evolved and engineered material in novel chimeric configurations (e.g., cyborg, hybrot, and other novel composite beings at the level of cells, organisms, and societies). In its own words, "this new word is derived from the Greek word 'σύνθεσις' (synthesis), meaning 'putting together,' and 'βίος' (bios), meaning 'life.' The -sis ending is also used in other terms denoting interaction or association, like 'symbiosis.' Synthbiosis signifies the flourishing relationship between living and artificial or engineered forms, portraying an image of different entities coming together to create something new and beneficial. This term emphasizes the interdependence and co-prosperity that arises from this unique interconnection, reflecting the concept of 'thriving together.'" with beings who are not entirely (or at all) like us. Humans find it very easy to draw boundaries for compassion and concern based on the smallest of distinctions between Us and Others, and this kind of "othering" has led to massive suffering throughout our history.[11,40-42] The coming spectrum of beings spanning the gap between "standard *Homo sapiens*" and an ELIZA chatbot[43] is huge and complex. We will need to navigate it or risk massive ethical lapses, as have occurred in the past when we thought various groups and human embodiments were below the level of human agents and thus unworthy of concern. It is perhaps the hardest problem there is, but it is facing humanity now; software AIs are just the harbinger.
We will have to make progress to become a mature species ethically, not just technologically. The current AIs are a gift—a training sandbox in which we can explore these ideas, prompted by confusing but likely non-agential systems, before the arrival of truly DIs renders these ethical questions immediate and dire. In many ways, the decades of science fiction love stories between beings of radically different composition and provenance are as important in driving a resetting of intuitions as the recent advances in bioengineering and DI. Recognizing that the forthcoming diversity of beings cannot be as easily dismissed from moral concern as can today's language models, we can shift the emphasis from "what can they do" to "what do we owe them."

[PAGE 5] 6. We do not Want to be Replaced; but what are we?

Many have defended an essential, privileged status of human beings.[44,45] Each of us is a walking, thinking collection of cells. We are made of an agential material in which each cell, tissue, and organ has its own ancient agenda and problem-solving competencies in physiological, anatomical, and metabolic spaces.[21,46,47] Our bodies are a collective intelligence, as are our minds (consisting of the function of a myriad of neurons and other cell types, and exploiting other minds and various tools for our cognition[38]). Our cells change over with time, and the materials of our body come and go constantly. An embryo is more than the sum of its individual cells because of a story all the cells commit to—they are all motivated by the goals of a journey through anatomical space. Mentally, we too are stories—collections of self-models, goals, and preferences to which our brain and body components commit. These stories are not fixed but change as our brain and body cells seek to improve their internal models of the outside world and of themselves. The cognitive glue that binds subunits into the emergent higher-level selves that we are includes bioelectricity—information-processing networks implemented by electrical signals among all cells. And despite the presence of physics-obeying mechanisms that underlie our life, the story of our chemistry is not the only (or even the most important) perspective—we are true cognitive beings with huge cognitive light cones (a cognitive light cone demarcates the size, in space and time, of the largest goal an agent can effectively pursue[48]). By joining into physiological networks, cells scale up their modest metabolic and proliferative goals into the grandiose construction projects that collectives can remember and work toward—building and repairing organs. This description is not "metaphorical" because the same experimental tools and molecular mechanisms relevant to the grouping of neurons into an animal with memories and behavioral competencies are now being exploited to manipulate the large-scale efforts of cells in regenerative medicine contexts.[49-53] While evolution and embryogenesis scale up the cognitive light cone of cells into that of cell collectives working on organ-sized anatomical construction projects, other processes like cancer can cause it to shrink again, resulting in cells that treat the rest of the body as just external environment. This can support goals of which our parts cannot conceive.
We are forever in jeopardy of dissociation, because we are made of active parts with their own agendas. Many mechanisms are required to keep these autonomous parts (neurons and all other cells) working toward the upkeep of the larger collective with its own unique memories, goals, and dreams. Keeping up a complex Self (in body and mind) is an active, dynamic, constant process of harnessing the individual components toward large-scale goals. Our individual parts can defect—cells can shrink their Self-model to a tiny radius matching the modest goals of their microbial past, to become cancer, thereafter treating the rest of the body as the external environment (this occurs in the body due to the action of oncogenes and other factors that cause disruptions in the cells' ability to join into a cohesive information-processing network. In the mind-brain, this kind of dissociative break can be caused by stress and trauma. These processes shift the perceived computational boundary between Self and World by changing the size of the Self [from a large tissue/organ back to that of individual unconnected cells]).[48] This downscaling of the cognitive light cone, and the upscaling of it during embryonic development, tells us that the boundary between Self and World is not fixed and can change both between generations and within a single lifetime.
This plasticity and the ability to determine our own Self-model—the story we tell ourselves about our structure, our capabilities, and our goals—is fundamental to the ability of life to survive evolutionary change, to thrive in novel environments and overcome developmental noise and perturbation, and to exist as chimeric and bioengineered forms.
Caterpillars destroy and remodel their brains to become butterflies. The memories formed during their 2D past life are maintained[54] but are remapped into novel behaviors with salience appropriate to their new 3D life, new food preferences, and new ways to control the body. What is it like to be a creature whose brain, body, cognitive repertoire, and preferences are completely refactored into a new form? We're about to find out, as a species. Of course, we already know it as individuals. Does the child we once were, before puberty changed our brain and remodeled our preferences and priorities, still exist? Will patients whose brains receive treatment with new stem cells for degenerative disease and aging still exist? Does our past Self exist in any sense, given the constant need to reify our Self-model and our memories using the engrams (biophysical implementations of specific memories in the body or brain[55-58]) left by past experience? The answers to these questions require us to abandon binary categorizations of intelligence to embrace that fundamental nature of all minds that should cohere while learning and improving: continuous change.
Every species faces this fundamental paradox: if it fails to change, it dies out. If it changes, it is no longer the same species. It is the same with us; all processes of learning, communication, and exploration change us. Moving beyond a vision of our Selves as persistent things, toward a process philosophy,[59,60] allows us to see change and growth with anticipation and not fear. That growth and change should be managed by wisdom and compassion toward specific values, not the random attractors of dynamical systems set up by evolutionary processes that do not have anyone's happiness as a goal. This perspective provides a new frame for the problem of what happens to us when new beings enter our world: It is not about how to remain the same caterpillar, but how to leverage the new knowledge gained to advance and thrive.

[PAGE 7] 7. AI, Living Beings, Machines: The Similarities are as Important as the Differences

The fundamental issues we must solve as a species have been explored for many decades in science fiction literature concerning exobiological life forms and robotics. We have not yet found any aliens, but the questions surrounding how we would recognize and relate to unfamiliar beings are now being brought to the foreground with advances in the information and life sciences. It is time to begin to grapple with the existential issues brought up by the aspects of AI that are general to all intelligent agents. In many ways, the debates about AI obscure important gaps in our understanding of ourselves and our own journey from matter to mind.
Many claim that AIs shuffle symbols, but do not really understand.[62,63] Very few of those arguments start with a definition of what it means in the context of a biological human, with their network of excitable cells and soup of neurotransmitters, to "understand." Perhaps this is because of (purely software) AIs' use of ungrounded symbols that do not refer to real experience in the world. But anyone who has had, or has been around, human children can see the gradual shift from babbling to pattern-matching words that seem to offer reinforcement to conversation that clearly reflects understanding. What happens during that process? Note that it involves all the issues we see with AIs today—loose symbol grounding (talking about things they've never experienced), confabulation, sycophancy, errors, etc. This is all a normal part of any cognitive system's development. And think about your own thoughts and speech: what percentage of the things you can convincingly talk about are grounded in first-hand experience? What percentage of the things you are sure of are grounded in any solid evidence, beyond inputs you've received from others? It's a sobering exercise to trace back the origins of the contents of our minds. How do we ground our symbols and what does it mean for transitional forms, such as infants, early hominids, or other vertebrates? The oft-asked question "but do they really understand?" highlights our own lack of a good theory of what it means when we understand (beyond the feeling that "we really get it"), along with our inability to imagine that some other very different being could be as good as us at understanding.

[PAGE 8] Perhaps the proof is in the achievements: surely humans understand, because groups of us built on generations of accumulated thought and experiment to tame the physical world via great engineering feats. Surely interplanetary flight, nuclear power, and bone marrow transplants mean that we have truly understood aspects of the universe? Yes; but what happens when groups of autonomous agents, engineered or hybrid, make novel discoveries and build things? This is already beginning, via the efforts of the artificial life (ALIFE), swarm robotics, and robot scientist communities.[64-69] I suspect that engineering and scientific feats by unconventional agents, which are used as sufficient evidence of understanding in the human realm, will still be discounted by many who will claim that they do it, but do not really understand. It is not easy to force people to make explicit their criteria, and those goalposts often shift as science advances.[70]
One other way people think about this is through "embodiment." Perhaps we are different from symbol-shuffling engines because we engage in the real world; we have bodies, and isn't at least some percentage of our mental content informed and polished by the interaction of our bodies with the world? Yes, embodiment is crucial. But we need to get over the idea that embodiment must involve a canonical physical body moving through 3D space.[21] This goes beyond robotics, which gives AI an actual body to cohabit in the environment alongside us, and beyond the coming revolution in virtual reality where many of us will spend a considerable amount of time in more interesting virtual worlds. While our sense organs are primed for recognizing agency in medium-sized objects moving at medium speeds through the 3D world, biology shows us that many active agents of different levels of intelligence live, traverse, win, lose, and suffer in other worlds,[71] much as humans are now moving into virtual worlds of their own making.
We are simply not very good at recognizing behavior, especially intelligent behavior, in spaces like the metabolic space, gene expression space, anatomical morphospace, etc. But recent advances in cell biology and bioengineering are revealing that the future of regenerative medicine may require us to understand how collective cellular intelligence navigates these other spaces by making decisions.[49] If we had a primary sense of our body chemistry, we would have no problem recognizing that our livers and kidneys are intelligent agents that solve problems every day in their attempt to achieve and maintain various goals in those physiological spaces. It's not that AIs are disembodied, or that they inhabit weird, imaginary spaces—so do "you." In an important sense, you are a "Brain in a Vat"[72]—an intelligence that builds internal models of the outside world and constructs visions of space while being unaware of the limitations of its sensory and processing systems and the many spaces in which its components actually work. Thinking about how AIs might be embodied is an important part of understanding ourselves and the fallible, necessarily limited, ability we have to engage with the "real" world. In tandem with this, consider how we humans, who take actions such as moving money and environmental resources based on outputs produced by AIs, are effectively aspects of AIs' bodies.
[PAGE 9] The reality is that we do not yet know how we really work, and we have a limited understanding of how even today's AIs work. Deep emergence suggests that with AIs, just as with human reproduction (in Dennett's phrase, competence without comprehension), we can create systems whose capabilities we do not understand—emergence of cognition, not just complexity or unpredictability.[73] Thus, a profound sense of humility is needed for statements about the lack of embodiment, intelligence, "true understanding," etc., in any system outside our very narrow experience.
To be clear, I do not support a deflationary, reductionist account of biological agency; we are not "just chemical machines." That framing is as utterly insufficient for progress in science and engineering[49,53] as it is for personal and social relationships. Whatever common questions are salient to AIs (today's AIs, as well as the radically different future AIs), they are not meant to minimize the special nature of living beings, including highly metacognitive ones like us. We are emergent, majestic agents, with causally potent willpower and moral worth. But it is critical to replace our ancient anthropocentric, in-group focused perspectives with science-driven frameworks that ask the hard questions about what it means to be embodied minds in a physical universe, and how we can rationally expand our compassion to Others. We are not fully encompassed by reductive perspectives on mechanism or methods for interaction with simple machines, but neither are a wide range of other beings which we are only beginning to imagine. Our tendency toward a zero-sum view of intelligence (the belief that acknowledging that AIs share some of our features necessarily lowers the worth of our own cognition) may be abandoned as we grow as a species. DI is not about deconstructing our importance; it's about developing an unflinching skepticism about things folk psychology takes for granted, and developing new versions of prescientific concepts around the things that make minds so special.


[PAGE 8] 8. Why is All this Critical Now?

It is clear that the forthcoming wave of AI-enhanced humans, cyborgs, hybrots (biological brains driving robotic bodies[74-78]) and household robotic AIs will strongly impact everything from the legal system to our normal daily lives. The network of concepts that will be revolutionized is truly vast. For example, basic notions of contribution, ownership, and invention are already being strained. If someone uses an AI to create something, who really created it? The confusion comes from trying to maintain a binary distinction between the creator, the tool, and perhaps various assistants who helped, or teachers who trained the creator (or the tool). As in many other domains, we are too focused on drawing crisp, binary boundaries. Steinbeck wrote,[79] "Nothing was ever created by two men. Once the miracle of creation has taken place, the group can build and extend it, but the group never invents anything. The preciousness lies in the lonely mind of a man." There is a certain truth to this, because of the difficulty of forming truly effective collective minds. But Steinbeck's sentiment belies a mistaken conviction that a "man" is an indivisible monad, not a collection of parts, competencies, drives, and tools (both internal and external to the body). All intelligences are collective intelligences, especially biological ones. A better understanding of the creative process, novel methods for improving emergent integration of creative agents, and improved social systems for fostering creativity require us to develop better models of causation and the essential contributions that support life-positive incentives for invention and discovery. Crucially, the path is not toward a washed-out notion of "everyone gets participation credit for everything," but toward the rational development of policies that enhance and scale-up creative performance, as biology did when it discovered how to bind individual cells into a complex organism that solves new problems in new worlds inaccessible to its individual components.
We also have to confront the fear of "losing our humanity" by dependence on, or other kinds of relationships with, these beings. From fire to farmed wheat to bicycles to calculators, all technology requires us to ask how it is changing us. A close friend—an outdoorsy forest ranger—was shocked to discover that I, a grown man, did not have the skills to successfully locate, hunt down, prepare, and eat a deer if I was hungry and supermarkets were not an option. He felt that humans had lost much of themselves by outsourcing food, although it seems most of us are alright with the trade-off. What skills and properties are essential to our humanity, and which are we willing to give up as we turn our finite attention to more interesting concerns?


[PAGE 9] 9. A Path Forward: An Ethics Filter for Civilization

There seems to be no convincing argument that the trial-and-error process of random mutation and selection has any monopoly on making minds that matter—why can't biological principles be implemented and enhanced by mindful engineers and the fruits of centuries of thought in the humanities, not just random cosmic rays hitting egg cells? While it's likely that today's creations are not high on the spectrum of cognition, this is surely a temporary situation due to improving understanding of the agential material of life and the principles of the scaling of minds across substrates.[46,47,81]
By focusing on language models and today's AIs, and on vague talk of "machines" versus "real beings,"[82] we have given ourselves permission to avoid key questions that serve as a Rubicon of maturity—to focus almost exclusively on "what will AI do to us?" and avoid the hard questions of what we owe other beings that are not like us in many ways. The challenge will not be LLMs.[12] It will be embodied software AIs that mimic biological architectures, hybrots, cyborgs, genetically and technologically augmented/repaired humans, and many other new forms of life that cannot be dismissed as easily as LLMs (never mind actual exo-biological aliens). They will share some, but not all, history with us. This makes it imperative to develop a principled continuum of ethical synthbiosis that goes beyond "Are you real or faking it?" I do not believe that our civilization can survive without solving this problem.
There are two ways to get this wrong. One way is objectophilia—a misplaced relationship with objects that seem mindful but are fooling us and do not have the agency to reciprocate deep relationships. But the opposite end of the spectrum—"Only love your own kind"—is arguably worse and leads to the kinds of ethical lapses with which our history is rife: mistreatment of others based on imaginary differences in the depth of their inner perspective (e.g., insufficient analgesia given to human women). We need to get it right, to develop principled frameworks for scaling our moral concern to the essential qualities of beings who matter, without relying on outdated categories of "natural" or "artificial." Old categories—what you look like and where you came from—have failed us consistently and will fail us in even worse ways in the coming decades. Our personal frameworks, as well as those of our legal systems, must begin to adapt to the emerging science around a continuum of possible minds.
The risk of not doing this is profound. It is very easy for humans to close off our radius of concern and only offer moral consideration to those who are exactly like us. The key question is not what AIs will do to us. Rather, it is how we will make sure to express kindness to the forthcoming wave of unconventional embodied minds. LLMs and their limitations constitute a straw man that distracts us from the bigger picture. Let's start to develop a way to make sure that we express kindness appropriately and are not driven by fear of the "other" and by magnification of differences. We need to focus on what we have in common, from which we can weave a defensible set of relational heuristics.
The field of DI is ideally placed to provide light on the way forward. It guides us away from constrictive questions like "Is it like a human mind?", a question that neither predicts risk nor addresses moral responsibility. There is an astronomical space of possible minds; many of them are dangerous, and many of them need, and are worthy of, love. Emerging sciences of bioengineering, cognition, and information are offering us, for the first time, the tools needed to answer anew key questions of what we really are, what we value, and what limits to functional compassion, driven by fear and selfishness, we are willing to overcome. The journey open to us, from the place where self-reflective thought took its first steps, is in equal measure outward into the universe and inward into ourselves.

[PAGE 10] Acknowledgements

The author gratefully acknowledges Kathleen Wood and Julia Poirier for assistance with the manuscript. The author also thanks Benjamin Levin, as well as Richard Watson, Olaf Witkowski, Thomas Doctor, Bill Duane, Elizaveta Solomonova, Pranab Das, Anna Ciaunica, and Daniel C. Dennett for many discussions on these topics. Research was sponsored by the Army Research Office and was accomplished under grant no. W911NF-23-1-0100. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Office or the U.S. Government.

[PAGE 10] Conflict of Interest

The author declares no conflict of interest.

[PAGE 10] Author Contributions

Michael Levin: conceptualization (lead); writing—original draft (lead); and writing—review and editing (lead).