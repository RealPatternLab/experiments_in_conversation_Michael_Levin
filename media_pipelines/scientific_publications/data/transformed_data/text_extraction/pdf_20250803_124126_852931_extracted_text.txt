arXiv:2501.13188v1 [cond-mat.stat-mech] 22 Jan 2025
Topological constraints on self-organisation in locally interacting systems*
Francesco Sacco
Allen Discovery Center at Tufts University, Medford, MA 02155
Dalton AR Sakthivadivel
Department of Mathematics, CUNY Graduate Center, New York, NY 10016
Michael Levin
Allen Discovery Center at Tufts University, Medford, MA 02155
Department of Biology, Tufts University
Wyss Institute for Biologically Inspired Engineering, Harvard University
(Dated: 24th January 2025)
All intelligence is collective intelligence, in the sense that it is made of parts which must align with
respect to system-level goals. Understanding the dynamics which facilitate or limit navigation of
problem spaces by aligned parts thus impacts many fields ranging across life sciences and engineering.
To that end, consider a system on the vertices of a planar graph, with pairwise interactions prescribed
by the edges of the graph. Such systems can sometimes exhibit long-range order, distinguishing one
phase of macroscopic behaviour from another. In networks of interacting systems we may view
spontaneous ordering as a form of self-organisation, modelling neural and basal forms of cognition.
Here, we discuss necessary conditions on the topology of the graph for an ordered phase to exist,
with an eye towards finding constraints on the ability of a system with local interactions to maintain
an ordered target state. By studying the scaling of free energy under the formation of domain walls
in three model systems—the Potts model, autoregressive models, and hierarchical networks—we
show how the combinatorics of interactions on a graph prevent or allow spontaneous ordering. As
an application we are able to analyse why multiscale systems like those prevalent in biology are
capable of organising into complex patterns, whereas rudimentary language models are challenged
by long sequences of outputs.
Keywords: Diverse intelligence, emergence, self-organisation, Potts model, phase transitions

[PAGE 1] I. INTRODUCTION
Self-organisation is a fascinating phenomenon observed across diverse systems in nature and technology. In biology, self-organisation of complex structures and functions, from subcellular machinery to multicellular morphogenesis, requires alignment of parts in order to navigate a problem space toward specific adaptive ends [1-7]. Dynamics of this form can be viewed as a sort of autopoietic cognition, raising interesting questions about how self-organising systems navigate through configuration space given some target morphology [8-18]. More recently, current approaches to machine learning have involved physics-inspired models such as the Hopfield network [19-21] and spin glasses [22], and energy-based [23] or diffusion models [24]. In these systems, in order to maintain a pattern out of equilibrium or produce sensible data over long time spans, there must exist a 'condensed' phase with long-range order. Whilst some systems—like those prevalent in biology—demonstrate remarkable abilities to organise at large-scales, other systems that also exhibit some degree of collective intelligence such as natural language models have much more limited capabilities. Despite this, spin systems have also been used to model cellular morphogenesis [25-29], suggesting the difference goes beyond the substrate of intelligence considered. In this paper we are interested in placing explicit thermodynamic bounds on the probability of some example systems occupying such a phase, with applications to estimating their capability to self-organise. In particular, this paper is motivated by the following question: what is the functional distinction between simple language models and multicellular organisms, and can generative AI harness that property to achieve long-range order?

A quick argument due initially to Landau-Lifshitz [30, §149] shows why the one-dimensional Ising model has no ordered phase at any temperature. Recall that a thermodynamically favourable change in state is one which decreases the free energy
ΔF = ΔΕ - TAS.
Let N be the number of spins in the chain and suppose a domain wall of perimeter P forms at an arbitrary location in the chain. Using an effective Hamiltonian, calculating the free energy of the system with zero domain walls and the system with one domain wall shows that the change in free energy scales like -Tlog P, meaning that forming a domain wall is always thermodynamically favourable for sufficiently large P. As a result, long chains are unstable under thermal fluctuations and disorder always propagates through the chain. In the thermodynamic limit there is no spontaneous magnetisation. Ising proves this by finding the partition function and calculating the mean magnetisation analytically in his celebrated 1925 paper, but the advantage of the argument of Landau and Lifshitz is that it applies generically to phase transitions in many different sorts of one-dimensional systems (though the details prove somewhat subtle) and uses a simple scaling argument. The argument to the contrary in dimension greater than one is famously due to Peierls [31], where it is shown that the change in internal energy has a factor of P balancing the change in entropy. This is found by computing the number of spins an 'island' interacts with which is highly dependent on the properties of the lattice. To circumvent this problem we focus only on the scaling relationship between energy and entropy.

We begin in Section II by presenting our argument for a large universality class of models, and deriving necessary conditions for the existence of an ordered phase in this class. In Section III we analyse the one-dimensional Potts chain as a simple model system, recovering the argument given by Landau-Lifshitz in a more general setting. Section IV maps autoregressive language models [32] onto this one-dimensional framework and proves their inability to maintain long-range order. Finally, we discuss implications of these results and future directions in Section VI. We conclude that certain systems cannot remain ordered over long ranges for all time, and suggest this no-go theorem as a source of fitness pressure for biological phenomena like stigmergy and embodiment. The key insight of our work will be that topology is the critical factor differentiating these systems. Namely, whilst cells in the human body can coordinate and organize over vast scales, forming coherent tissues and organs, language models struggle to maintain consistency beyond their limited context windows. This disparity stems directly from the underlying topology of interactions in these systems.

We thank Karl Friston for helpful comments and Mikalai Shevko for assistance with code debugging. An interactive preprint: francesco215.github.io/Language_CA and video abstract: youtu.be/cGcY-ReeGDU accompany this paper.

* DARS is supported by the Einstein Chair programme at the CUNY Graduate Center and the VERSES Research Lab.
† dsakthivadivel@gc.cuny.edu


[PAGE 2] II. THE MAIN ARGUMENT
Consider a k-vertex graph with k-by-k adjacency matrix G and an n-ary variable on each vertex. Denote each such variable as  _s_<sub>_i_</sub> , indexed by  _i_ ∈ {1,..., _k_ }. The interactions between any set of spins will be given by the Hamiltonian _H_.

Definition 1. A _windowed Hamiltonian H_ is a Hamiltonian in which spin-spin interactions are defined only within a finite window of interaction _w_.

Remark. Without loss of generality, we will assume that the lowest energy state of any windowed Hamiltonian is zero. We will moreover assume the existence of an upper bound to the highest energy of any possible window Hamiltonian, _E_<sub>max</sub> <  _E_<sub>max</sub>. We call a sum of such effective Hamiltonians a _local Hamiltonian_. In particular,

Definition 2. A _local Hamiltonian_ is a Hamiltonian which can be decomposed into a sum of several window Hamiltonians _H_ = ∑<sub>_u_</sub> _H_<sub>_u_</sub>, all of which have the same window length _w_.

For intuition's purposes, one may notice a local Hamiltonian with window size equal to one is a discrete Markov field.

Our methodology will be given by the following prescription:
1. Begin with the system in one of the ordered configurations, e.g. one of the stored patterns
2. Create a domain wall
3. Estimate the energy gained by the system
4. Find the asymptotics of the free energy as the number of domain walls increases

Computing the change in _F_ by changing the number of domain walls requires detailed knowledge of the combinatorics of the interactions on the graph. Instead we can use the structure imposed by the windows. Namely, we have regulated the length of interactions such that we need only count the number of windows containing a domain wall. This does away with the particularities of the lattice and so can be applied to systems on very generic graphs. We will explore this in the present subsection.

The most general way to consider the interaction between the elements of our system is if the interactions are represented by a graph Hamiltonian. For simplicity we will assume that the edges of the graph are fixed in time; one can easily justify this by appealing to an adiabatic approximation where the birth or death of edges is unlikely for the timescale on which observations are made.

Definition 3. Let _G_ be the adjacency matrix of a graph on _k_ vertices and _H_ a _k_-by-_k_ matrix. A _graph Hamiltonian_ is the Hamiltonian of a weighted directed graph; namely a Hamiltonian which can be written as
_H_ = _H_ ◦ _G_
where ◦ is entry-wise multiplication and _H_ has as entries the coupling strengths of the system.

We will now give a recipe for computing the scaling behaviour of energy and entropy for a graph Hamiltonian system. For the sake of simplicity we will work with square planar embeddings of graphs (grid-like lattices) in the present paper. In these cases a domain wall and its perimeter can be easily defined (Figure 3).

Let _H_ be a graph Hamiltonian and _P_ be the perimeter length of a domain wall. As the perimeter length increases, the number of possible configurations of domain barriers increases, increasing the entropy of the system Δ_S_. We say that the entropy gained scales as _f_<sub>_S_</sub> if

Δ_S_ = O(_f_<sub>_S_</sub>(_P_)).

We give a similar definition for energy scaling: as the perimeter length increases, the upper and lower bounds of the energy gained scale as O(_f_<sub>high</sub>(_P_)) and O(_f_<sub>low</sub>(_P_)) respectively. If _f_<sub>high</sub> = _f_<sub>low</sub> = _f_<sub>_E_</sub> we say that the energy gained scales as _f_<sub>_E_</sub>, that is,

Δ_E_ = O(_f_<sub>_E_</sub>(_P_)).

If we can estimate how the energy and entropy scale, we can verify the existence or non-existence of an ordered phase without knowing the exact formulae for _E_(_P_) and _S_(_P_), only considering how they scale as _P_ → ∞.

Proposition 1. If O(_f_<sub>_S_</sub>) = O(_f_<sub>_E_</sub>) then there exists an ordered phase.

Proof. Suppose O(_f_) = O(_f_<sub>_S_</sub>) = O(_f_<sub>_E_</sub>). Then the change in free energy is

Δ_F_ = Δ_E_ – _T_Δ_S_ = lim<sub>_P_→∞</sub> O(_f_(_P_)) – _T_ O(_f_(_P_))

If we now take _T_ to zero, the change in free energy becomes increasingly positive. As such, the creation of a domain wall is unfavourable.


In this way we can rule out details of the system that could complicate the combinatorics—for example, the number of stored patterns. Let

π = (..., _s_<sub>−1</sub>, _s_<sub>0</sub>, _s_<sub>1</sub>, ...)

denote a ground state of the system. One may think of this state as a stored pattern or morphogenetic configuration. When there is a ground state degeneracy—that is, multiple states with zero energy exist, for instance, if a Hopfield model has _m_ > 1 stored patterns—they will be enumerated as

π<sup>_a_</sup> = (..., _s_<sub>−1</sub>, _s_<sub>0</sub>, _s_<sub>1</sub>, ...), 1 < _a_ < _m_.

We can show that the number of such patterns does not affect the scaling of the entropy.

Lemma 1. Let _H_ be a graph Hamiltonian with _m_ > 1 stored patterns. At thermal equilibrium, the ability to converge to an ordered phase is independent of _m_.

Proof. Let _B_(_P_) be the number of possible configurations of domain barriers with perimeter _P_. The change in entropy due to the creation of a domain barrier can always be written as

Δ_S_ = log [( _m_ - 1)_B_(_P_)] = log _B_(_P_) + log( _m_ - 1).

In the thermodynamic limit, the term proportional to the number of barriers increases, while the one proportional to the number of patterns stored stays constant. As such its contribution can be ignored. □

Lemma 2. Let _H_ = ∑<sub>_u_</sub> _H_<sub>_u_</sub>. If there exist two energies _E_<sub>max</sub>, _E_<sub>min</sub> which are the greatest and least non-zero energy level of all the windowed Hamiltonians _H_<sub>_u_</sub> respectively, then at thermal equilibrium, the ability to converge to an ordered phase is independent of energy levels and window sizes.

Proof. For any _H_<sub>_u_</sub> let _w_<sub>1</sub> the size of the smallest window and _w_<sub>2</sub> that of the largest. The energy gained from the creation of a domain wall is bounded by

_w_<sub>1</sub>_P E_<sub>min</sub> < Δ_E_ < _w_<sub>2</sub>_P E_<sub>max</sub>.

In both cases we have _E_ = O(_P_) so that the asymptotics of the system depend only on the perimeter length. □

Since the number and the shape of stored patterns do not affect the thermodynamics of the problem, and neither does the size of the interaction window, we reduce our analysis to the nearest-neighbour Ising model. Our main technical result is the following topological equivalence theorem:

Theorem 1. All local Hamiltonians on lattices with the same combinatorial structure have asymptotically equivalent free energies.

Proof. We will show we can approximate any _H_ with the Hamiltonian of some arbitrary other model in such a way that their asymptotics are equivalent, implying that in the thermodynamic limit, the Peierls argument depends only on the perimeter length in the approximate system. Let _H_ = ∑ _H_<sub>_u_</sub> be a local Hamiltonian on a planar graph _G_ with any spin _i_ coupled to _n_<sub>_i_</sub> other spins. Let _H_<sub>0</sub> be the Hamiltonian of an arbitrary system. One knows by the Bogoliubov inequality [33] that

_F_ < _F_<sub>0</sub> + < _H_ - _H_<sub>0</sub> ><sub>0</sub>

and therefore that if _H_ and _H_<sub>0</sub> are asymptotically equivalent then _F_ ~ _F_<sub>0</sub>. As the perimeter length increases we have _E_ = O(_P_) and _E_<sub>1</sub> = O(_P_<sub>0</sub>) by Lemma 2. If the combinatorics of the lattices are the same—namely, if the set of _n_<sub>_i_</sub> is equal on both lattices—then we can take _P_ = _P_<sub>0</sub>. The change in the energy is computed by the Hamiltonian of the new configuration, implying < _H_ - _H_<sub>0</sub> ><sub>0</sub> ~ 0. By Lemma 1, the probability of any disorder occurring is asymptotically the same in both systems, so that the change in free energies is also asymptotically equivalent. The claim follows. □

Corollary 1. The capacity for self-organisation in any system on a graph _G_—that is, the existence or non-existence of a phase transition—is equivalent to that of a nearest-neighbour Ising model on the same graph, with  and two stored patterns
π¹ = (1, 1, 1, ..., 1)
π² = (−1, -1, -1, . . ., −1).

An important remark is that we do not claim the phase transitions are the same. Naturally they will differ in general, for instance if there are more stored patterns in one system than the other. It is the existence of a phase transition from the topology of the lattice which we study.

[PAGE 5] III. STORED PATTERNS IN THE WINDOWED POTTS MODEL
With this in hand, we can study our first model system: the one-dimensional Potts model. The Potts model is a variant of the Ising model whose state vectors are richer than simply binary numbers. In particular, one can encode data in a Potts chain by choosing different spin configurations, recalling the discussion in the Introduction. It is a suitable model to describe stored images or other configurations of multiply-valued variables.

Definition 4. Let _n_ be a finite positive number. A Potts chain _C_ is a  ℤ-indexed set of _n_-ary integer symbols; that is, a chain of spins _s_<sub>_i_</sub> indexed by _i_ ∈ ℤ, where each _s_<sub>_i_</sub> can assume any integer value in {1,..., _n_}.

In the same fashion of Landau-Lifshitz, it can be shown that local Hamiltonians in dimension one do not converge to a prescribed ordered state, since the formation of a domain wall always 'interrupts' the pattern.

Theorem 2. Let _H_ be a one-dimensional local Hamiltonian with _m_ > 1 stored patterns. At non-zero temperature the formation of a domain wall is thermodynamically favourable.

Proof. Suppose that our Potts chain starts out in the first ground state or pattern, _C_ = π¹. If

Δ_F_ = Δ_E_ – _T_Δ_S_ < 0,

so that the free energy of the system decreases upon the formation of a domain barrier, then the formation of a domain barrier is thermodynamically favourable. It is immediate that any π<sup>_a_</sup> differs from some other π by at least one change in spin. In a sequence of length _L_ there are _L_ – 1 possible places where a domain wall can appear, and at each such place we may obtain one of the _m_-1 other patterns saved. As such the change in entropy of the system is

Δ_S_ = log[( _m_ - 1)(_L_ − 1)].

Upon the formation of a domain barrier, the windowed Hamiltonians that intersect it will have non-zero, positive energy. By assumption the energy is bounded, and no more than _w_ windows can be affected by a domain wall, from which we obtain

0 < Δ_E_ < _wE_<sub>max</sub>.

The change in free energy is

Δ_F_ < _wE_<sub>max</sub> – _T_ log[( _m_ - 1)(_L_ − 1)].

Assume _T_ > 0. As _L_ increases, the right hand side of the equation eventually becomes negative. □


[PAGE 5] IV. AUTOREGRESSIVE MODELS
We begin this section by recalling in Figure 4 the motivation stated in the introduction: contrasting the generation of textual features with the generation of morphological features, we would like to understand how the self-organising nature of text is constrained by the topology of the interactions between subunits generating that text.

We will now discuss a similar result as the one in the previous subsection, for autoregressive models.

[PAGE 6] An autoregressive model is formed when values of a sequence are regressed against previous values of that sequence. Here it will be defined as an estimator of some conditional probability distribution; namely, that of a sequence of observations of some data at step _i_, _C_, given a history of observations until _i_ - 1.

Definition 5. Let {_s_<sub>1</sub>,...,_s_<sub>_i_−1</sub>} be a random _n_-ary sequence of length _i_-1. Given a window (also called context) of length _w_, an order _w_ autoregressive model computes

_P_(_s_<sub>_i_</sub>|_s_<sub>_i_−1</sub>,..._s_<sub>_i_−_w_</sub>)

as a probability vector over {1,..., _n_} by generating samples of _s_<sub>_i_</sub> according to some random process on window states.

Such a function is called an AR(_w_) model in particular. As shorthand we will denote the estimator whose output is _v_ when given a sequence {_s_<sub>_i_−1</sub>,..._s_<sub>_i_−_w_</sub>} as _M_<sub>_w_</sub>:

_v_ := _M_(_s_<sub>_i_</sub> | _s_<sub>_i_−1</sub>,..._s_<sub>_i_−_w_</sub>).

The function _M_ has the type of a conditional probability distribution. We further write

_P_(_s_<sub>_i_</sub> = _c_) = _M_(_s_<sub>_i_</sub> = _c_ | _s_<sub>_i_−1</sub>,..._s_<sub>_i_−_w_</sub>)

for the _c_-th component of _v_.

To fit this in the discussion of patterns and long-range order in spin chains, we find the following theorem useful. We will set the convention that if _u_ - _w_ < 1 then the window is empty at that index, and that conditioning on the empty set is the same as taking unconditional probability.

Theorem 3. A unique local Hamiltonian with window length _w_ can be associated to any AR(_w_) model.

Proof. Let _M_ be our autoregressive model, and _s_<sub>_i_−1</sub>,...,_s_<sub>_i_−_w_</sub> our input sequence. The probability that the next observed spin in the sequence is equal to _c_ is

_P_(_s_<sub>_i_</sub> = _c_) = _M_(_s_<sub>_i_</sub> = _c_ | _s_<sub>_i_−1</sub>,..._s_<sub>_i_−_w_</sub>).

Suppose we assign an energy to each possible _c_ with a scalar function _E_: {1,..., _n_} → ℝ and constant weight β ≥ 0, such that

β_E_ = -log _P_(_s_<sub>_i_</sub> = _c_) + const with _c_ ∈ {1..._n_}.

Set the constant in such a way that the lowest energy state has energy equal to zero. Now define a windowed Hamiltonian

_H_<sub>_u_</sub>(_s_<sub>_u_</sub>) = -log _M_(_s_<sub>_u_</sub>|_s_<sub>_u_−1</sub>,..., _s_<sub>_u_−_w_</sub>) + const

for any _u_ in {1, ..., _i_} so that the probability of any _u_-th token occurring before _i_ is conditioned on the window preceding it. The full local Hamiltonian is the sum

_H_ = ∑<sub>_u_</sub> _H_<sub>_u_</sub> (_s_<sub>_u_</sub>)

in an obvious way. □

Remark. By Theorem 3, the generation of samples by an autoregressive model can now be seen as sampling from a Boltzmann distribution over sequences.

Most state-of-the-art language models of today are autoregressive, meaning that to predict the next word (or token) they look at all the previous elements of text. Indeed, transformers can be described as spin collectives [34-36]. Notably, however, as the context increases, it becomes computationally infeasible to predict the next token and only the last few words are fed as input to the model. Intuitively, this leads the model to completely forget what is left outside of its input window, placing constraints on how coherent the model is able to be over long periods of time. This will be a useful observation in Section VI.

We close this subsection with the following conclusion. The free energy can be calculated by _F_ = _E_ - β<sup>-1</sup>_S_ as usual. By Theorem 3, autoregressive models are one-dimensional systems described by a local Hamiltonian. The following corollary is then a consequence of the scaling argument in Theorem 2.

Corollary 2. For any finite β, an autoregressive model is unable to converge to a single stored pattern.

[PAGE 7] V. LARGE HIERARCHICAL SYSTEMS ON GRAPHS
In many systems of interest there are hierarchical interactions, i.e. effective interactions between subgraphs. Many multiscale systems in biology and physics exhibit complex patterns consisting of pockets of regularity assembled into structures with global irregularity, such as tissues with different morphogenetic features assembled out of their constituent cells [37-42], functional networks in the brain consisting of regions specialised to process certain sorts of information [43-46], and self-assembling molecules in active matter situations [47-51]. In this section we will investigate the interplay between the scaling of free energy at one level of a hierarchy and that of another, when the topology of the graph organises those levels meaningfully, to quantify when such patterns are possible. We will complement the results in previous sections by showing that systems lacking hierarchical structure may be limited in their ability to form complex patterns.

Recall that a clique is a (non-empty) complete induced subgraph. Suppose there exist _l_ > 1 independent cliques in _G_, with _n_<sub>1</sub>,...,_n_<sub>_l_</sub> vertices respectively, and each _n_<sub>_i_</sub> > 2. There will be a macrostate associated to each clique giving the magnetisation of that subgraph. We will argue that there are ways for local order but global disorder to exist in systems with cliques. Since the effective behaviour of the system, i.e. the properties of the cliques, is often a meaningful experimental variable (and hence a useful macrostate), this says organising a system hierarchically can create interesting order phenomena. In particular, we want to show there can exist 'hierarchical behaviours', where each clique individually is a coherent phase, but that phase varies from clique to clique.

For brevity, and without loss of generality, we will assume the coupling constants _J_ are uniform across the graph. We will need the following observation before we prove our main theorem in this section. Recall that Boltzmann's formula _S_ = _k_ log _W_ denotes by _W_ the multiplicity of a macrostate. A clique is positively (negatively) magnetised if all spins in the clique have value +1 (-1). We will begin with _l_ positively magnetised cliques. If the number (denote it _r_) of 'flipped' (i.e. uniformly changed) cliques is a macrostate, then the multiplicity is the number of ways to arrange _r_ distinguished cliques out of the total _l_ cliques. As such, we have

_S_ = _k_ log ( _l_ choose _r_ )

Theorem 4. Take any of the _l_ cliques. There exist parameter regimes where individual cliques may change from positive to negative magnetisation. For that temperature _T_, take any individual _n_<sub>_i_</sub>-clique and consider a spin within it. If the coupling of every spin in the clique is greater than log _n_<sub>_i_</sub> then the clique remains uniformly magnetised.

Proof. Flipping _r_ cliques from positive to negative magnetisation takes an energy of  ∑<sup>_r_</sup><sub>γ=1</sub> 2_Jn_<sub>_i_γ</sub> where γ indexes cliques flipped, and has an entropy of the logarithm of  _l_ choose _r_ . The full change in free energy is

Δ_F_ =  ∑<sup>_r_</sup><sub>γ=1</sub> 2_Jn_<sub>_i_γ</sub> - _T_ log ( _l_ choose _r_ )

so that the scaling behaviour of _r_ flips is

Δ_F_ ~ O(_r_) – _T_O(_r_ log _l_ - _r_ log _r_ + _r_),

where we have obtained the approximation of the entropy from ( _l_ choose _r_ ) ≈ _l_<sup>_r_</sup>/_r_! and Stirling's formula.


[PAGE 8] Clearly if (up to some constant)

_T_ > 1/(log _l_ - log _r_ +1)

then Δ_F_ < 0. Hence there exist temperatures for which it is favourable for some number _r_ of entire cliques to change. Fix such a _T_. Within an _n_<sub>_i_</sub>-clique there are _n_<sub>_i_</sub> ways to flip a single spin. This takes energy 2_J_. If we have 2_J_ > _T_log _n_<sub>_i_</sub>, then there is no domain wall within the clique.

By minding constants in the O(_r_) terms above we show the hypothesis can be attained—namely, that there exist values of _T_ for which the inequality is satisfied.

Proposition 2. Let _n_<sub>max</sub> be an integer greater than zero denoting the number of vertices in the largest clique. There exists a non-empty critical temperature range of hierarchical behaviour.

Proof. From the theorem above we have

2_J_/log _n_<sub>_i_</sub> > _T_ > 2_J_ ∑<sup>_r_</sup><sub>γ=1</sub> _n_<sub>_i_γ</sub> / (_r_log _l_ - _r_log _r_ + _r_)

We also know that

_r n_<sub>max</sub> >  ∑<sup>_r_</sup><sub>γ=1</sub> _n_<sub>_i_γ</sub>

and

1 > 1/log _n_<sub>_i_</sub>

so it suffices to take

2_J_/log _n_<sub>max</sub> > _T_ > 1/log _n_<sub>max</sub> * 2_Jrn_<sub>max</sub>/(_r_ log _l_ - _r_ log _r_ + _r_)

It follows that

1 > _T_ > 1/log _n_<sub>max</sub> * 1/(log _l_ - log _r_ +1) * _n_<sub>max</sub>.

Since the upper bound is a strictly decreasing function of _n_<sub>max</sub> with a singularity at one, and the lower bound is a linear function of _n_<sub>max</sub>, they intersect for some sufficiently small slope, before which the inequality is satisfied. We conclude that there exist _l_,_r_ for which the set of satisfactory _T_ is non-empty. In particular, this occurs whenever

_l_/_n_<sub>max</sub> > _r_/e

By looking at the effective behaviour of the graph we consider the statistical properties of cliques to be like those of individual spins. When those cliques themselves form cliques, we have complete induced subgraphs on an effective graph and can make this argument again (see Figure 7 for an example of what is meant).

This section demonstrates that whenever we have


[PAGE 9] cliques at some level, there can be interesting hybridised behaviours where local order may exist but the system may be globally disordered. This recapitulates observations of multiscale phenomena in biology and physics, where for some parameter regimes there is coherence at one level (e.g. the tissues constituting an individual organ) and non-uniformity at another (e.g. the differing organs in a body).

[PAGE 9] VI. CONCLUSIONS AND FUTURE DIRECTIONS
In this paper, we have developed a scaling argument extending Peierls' argument, which can be used to reason about the possibility of spontaneous order in systems with local interactions.

Biological systems are known to exploit the complex, hierarchical structures formed by cells in multicellular organisms to enable self-organisation and problem-solving in anatomical, physiological, and gene expression spaces, as well as the three-dimensional space of conventional behaviour and linguistics [52, 53]. Many recent discussions have focused on the similarities and differences in the dynamics that allow evolved, engineered, and hybrid systems to bind their parts towards efficient navigation to large-scale goals – a capability that is really a defining feature or "life" [5, 54-56].

In stark contrast, we have demonstrated that current natural language processing algorithms lack the necessary topology for self-organisation. This limitation explains their inability to generate long and coherent text that matches the complexity and consistency of biological systems. The key insight of our results is that topology is the critical factor differentiating these systems. Whilst cells in the human body can coordinate and organise over large scales, forming coherent tissues and organs, language models struggle to maintain consistency beyond their limited context windows. This disparity stems directly from the underlying topology of interactions in these systems.

By understanding the crucial role of topology in enabling self-organisation, we can begin to envision new architectures for natural language processing and biologically-inspired computing that might better emulate the self-organising capabilities of biological systems. The inability for autoregressive large language models to maintain states of long range order resembles the tangential speech or derailment in formal thought disorder, such as that found in schizophrenia and other forms of psychosis [57], lending an interesting interpretation to what is colloquially called 'hallucination'. Proposed therapeutic approaches to formal thought disorder involve refining the articulated thought in conversation or written (i.e. diagrammatic) form, suggesting that interacting with an environment is a way to enforce coherence of information. This further suggests that an embodied world model, extending the system in space and time by its interactions with an environment, can be leveraged to maintain coherence. We hypothesise this explains why stigmergy [58-61] and other forms of extracellular signalling arise in biological systems.

Throughout we have assumed that the free energy is minimised. For some systems the equilibration time is sufficiently long that in the interest of practicality one would be interested in relaxing this assumption – for example, when the energy landscape is very rugged. One calls such systems spin glasses [22].

Studying the phase transitions of glassy systems can be challenging even for relatively simple glasses, such as Hopfield networks [62, 63] or the Edwards-Anderson model [64]. In forthcoming work we will give similar estimates constraining the existence of phases with frozen disorder by the topology of the underlying lattice.